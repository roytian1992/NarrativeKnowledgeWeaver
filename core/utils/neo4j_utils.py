"""
Neo4jæ•°æ®åº“æ“ä½œå·¥å…·ç±»
æä¾›å¯æ‰©å±•çš„æŸ¥è¯¢æ¥å£ï¼Œä¾¿äºåç»­æ·»åŠ æ–°çš„æŸ¥è¯¢åŠŸèƒ½
"""

from typing import List, Optional, Union, Tuple, Dict, Any, Set
import json
from neo4j import Driver
from core.models.data import Entity, Relation
from tqdm import tqdm
import numpy as np
from core.utils.config import EmbeddingConfig
from core.utils.format import DOC_TYPE_META

EVENT_PLOT_GRAPH_RELS = ["EVENT_CAUSES", "EVENT_INDIRECT_CAUSES", "EVENT_PART_OF", "HAS_EVENT"]

class Neo4jUtils:
    """
    Neo4jæ•°æ®åº“æ“ä½œå·¥å…·ç±»
    è®¾è®¡åŸåˆ™ï¼š
    1. åŸºç¡€æŸ¥è¯¢æ–¹æ³•å¯å¤ç”¨
    2. æ”¯æŒåŠ¨æ€CypheræŸ¥è¯¢æ„å»º
    3. ä¾¿äºåç»­æ·»åŠ æ–°çš„æŸ¥è¯¢åŠŸèƒ½
    4. æŸ¥è¯¢ç»“æœæ ‡å‡†åŒ–å¤„ç†
    """
    
    def __init__(self, driver: Driver, doc_type: str = "screenplay"):
        """
        åˆå§‹åŒ–Neo4jå·¥å…·ç±»
        
        Args:
            driver: Neo4jè¿æ¥é©±åŠ¨
        """
        if doc_type not in DOC_TYPE_META:
            raise ValueError(f"Unsupported doc_type: {doc_type}")
        self.doc_type = doc_type
        self.meta = DOC_TYPE_META[doc_type]
        
        self.driver = driver
        self.model = None
        self.embedding_field = "embedding"
        # self.load_emebdding_model()
        
    def load_embedding_model(self, config: EmbeddingConfig):
        if config.provider == "openai":
            from core.model_providers.openai_embedding import OpenAIEmbeddingModel
            self.model = OpenAIEmbeddingModel(config)
            self.dim = config.dimensions
        else:
            from sentence_transformers import SentenceTransformer
            self.model = SentenceTransformer(config.model_name)
            self.dim = config.dimensions or self.model.get_sentence_embedding_dimension()
            
        # return model
    
    def execute_query(self, cypher: str, params: Dict[str, Any] = None) -> List[Dict]:
        """
        æ‰§è¡Œè‡ªå®šä¹‰CypheræŸ¥è¯¢çš„é€šç”¨æ–¹æ³•
        
        Args:
            cypher: CypheræŸ¥è¯¢è¯­å¥
            params: æŸ¥è¯¢å‚æ•°
            
        Returns:
            æŸ¥è¯¢ç»“æœåˆ—è¡¨
        """
        if params is None:
            params = {}
            
        with self.driver.session() as session:
            result = session.run(cypher, params)
            return [dict(record) for record in result]
        
    def search_entities_by_type(
        self,
        entity_type: Optional[str] = None,
        keyword: Optional[str] = None
    ) -> List[Entity]:
        """
        æœç´¢å›¾ä¸­æ‰€æœ‰æ»¡è¶³ç±»å‹å’Œå…³é”®è¯çš„å®ä½“ï¼ˆå¯é€‰è¿‡æ»¤ï¼‰
        
        Args:
            entity_type: å®ä½“ç±»å‹ï¼ˆå¦‚ "Character", "Concept", "Object"ï¼Œä¼  None è¡¨ç¤ºä¸é™åˆ¶ï¼‰
            keyword: å¯é€‰åç§°å…³é”®è¯ï¼ˆæ¨¡ç³ŠåŒ¹é… name æˆ– aliasesï¼‰
            limit: è¿”å›ç»“æœä¸Šé™
            
        Returns:
            List[Entity]
        """
        if self.driver is None:
            return []

        cypher_template = f"""
        MATCH (e:{entity_type if entity_type else ''})
        {{where_clause}}
        RETURN DISTINCT e
        """

        # åŠ¨æ€æ‹¼æ¥ WHERE å­å¥
        where_clauses = []
        params = {}

        if keyword:
            where_clauses.append(
                "(e.name CONTAINS $kw OR any(alias IN e.aliases WHERE alias CONTAINS $kw))"
            )
            params["kw"] = keyword

        where_clause = ""
        if where_clauses:
            where_clause = "WHERE " + " AND ".join(where_clauses)

        cypher = cypher_template.format(where_clause=where_clause)

        # æ‰§è¡ŒæŸ¥è¯¢
        with self.driver.session() as session:
            result = session.run(cypher, params)
            entities = []
            for record in result:
                data = record["e"]
                entities.append(self._build_entity_from_data(data))
            return entities

    
    def search_related_entities(
        self,
        source_id: str,
        predicate: Optional[str] = None,
        relation_types: Optional[List[str]] = None,
        entity_types: Optional[List[str]] = None,
        limit: Optional[int] = None,
        return_relations: bool = False
    ) -> Union[List[Entity], List[Tuple[Entity, Relation]]]:
        """
        æœç´¢ä¸æŒ‡å®šå®ä½“ç›¸å…³çš„å®ä½“ï¼Œå¯æŒ‰å…³ç³»ç±»å‹ã€è°“è¯ã€ç›®æ ‡å®ä½“ç±»å‹è¿‡æ»¤

        Args:
            source_id: æºå®ä½“ ID
            predicate: å…³ç³»è°“è¯è¿‡æ»¤ï¼ˆrel.predicateï¼‰
            relation_types: å…³ç³»ç±»å‹æ ‡ç­¾åˆ—è¡¨ï¼ˆCypher ä¸­çš„ :TYPE æ ‡ç­¾ï¼‰
            entity_types: ç›®æ ‡å®ä½“ç±»å‹è¿‡æ»¤ï¼ˆtarget.typeï¼‰
            limit: è¿”å›æ•°é‡é™åˆ¶ï¼ˆå¯é€‰ï¼Œä¸ä¼ åˆ™ä¸é™åˆ¶ï¼‰
            return_relations: æ˜¯å¦è¿”å› (å®ä½“, å…³ç³») å¯¹

        Returns:
            å®ä½“åˆ—è¡¨æˆ–å®ä½“-å…³ç³»å…ƒç»„åˆ—è¡¨
        """
        if self.driver is None:
            return []

        params: Dict[str, any] = {"source_id": source_id}
        if predicate:
            params["predicate"] = predicate
        if relation_types:
            params["rel_types"] = relation_types
        if entity_types:
            params["etypes"] = entity_types
        if limit:
            params["limit"] = limit

        # æ„é€  Cypher è¿‡æ»¤å­å¥
        predicate_filter = "AND rel.predicate = $predicate" if predicate else ""
        # type_filter = "AND type(target) IN $etypes" if entity_types else ""
        type_filter = "AND ANY(l IN labels(target) WHERE l IN $etypes)" if entity_types else ""

        rel_type_filter = "AND type(rel) IN $rel_types" if relation_types else ""
        limit_clause = "LIMIT $limit" if limit else ""

        results = []

        with self.driver.session() as session:
            # æ­£å‘è¾¹æŸ¥è¯¢
            forward_cypher = f"""
            MATCH (source)-[rel]->(target)
            WHERE source.id = $source_id
            AND rel.predicate IS NOT NULL
            {predicate_filter}
            {rel_type_filter}
            {type_filter}
            RETURN target, rel
            {limit_clause}
            """

            for record in session.run(forward_cypher, params):
                entity, relation = self._process_entity_relation_record(record, source_id, "forward")
                results.append((entity, relation) if return_relations else entity)

            # åå‘è¾¹æŸ¥è¯¢
            backward_cypher = f"""
            MATCH (target)-[rel]->(source)
            WHERE source.id = $source_id
            AND rel.predicate IS NOT NULL
            {predicate_filter}
            {rel_type_filter}
            {type_filter}
            RETURN target, rel
            {limit_clause}
            """

            for record in session.run(backward_cypher, params):
                entity, relation = self._process_entity_relation_record(record, source_id, "backward")
                results.append((entity, relation) if return_relations else entity)

        return results

    
    def get_entity_by_id(self, entity_id: str) -> Optional[Entity]:
        """
        æ ¹æ® ID ç²¾å‡†æŸ¥æ‰¾ä¸€ä¸ªå®ä½“èŠ‚ç‚¹ï¼ˆå…¼å®¹æ‰€æœ‰æ ‡ç­¾ï¼‰
        
        Args:
            entity_id: å®ä½“çš„å”¯ä¸€ IDï¼ˆä¾‹å¦‚ "entity_123456"ï¼‰
            
        Returns:
            åŒ¹é…çš„ Entity å¯¹è±¡ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å› None
        """
        cypher = """
        MATCH (e)
        WHERE e.id = $entity_id
        RETURN e
        LIMIT 1
        """
        params = {"entity_id": entity_id}

        with self.driver.session() as session:
            result = session.run(cypher, params)
            record = result.single()
            if not record:
                return None

            data = record["e"]
            return self._build_entity_from_data(data)
        
        
    def delete_relation_by_ids(
        self,
        source_id: str,
        target_id: str,
        relation_type: str
    ) -> bool:
        """
        æ ¹æ® source_idã€target_id å’Œ relation_type åˆ é™¤æŒ‡å®šå…³ç³»

        Args:
            source_id: æºå®ä½“çš„ ID
            target_id: ç›®æ ‡å®ä½“çš„ ID
            relation_type: è¦åˆ é™¤çš„å…³ç³»ç±»å‹ï¼ˆå¦‚ "EVENT_CAUSES"ï¼‰

        Returns:
            bool: æ˜¯å¦æˆåŠŸåˆ é™¤äº†å…³ç³»ï¼ˆTrue è¡¨ç¤ºè‡³å°‘åˆ é™¤äº†ä¸€æ¡ï¼‰
        """
        cypher = f"""
        MATCH (s)-[r:{relation_type}]->(t)
        WHERE s.id = $source_id AND t.id = $target_id
        DELETE r
        RETURN COUNT(r) AS deleted_count
        """
        params = {"source_id": source_id, "target_id": target_id}

        with self.driver.session() as session:
            result = session.run(cypher, params)
            record = result.single()
            return record and record["deleted_count"] > 0


    def get_common_neighbors(
        self,
        id1: str,
        id2: str,
        rel_types: Optional[List[str]] = None,
        direction: str = "any",  # "any" / "out" / "in"
        limit: Optional[int] = None,
    ) -> List[Entity]:
        """
        è¿”å›ä¸¤ä¸ªå®ä½“çš„å…±åŒé‚»å±…ï¼ˆé»˜è®¤å¿½ç•¥æ–¹å‘ï¼‰ã€‚
        
        Args:
            id1: ç¬¬ä¸€ä¸ªå®ä½“çš„ e.id
            id2: ç¬¬äºŒä¸ªå®ä½“çš„ e.id
            rel_types: å…³ç³»ç±»å‹ç™½åå•ï¼ˆå¦‚ ["RELATED_TO", "LOCATED_IN"]ï¼‰ï¼ŒNone è¡¨ç¤ºä¸é™
            direction: "any"ï¼ˆæ— å‘ï¼‰ã€"out"ï¼ˆa->n & b->nï¼‰ã€"in"ï¼ˆa<-n & b<-nï¼‰
            limit: å¯é€‰çš„ä¸Šé™æ¡æ•°
            
        Returns:
            List[Entity]: å…±åŒé‚»å±…çš„å®ä½“åˆ—è¡¨
        """
        # åŠ¨æ€å…³ç³»ç±»å‹ç‰‡æ®µ
        type_pattern = ""
        if rel_types:
            # å…³ç³»ç±»å‹ç”¨ | è¿æ¥ï¼Œå¦‚ :TYPE1|TYPE2
            type_pattern = ":" + "|".join(rel_types)

        # åŠ¨æ€æ–¹å‘
        if direction == "out":
            rel1 = f"-[r1{type_pattern}]->"
            rel2 = f"-[r2{type_pattern}]->"
        elif direction == "in":
            rel1 = f"<-[r1{type_pattern}]-"
            rel2 = f"<-[r2{type_pattern}]-"
        else:
            rel1 = f"-[r1{type_pattern}]-"
            rel2 = f"-[r2{type_pattern}]-"

        cypher = f"""
        MATCH (a {{id: $id1}}), (b {{id: $id2}})
        MATCH (a){rel1}(n)
        MATCH (b){rel2}(n)
        WHERE n.id <> $id1 AND n.id <> $id2
        RETURN DISTINCT n
        {"LIMIT $limit" if limit else ""}
        """

        params: Dict[str, Any] = {"id1": id1, "id2": id2}
        if limit:
            params["limit"] = limit

        with self.driver.session() as session:
            result = session.run(cypher, params)
            neighbors: List[Entity] = []
            for record in result:
                node = record["n"]
                neighbors.append(self._build_entity_from_data(node))
            return neighbors


    def get_common_neighbors_with_rels(
        self,
        id1: str,
        id2: str,
        rel_types: Optional[List[str]] = None,
        direction: str = "any",
        limit: Optional[int] = None,
    ) -> List[Dict[str, Any]]:
        """
        è¿”å›å…±åŒé‚»å±…ï¼Œå¹¶é™„å¸¦ä» a/b æŒ‡å‘è¯¥é‚»å±…çš„å…³ç³»ç±»å‹åˆ—è¡¨ï¼ˆä¾¿äºè°ƒè¯•/åˆ†æï¼‰ã€‚
        
        Returns:
            List[Dict]: å½¢å¦‚
                {
                "entity": Entity,
                "rels_from_a": ["RELATED_TO", ...],
                "rels_from_b": ["LOCATED_IN", ...]
                }
        """
        type_pattern = ""
        if rel_types:
            type_pattern = ":" + "|".join(rel_types)

        if direction == "out":
            rel1 = f"-[r1{type_pattern}]->"
            rel2 = f"-[r2{type_pattern}]->"
        elif direction == "in":
            rel1 = f"<-[r1{type_pattern}]-"
            rel2 = f"<-[r2{type_pattern}]-"
        else:
            rel1 = f"-[r1{type_pattern}]-"
            rel2 = f"-[r2{type_pattern}]-"

        cypher = f"""
        MATCH (a {{id: $id1}}), (b {{id: $id2}})
        MATCH (a){rel1}(n)
        MATCH (b){rel2}(n)
        WHERE n.id <> $id1 AND n.id <> $id2
        RETURN DISTINCT n, collect(DISTINCT type(r1)) AS fromA, collect(DISTINCT type(r2)) AS fromB
        {"LIMIT $limit" if limit else ""}
        """

        params: Dict[str, Any] = {"id1": id1, "id2": id2}
        if limit:
            params["limit"] = limit

        with self.driver.session() as session:
            result = session.run(cypher, params)
            out: List[Dict[str, Any]] = []
            for record in result:
                node = record["n"]
                out.append({
                    "entity": self._build_entity_from_data(node),
                    "rels_from_a": record["fromA"] or [],
                    "rels_from_b": record["fromB"] or [],
                })
            return out


    def list_relationship_types(self) -> List[str]:
        """
        è·å– Neo4j å›¾æ•°æ®åº“ä¸­å·²å­˜åœ¨çš„æ‰€æœ‰å…³ç³»ç±»å‹
        
        Returns:
            å…³ç³»ç±»å‹åç§°åˆ—è¡¨ï¼ˆå»é‡ã€æŒ‰å­—æ¯æ’åºï¼‰
        """
        cypher = """
        CALL db.relationshipTypes() YIELD relationshipType
        RETURN relationshipType
        ORDER BY relationshipType
        """

        with self.driver.session() as session:
            result = session.run(cypher)
            rel_types = [record["relationshipType"] for record in result]

        return rel_types
    
    def list_entity_types(self) -> List[str]:
        """
        è·å– Neo4j å›¾æ•°æ®åº“ä¸­å·²å­˜åœ¨çš„æ‰€æœ‰å®ä½“ç±»å‹ï¼ˆèŠ‚ç‚¹æ ‡ç­¾ï¼‰

        Returns:
            å®ä½“ç±»å‹åç§°åˆ—è¡¨ï¼ˆå»é‡ã€æŒ‰å­—æ¯æ’åºï¼‰
        """
        cypher = """
        CALL db.labels() YIELD label
        RETURN label
        ORDER BY label
        """
        with self.driver.session() as session:
            result = session.run(cypher)
            labels = [record["label"] for record in result]
        if "*" in labels:
            labels.remove("*")
        return labels


    def get_relation_summary(self, src_id: str, tgt_id: str, relation_type: str=None) -> Optional[str]:
        """
        ç›´æ¥åœ¨ Neo4j ä¸­æŸ¥æ‰¾ src_id åˆ° tgt_id ä¹‹é—´çš„ç‰¹å®šå…³ç³»ï¼Œå¹¶è¿”å›æ ¼å¼åŒ–æè¿°
        
        Args:
            src_id: æºå®ä½“ ID
            tgt_id: ç›®æ ‡å®ä½“ ID
            relation_type: å…³ç³»ç±»å‹ï¼ˆå¦‚ "EVENT_CAUSES"ï¼‰
        
        Returns:
            æ ¼å¼åŒ–æè¿°å­—ç¬¦ä¸²æˆ– None
        """
        cypher = f"""
        MATCH (s {{id: $src_id}})-[r:{relation_type}]->(t {{id: $tgt_id}})
        RETURN r, s.id AS source_id, t.id AS target_id
        LIMIT 1
        """
        results = self.execute_query(cypher, {"src_id": src_id, "tgt_id": tgt_id})

        if not results:
            return None

        record = results[0]
        relation = record["r"]
        description = ""
        subject_name = self.get_entity_by_id(src_id).name
        subject_description = self.get_entity_by_id(src_id).description
        object_name = self.get_entity_by_id(tgt_id).name
        object_description = self.get_entity_by_id(tgt_id).description
        if relation_type in EVENT_PLOT_GRAPH_RELS:
            if relation.get("reason", ""):
                description = " ç†ç”±: " + str(relation.get("reason"))
            return f"{src_id} --> {tgt_id}\n{subject_description}-->{object_description}{description}"
            
        relation_name = relation.get("relation_name", relation.get("predicate", relation_type))
        description = ":" + relation.get("description", "æ— ç›¸å…³æè¿°")
        return f"{subject_name}({subject_description})-{relation_name}->{object_name}({object_description}){description}"


    def delete_relation_type(self, relation_type):
        print(f"ğŸ§¹ æ­£åœ¨æ¸…é™¤å·²æœ‰çš„ {relation_type} å…³ç³»...")
        self.execute_query(f"""
            MATCH ()-[r:{relation_type}]->()
            DELETE r
        """)
        print(f"âœ… å·²åˆ é™¤æ‰€æœ‰ {relation_type} å…³ç³»")
        

    def has_path_between(
        self, 
        src_id: str, 
        dst_id: str, 
        max_depth: int = 5, 
        allowed_rels: Optional[List[str]] = None
    ) -> bool:
        """
        åˆ¤æ–­å›¾ä¸­æ˜¯å¦å­˜åœ¨ä» src åˆ° dst çš„è·¯å¾„ï¼Œä»…å…è®¸ä½¿ç”¨ç™½åå•ä¸­æŒ‡å®šçš„è¾¹ç±»å‹
        
        Args:
            src_id: æºå®ä½“ID
            dst_id: ç›®æ ‡å®ä½“ID
            max_depth: æœ€å¤§è·¯å¾„æ·±åº¦
            allowed_rels: å…è®¸çš„å…³ç³»ç±»å‹ï¼ˆå¦‚ ['follows', 'supports']ï¼‰
            
        Returns:
            æ˜¯å¦å­˜åœ¨è·¯å¾„
        """
        if not allowed_rels:
            print("âš ï¸ æ²¡æœ‰æŒ‡å®š allowed_rels ç™½åå•ï¼ŒæŸ¥è¯¢å¯èƒ½æ— æ„ä¹‰")
            return False

        # ç”¨å†’å·æ‹¼æ¥ï¼š:rel1|rel2|rel3
        rel_pattern = ":" + "|".join(allowed_rels)

        cypher = f"""
        MATCH p = (src {{id: $src}})-[{rel_pattern}*1..{max_depth}]-(dst {{id: $dst}})
        WHERE src.id <> dst.id
        RETURN count(p) > 0 AS connected
        """

        try:
            with self.driver.session() as session:
                result = session.run(
                    cypher,
                    {"src": src_id, "dst": dst_id}
                ).single()
                return result["connected"] if result else False
        except Exception as e:
            print(f"[Neo4j] has_path_between (whitelist mode) æ‰§è¡Œå¤±è´¥: {e}")
            return False


    def _build_entity_from_data(self, data) -> Entity:
        """
        ä»Neo4jæŸ¥è¯¢ç»“æœæ„å»ºEntityå¯¹è±¡
        - ä¸å†è¯» e.type å±æ€§ï¼›ç”¨èŠ‚ç‚¹ labels ä½œä¸ºç±»å‹ï¼ˆæ”¯æŒå¤šç±»å‹ï¼‰
        - å…¶ä½™é€»è¾‘ä¿æŒä¸å˜
        """
        # å–æ ‡ç­¾ï¼ˆå…¼å®¹ neo4j.Node æˆ– dictï¼‰ï¼Œå¹¶å»æ‰è¶…æ ‡ç­¾ Entity
        if hasattr(data, "labels"):
            labels = [lbl for lbl in list(data.labels) if lbl != "Entity"]
        else:
            labels = [lbl for lbl in (data.get("labels", []) or []) if lbl != "Entity"]

        # properties ä»å¯èƒ½æ˜¯å­—ç¬¦ä¸²åŒ–çš„ JSON
        raw_props = data.get("properties", "{}")
        try:
            props = json.loads(raw_props) if isinstance(raw_props, str) else (raw_props or {})
        except Exception:
            props = {}

        return Entity(
            id=data["id"],
            name=data["name"],
            type=labels if labels else "Unknown",   # â† è¿™é‡Œä» labels æ¥ï¼ˆUnion[str, List[str]] å…¼å®¹ï¼‰
            aliases=data.get("aliases", []),
            description=data.get("description", ""),
            properties=props,
            source_chunks=data.get("source_chunks", []),
        )


    # def _build_entity_from_data(self, data) -> Entity:
    #     """
    #     ä»Neo4jæŸ¥è¯¢ç»“æœæ„å»ºEntityå¯¹è±¡
        
    #     Args:
    #         data: Neo4jèŠ‚ç‚¹æ•°æ®
            
    #     Returns:
    #         Entityå¯¹è±¡
    #     """
    #     return Entity(
    #         id=data["id"],
    #         name=data["name"],
    #         type=data.get("type", "Unknown"),
    #         aliases=data.get("aliases", []),
    #         description=data.get("description", ""),
    #         properties=json.loads(data.get("properties", "{}")),
    #         source_chunks=data.get("source_chunks", []),
    #     )

    def _process_entity_relation_record(
        self, 
        record, 
        source_id: str, 
        direction: str
    ) -> Tuple[Entity, Relation]:
        """
        å¤„ç†å®ä½“-å…³ç³»æŸ¥è¯¢è®°å½•
        
        Args:
            record: Neo4jæŸ¥è¯¢è®°å½•
            source_id: æºå®ä½“ID
            direction: å…³ç³»æ–¹å‘ ("forward" æˆ– "backward")
            
        Returns:
            (Entity, Relation)å…ƒç»„
        """
        data = record["target"]
        rel = record["rel"]
        # print("[CHECL] rel.type: ", rel.type )
        
        entity = self._build_entity_from_data(data)
        # print("[CHECK] rel: ", [k for k in rel])
        predicate = rel.get("predicate", rel.type)
        
        if direction == "forward":
            relation_id_str = f"{source_id}_{predicate}_{data["id"]}"
        else:
            relation_id_str = f"{data["id"]}_{predicate}_{source_id}"
            
        rel_id = f"rel_{hash(relation_id_str) % 1000000}"
        
        
        if direction == "forward":
            relation = Relation(
                id=rel.get("id", rel_id),
                subject_id=source_id,
                predicate=predicate,
                object_id=data["id"],
                source_chunks=rel.get("source_chunks", []),
                properties=json.loads(rel.get("properties", "{}")),
            )
        else:  # backward
            relation = Relation(
                id=rel.get("id", rel_id),
                subject_id=data["id"],
                predicate=predicate,
                object_id=source_id,
                source_chunks=rel.get("source_chunks", []),
                properties=json.loads(rel.get("properties", "{}")),
            )
        
        return entity, relation
    
    
    def encode_node_embedding(self, node: Dict) -> List[float]:
        name = node.get("name", "")
        desc = node.get("description", "")
        props = node.get("properties", "")
        try:
            props_dict = json.loads(props) if isinstance(props, str) else props
        except Exception:
            props_dict = {}

        # æ„é€ åµŒå…¥è¾“å…¥
        if props_dict:
            prop_text = "ï¼›".join([f"{k}ï¼š{v}" for k, v in props_dict.items()])
            text = f"{name}{name}{name}.{desc}.{prop_text}"
        else:
            text = f"{name}{name}{name}.{desc}"
        if len(text) > 500:
            text = text[:500] # BGEæœ€å¤§ä¸Šä¸‹æ–‡é™åˆ¶
        embed = self.model.encode(text)
        embed = embed.tolist() if hasattr(embed, "tolist") else embed
        return embed

    def encode_relation_embedding(self, rel: Dict) -> Optional[List[float]]:
        try:
            props = rel.get("properties", "")
            props_dict = json.loads(props) if isinstance(props, str) else props
            desc = props_dict.get("description", "")
            if desc:
                embed = self.model.encode(desc)
                embed = embed.tolist() if hasattr(embed, "tolist") else embed
                return embed
        except Exception:
            pass
        return None
    
    def fetch_all_nodes(self, node_types: List[str]) -> List[Dict]:
        results = []
        with self.driver.session() as session:
            for label in node_types:
                query = f"""
                MATCH (e:{label})
                RETURN labels(e) AS labels, e.id AS id, e.name AS name, e.description AS description, e.properties AS properties
                """
                res = session.run(query)
                results.extend([r.data() for r in res])
        return results

    def fetch_all_relations(self, relation_types: Optional[List[str]] = None) -> List[Dict]:
        """
        è·å–å›¾ä¸­æ‰€æœ‰å…³ç³»ï¼Œæ”¯æŒæŒ‰å…³ç³»ç±»å‹ï¼ˆpredicateï¼‰è¿‡æ»¤ã€‚

        Args:
            relation_types: è¦ä¿ç•™çš„å…³ç³»ç±»å‹åˆ—è¡¨ï¼ˆå¦‚ ["happens_at", "causes"]ï¼‰
                            è‹¥ä¸º Noneï¼Œåˆ™è¿”å›æ‰€æœ‰å…³ç³»

        Returns:
            æ¯æ¡è¾¹çš„æ•°æ®å­—å…¸ï¼Œå­—æ®µåŒ…æ‹¬ predicateã€idã€properties
        """
        with self.driver.session() as session:
            if relation_types:
                predicate_filter = ", ".join([f"'{r}'" for r in relation_types])
                query = f"""
                MATCH ()-[r]->()
                WHERE type(r) IN [{predicate_filter}]
                RETURN type(r) AS predicate, r.id AS id, r.properties AS properties
                """
            else:
                query = """
                MATCH ()-[r]->()
                RETURN type(r) AS predicate, r.id AS id, r.properties AS properties
                """

            result = session.run(query)
            return [record.data() for record in result]

        
    def update_node_embedding(self, node_id: str, embedding: List[float]) -> None:
        with self.driver.session() as session:
            session.run(f"""
            MATCH (e) WHERE e.id = $id
            SET e.{self.embedding_field} = $embedding
            """, id=node_id, embedding=embedding)
            
    def update_relation_embedding(self, rel_id: str, embedding: List[float]) -> None:
        with self.driver.session() as session:
            session.run(f"""
            MATCH ()-[r]->() WHERE r.id = $id
            SET r.{self.embedding_field} = $embedding
            """, id=rel_id, embedding=embedding)
    
    def process_all_embeddings(self, entity_types: List[str] = [], exclude_entity_types: List[str] = []):
        """
        è‡ªåŠ¨å¤„ç†æ‰€æœ‰èŠ‚ç‚¹æ ‡ç­¾å’Œæ‰€æœ‰è¾¹ï¼Œä¸ºå…¶ç”Ÿæˆ embedding å¹¶å†™å›å›¾æ•°æ®åº“ã€‚
        èŠ‚ç‚¹ embedding è¾“å…¥ï¼šname + description (+ properties)
        è¾¹ embedding è¾“å…¥ï¼šproperties.description
        """
        # === è·å–æ‰€æœ‰å®ä½“ç±»å‹ï¼ˆæ ‡ç­¾ï¼‰ ===
        if not entity_types:
            entity_types = self.list_entity_types()

        # === å¤„ç†èŠ‚ç‚¹åµŒå…¥ ===
        print("ğŸš€ å¼€å§‹å¤„ç†èŠ‚ç‚¹åµŒå…¥...")
        for node in exclude_entity_types:
            if node in entity_types:
                entity_types.remove(node)
                
        print(f"ğŸ“Œ å®ä½“ç±»å‹æ ‡ç­¾: {entity_types}")
        nodes = self.fetch_all_nodes(entity_types)
        for n in  tqdm(nodes, desc="Encoding Nodes", ncols=80):
            try:
                emb = self.encode_node_embedding(n)
                self.update_node_embedding(n["id"], emb)
            except Exception as e:
                print(f"âš ï¸ Node {n.get('id')} embedding failed:", str(e))

        print(f"âœ… èŠ‚ç‚¹åµŒå…¥å®Œæˆï¼Œå…±å¤„ç† {len(nodes)} ä¸ªèŠ‚ç‚¹")
                
    def ensure_entity_superlabel(self):
        """
        ä¸ºæ‰€æœ‰å…·æœ‰ embedding çš„èŠ‚ç‚¹æ·»åŠ è¶…æ ‡ç­¾ :Entityï¼ˆè·³è¿‡å·²å­˜åœ¨æ ‡ç­¾ï¼‰
        """
        query = """
        MATCH (n)
        WHERE n.embedding IS NOT NULL AND NOT 'Entity' IN labels(n)
        SET n:Entity
        """
        with self.driver.session() as session:
            session.run(query)
            print("[âœ“] å·²ä¸ºæ‰€æœ‰å« embedding çš„èŠ‚ç‚¹æ·»åŠ è¶…æ ‡ç­¾ :Entity")

    def create_vector_index(self, index_name="entityEmbeddingIndex", similarity="cosine"):
        """
        åˆ é™¤å·²æœ‰åŒåç´¢å¼•å¹¶é‡å»ºç»Ÿä¸€å‘é‡ç´¢å¼•
        """

        with self.driver.session() as session:
            # DROP index if existsï¼ˆ5.x è¯­æ³•ï¼‰
            session.run(f"DROP INDEX {index_name} IF EXISTS")
            print(f"[âœ“] å·²åˆ é™¤æ—§ç´¢å¼• {index_name}ï¼ˆå¦‚å­˜åœ¨ï¼‰")

            # åˆ›å»ºæ–°ç´¢å¼•ï¼ˆæ ‡å‡† Cypher è¯­æ³•ï¼Œç¤¾åŒºç‰ˆå…¼å®¹ï¼‰
            session.run(f"""
            CREATE VECTOR INDEX {index_name}
            FOR (n:Entity)
            ON (n.embedding)
            OPTIONS {{
              indexConfig: {{
                `vector.dimensions`: {self.dim},
                `vector.similarity_function`: '{similarity}'
              }}
            }}
            """)
            print(f"[âœ“] å·²åˆ›å»ºæ–°å‘é‡ç´¢å¼• {index_name} on :Entity(embedding)")

    def _query_entity_knn(self, embedding: list, top_k: int = 5):
        """
        æŸ¥è¯¢ä¸è¾“å…¥ embedding å‘é‡æœ€ç›¸ä¼¼çš„ top-K èŠ‚ç‚¹
        """
        query = """
        CALL db.index.vector.queryNodes('entityEmbeddingIndex', $top_k, $embedding)
        YIELD node, score
        RETURN node.name AS name, labels(node) AS labels, node.id AS id, score
        ORDER BY score DESC
        """

        with self.driver.session() as session:
            result = session.run(query, {"embedding": embedding, "top_k": top_k})
            return result.data()

    def query_similar_entities(self, text: str, top_k: int = 5, normalize: bool = True):
        """
        ç»™å®šè‡ªç„¶è¯­è¨€ `text`ï¼Œè‡ªåŠ¨ç¼–ç ä¸º embeddingï¼ŒæŸ¥è¯¢æœ€ç›¸ä¼¼çš„å®ä½“èŠ‚ç‚¹ï¼ˆä½¿ç”¨ entityEmbeddingIndexï¼‰

        Args:
            text (str): æŸ¥è¯¢æ–‡æœ¬ï¼ˆå¦‚å®ä½“åã€äº‹ä»¶ç‰‡æ®µç­‰ï¼‰
            model: ä½ çš„ embedding æ¨¡å‹ï¼ˆéœ€æœ‰ encode æ–¹æ³•ï¼‰
            top_k (int): è¿”å›å‰ top-k ä¸ªç»“æœ
            normalize (bool): æ˜¯å¦æ ‡å‡†åŒ–å‘é‡ï¼ˆç¡®ä¿åŒ¹é… cosine ç´¢å¼•ï¼‰

        Returns:
            List[Dict]: åŒ…å« nameã€labelsã€idã€score çš„ç»“æœåˆ—è¡¨
        """
        embed = self.model.encode(text)
        embed = embed.tolist() if hasattr(embed, "tolist") else embed
         
        return self._query_entity_knn(embed, top_k=top_k)
    
    
    def compute_semantic_similarity(self, node_id_1, node_id_2):
        query = f"""
        MATCH (a {{id: '{node_id_1}'}}), (b {{id: '{node_id_2}'}})                                          
        RETURN gds.similarity.cosine(a.embedding, b.embedding) AS similarity
        """
        result = self.execute_query(query)
        return result[0].get("similarity")
    
    def compute_graph_similarity(self, node_id_1, node_id_2, field):
        query = f"""
        MATCH (a {{id: '{node_id_1}'}}), (b {{id: '{node_id_2}'}})                                          
        RETURN gds.similarity.cosine(a.{field}, b.{field}) AS graph_similarity
        """
        result = self.execute_query(query)
        return result[0].get("graph_similarity")
    
    def check_nodes_reachable(
        self,
        src_id: str,
        dst_id: str,
        max_depth: int = 3,
        excluded_rels: Optional[List[str]] = None
    ) -> bool:
        """
        åˆ¤æ–­ä¸¤ä¸ªä»»æ„èŠ‚ç‚¹ä¹‹é—´æ˜¯å¦å­˜åœ¨è·¯å¾„ï¼Œé•¿åº¦ä¸è¶…è¿‡ max_depthï¼Œä¸”ä¸åŒ…å«æŸäº›å…³ç³»ç±»å‹
        
        Args:
            src_id: èµ·ç‚¹èŠ‚ç‚¹ ID
            dst_id: ç»ˆç‚¹èŠ‚ç‚¹ ID
            max_depth: æœ€å¤§å…è®¸çš„è·¯å¾„æ·±åº¦
            excluded_rels: è¦æ’é™¤çš„å…³ç³»ç±»å‹åˆ—è¡¨ï¼ˆå¦‚ ["SCENE_CONTAINS"]ï¼‰
            
        Returns:
            æ˜¯å¦å¯è¾¾ï¼ˆTrue/Falseï¼‰
        """
        rel_filter = ""
        if excluded_rels:
            # æ„é€ è¿‡æ»¤è°“è¯ï¼štype(r) <> 'X' AND type(r) <> 'Y' ...
            rel_filter = " AND ".join([f"type(r) <> '{rel}'" for rel in excluded_rels])
            rel_filter = f"WHERE ALL(r IN relationships(p) WHERE {rel_filter})"

        query = f"""
        MATCH (n1 {{id: $src_id}}), (n2 {{id: $dst_id}})
        RETURN EXISTS {{
            MATCH p = (n1)-[*1..{max_depth}]-(n2)
            {rel_filter}
        }} AS reachable
        """
        result = self.execute_query(query, {"src_id": src_id, "dst_id": dst_id})
        if result and isinstance(result, list):
            return result[0].get("reachable", False)
        return False


    def get_entity_info(self, event_id: str, entity_type="", contain_relations=False, contain_properties=False) -> str:
        """
        è·å–äº‹ä»¶çš„è¯¦ç»†ä¿¡æ¯ï¼Œç”¨äºå› æœå…³ç³»æ£€æŸ¥
        Args:
            event_id: äº‹ä»¶ID
            
        Returns:
            æ ¼å¼åŒ–çš„äº‹ä»¶ä¿¡æ¯å­—ç¬¦ä¸²
        """
        event_node = self.get_entity_by_id(event_id)
        
        relation_types = self.list_relationship_types()
        
        for relation in EVENT_PLOT_GRAPH_RELS + [self.meta["contains_pred"]]:
            if relation in relation_types:
                relation_types.remove(relation)
            
        results = self.search_related_entities(
            source_id=event_id, 
            return_relations=True,
            relation_types=relation_types
        )
        
        relevant_info = []
        for result in results:
            info = self._get_relation_info(result[1])
            if info:
                relevant_info.append("- " + info)
                
        event_description = event_node.description or "æ— å…·ä½“æè¿°"
        if not entity_type:
            entity_type = "å®ä½“"
        
        context = f"{entity_type}åç§°ï¼š{event_node.name}ï¼Œæè¿°ï¼š{event_description}\n"
        if contain_relations:
            context += f"ç›¸å…³ä¿¡æ¯æœ‰ï¼š\n" + "\n".join(relevant_info) + "\n"
    
        if contain_properties:
            event_props = event_node.properties
            # print(event_props)
            non_empty_props = {k: v for k, v in event_props.items() if v}

            if non_empty_props:
                context += f"{entity_type}çš„å±æ€§å¦‚ä¸‹ï¼š\n"
                for k, v in non_empty_props.items():
                    context += f"- {k}ï¼š{v}\n"

        return context
    
    
    def _get_relation_info(self, relation) -> Optional[str]:
        """
        è·å–å…³ç³»ä¿¡æ¯çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        
        Args:
            relation: å…³ç³»å¯¹è±¡
            
        Returns:
            æ ¼å¼åŒ–çš„å…³ç³»ä¿¡æ¯ï¼Œå¦‚æœæ˜¯SCENE_CONTAINSåˆ™è¿”å›None
        """
        if relation.predicate == self.meta["contains_pred"]:
            return None
            
        subject_id = relation.subject_id
        subject_name = self.get_entity_by_id(subject_id).name
        object_id = relation.object_id
        object_name = self.get_entity_by_id(object_id).name
        relation_name = relation.properties.get("relation_name", relation.predicate)
        description = relation.properties.get("description", "")
        
        return f"{subject_name}-{relation_name}->{object_name}: {description}"
    

    def create_event_causality_graph(
        self,
        graph_name: str = "event_causality_graph",
        force_refresh: bool = True,
        min_confidence: float = 0.0,
    ):
        """
        åŸºäº Event èŠ‚ç‚¹ä¸ä¸‰ç±»å…³ç³»ï¼ˆEVENT_CAUSES / EVENT_INDIRECT_CAUSES / EVENT_PART_OFï¼‰
        åˆ›å»ºä¸€ä¸ªç”¨äºå› æœåˆ†æçš„ GDS å­å›¾ï¼ˆæœ‰å‘ï¼ŒNATURAL æ–¹å‘ï¼‰ã€‚
        ä»…ä¿ç•™ coalesce(r.confidence, 0.0) >= min_confidence çš„è¾¹ã€‚
        - å…¼å®¹ä¸åŒ GDS ç‰ˆæœ¬ï¼šä¸ä½¿ç”¨ relationshipPropertiesï¼›æä¾› parameters ä¸å†…è”å¸¸é‡ä¸¤ç§åˆ›å»ºæ–¹æ¡ˆçš„å›é€€ã€‚
        """
        from neo4j.exceptions import ClientError
        rel_types = '["EVENT_CAUSES","EVENT_INDIRECT_CAUSES","EVENT_PART_OF"]'

        def _drop_if_exists(session, name: str):
            exists = session.run("CALL gds.graph.exists($name) YIELD exists", {"name": name}).single()["exists"]
            if exists:
                session.run("CALL gds.graph.drop($name) YIELD graphName", {"name": name})
                print(f"[âœ“] å·²åˆ é™¤æ—§å›¾ {name}")

        def _count_edges(session, min_conf: float) -> int:
            return session.run(
                f"""
                MATCH (:Event)-[r]->(:Event)
                WHERE type(r) IN {rel_types}
                AND coalesce(r.confidence, 0.0) >= $min_conf
                RETURN count(r) AS edge_count
                """,
                {"min_conf": float(min_conf)}
            ).single()["edge_count"]

        with self.driver.session() as s:
            # åˆ·æ–°
            if force_refresh:
                _drop_if_exists(s, graph_name)

            # å·²å­˜åœ¨ç›´æ¥è¿”å›
            exists = s.run("CALL gds.graph.exists($name) YIELD exists", {"name": graph_name}).single()["exists"]
            if exists:
                print(f"[=] å·²å­˜åœ¨å›¾ {graph_name}ï¼Œæœªåˆ·æ–°ã€‚")
                edge_count = _count_edges(s, min_confidence)
                print(f"[âœ“] å½“å‰æ»¡è¶³æ¡ä»¶çš„è¾¹æ•°é‡ï¼š{edge_count}")
                return

            # -------- æ–¹æ¡ˆAï¼šä½¿ç”¨ parametersï¼ˆä¸å¸¦ relationshipPropertiesï¼‰--------
            query_A = f"""
            CALL gds.graph.project.cypher(
            $name,
            'MATCH (e:Event) RETURN id(e) AS id',
            'MATCH (e1:Event)-[r]->(e2:Event)
                WHERE type(r) IN {rel_types}
                AND coalesce(r.confidence, 0.0) >= $min_conf
                AND e1 <> e2
            RETURN id(e1) AS source,
                    id(e2) AS target,
                    coalesce(r.confidence, 0.0) AS confidence',
            {{ parameters: {{ min_conf: $min_conf }} }}
            )
            YIELD graphName, nodeCount, relationshipCount
            RETURN graphName, nodeCount, relationshipCount
            """

            # -------- æ–¹æ¡ˆBï¼šä¸ä½¿ç”¨ parametersï¼Œå†…è”å¸¸é‡ --------
            query_B = f"""
            CALL gds.graph.project.cypher(
            $name,
            'MATCH (e:Event) RETURN id(e) AS id',
            'MATCH (e1:Event)-[r]->(e2:Event)
                WHERE type(r) IN {rel_types}
                AND coalesce(r.confidence, 0.0) >= {float(min_confidence)}
                AND e1 <> e2
            RETURN id(e1) AS source,
                    id(e2) AS target,
                    coalesce(r.confidence, 0.0) AS confidence'
            )
            YIELD graphName, nodeCount, relationshipCount
            RETURN graphName, nodeCount, relationshipCount
            """

            created = False
            try:
                rec = s.run(query_A, {"name": graph_name, "min_conf": float(min_confidence)}).single()
                created = True
            except ClientError as e:
                # æŸäº›ç‰ˆæœ¬ä¸æ”¯æŒ parameters é”®ï¼Œå›é€€åˆ°å†…è”å¸¸é‡æ–¹æ¡ˆ
                print(f"[i] ä½¿ç”¨ parameters æ–¹æ¡ˆå¤±è´¥ï¼Œå›é€€ï¼ˆåŸå› ï¼š{str(e)[:120]} ...ï¼‰")
            except Exception as e:
                print(f"[i] ä½¿ç”¨ parameters æ–¹æ¡ˆå¼‚å¸¸ï¼Œå›é€€ï¼ˆåŸå› ï¼š{str(e)[:120]} ...ï¼‰")

            if not created:
                rec = s.run(query_B, {"name": graph_name}).single()

            print(f"[+] å·²åˆ›å»ºå› æœå­å›¾ {rec['graphName']}")
            print(f"    èŠ‚ç‚¹æ•°: {rec['nodeCount']}ï¼Œè¾¹æ•°: {rec['relationshipCount']}")

            # ç»Ÿè®¡
            edge_count = _count_edges(s, min_confidence)
            print(f"[âœ“] å½“å‰æ»¡è¶³æ¡ä»¶çš„è¾¹æ•°é‡ï¼š{edge_count}")


    
    def create_subgraph(
        self,
        graph_name: str = "subgraph_1",
        exclude_entity_types: Optional[List[str]] = None,
        exclude_relation_types: Optional[List[str]] = None,
        force_refresh: bool = False,
    ) -> None:
        """
        åˆ›å»º/åˆ·æ–°ä¸€ä¸ª GDS å‘½åå­å›¾ï¼š
        - èŠ‚ç‚¹ï¼šå…¨å›¾èŠ‚ç‚¹ï¼Œä½†ä¼šæ’é™¤æŒ‡å®šæ ‡ç­¾ï¼ˆé»˜è®¤ :Sceneï¼‰
        - è¾¹  ï¼šæ’é™¤æŒ‡å®šå…³ç³»ç±»å‹ï¼ˆé»˜è®¤ SCENE_CONTAINSï¼‰
        
        Args:
            graph_name:            å­å›¾åç§°
            exclude_node_labels:   è¦æ’é™¤çš„èŠ‚ç‚¹æ ‡ç­¾åˆ—è¡¨ï¼Œé»˜è®¤ ["Scene"]
            exclude_rel_types:     è¦æ’é™¤çš„å…³ç³»ç±»å‹åˆ—è¡¨ï¼Œé»˜è®¤ ["SCENE_CONTAINS"]
            force_refresh:         å¦‚å­å›¾å·²å­˜åœ¨ï¼Œæ˜¯å¦å¼ºåˆ¶åˆ é™¤åé‡å»º
        """

        exclude_entity_types = exclude_entity_types or [self.meta["section_label"]]
        exclude_relation_types = exclude_relation_types or [self.meta["contains_pred"]]

        with self.driver.session() as s:
            # --- 1. è‹¥å·²å­˜åœ¨ä¸”è¦æ±‚åˆ·æ–°ï¼Œåˆ™åˆ é™¤ ---
            exists = s.run("RETURN gds.graph.exists($name) AS ok",
                        name=graph_name).single()["ok"]
            if exists and force_refresh:
                s.run("CALL gds.graph.drop($name, false)", name=graph_name)
                exists = False
                print(f"[âœ“] æ—§å­å›¾ {graph_name} å·²åˆ é™¤å¹¶åˆ·æ–°")

            if exists:
                print(f"[âœ“] GDS å­å›¾ {graph_name} å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º")
                return

            # --- 2. ç”ŸæˆèŠ‚ç‚¹ / å…³ç³» Cypher ---
            #   èŠ‚ç‚¹ï¼šæ’é™¤æŒ‡å®šæ ‡ç­¾
            label_filter = " AND ".join([f"NOT '{lbl}' IN labels(n)" for lbl in exclude_entity_types]) or "true"
            node_query = f"""
            MATCH (n) WHERE {label_filter}
            RETURN id(n) AS id
            """

            #   å…³ç³»ï¼šæ’é™¤æŒ‡å®šç±»å‹ & æ’é™¤ä¸è¢«æ’é™¤èŠ‚ç‚¹ç›¸è¿çš„è¾¹
            rel_filter = " AND ".join([f"type(r) <> '{rt}'" for rt in exclude_relation_types]) or "true"
            # é¢å¤–ä¿è¯ä¸¤ç«¯èŠ‚ç‚¹éƒ½ä¸æ˜¯è¢«æ’é™¤æ ‡ç­¾
            node_label_neg = " AND ".join([f"NOT '{lbl}' IN labels(a)" for lbl in exclude_entity_types] +
                                        [f"NOT '{lbl}' IN labels(b)" for lbl in exclude_entity_types]) or "true"

            rel_query = f"""
            MATCH (a)-[r]->(b)
            WHERE {rel_filter} AND {node_label_neg}
            RETURN id(a) AS source, id(b) AS target
            """

            # --- 3. è°ƒç”¨ project.cypher ---
            s.run("""
            CALL gds.graph.project.cypher(
            $name,
            $nodeQuery,
            $relQuery
            )
            """, name=graph_name, nodeQuery=node_query, relQuery=rel_query)

            print(f"[+] å·²åˆ›å»º GDS å­å›¾ {graph_name}ï¼ˆæ’é™¤æ ‡ç­¾ {exclude_entity_types}ï¼Œæ’é™¤è¾¹ {exclude_relation_types}ï¼‰")

    def run_louvain(
        self,
        graph_name: str = "event_graph",
        write_property: str = "community",
        max_iterations: int = 20,
        force_run: bool = False
    ) -> None:
        """
        åœ¨æŒ‡å®šå­å›¾ä¸Šè·‘ Louvainï¼›è‹¥å·²å†™è¿‡å±æ€§ä¸” !force_run åˆ™è·³è¿‡
        """
        with self.driver.session() as s:
            if not force_run:
                # å¿«é€Ÿæ£€æµ‹æ˜¯å¦å·²æœ‰ç¤¾åŒºå­—æ®µ
                has_prop = s.run("""
                    MATCH (n) WHERE exists(n[$prop]) RETURN n LIMIT 1
                """, prop=write_property).single()
                if has_prop:
                    print(f"[âœ“] èŠ‚ç‚¹å·²å­˜åœ¨ {write_property}ï¼Œè·³è¿‡ Louvain")
                    return

            s.run(f"""
            CALL gds.louvain.write($graph, {{
              writeProperty: $prop,
              maxIterations: $iters
            }});
            """, graph=graph_name, prop=write_property, iters=max_iterations)
            print(f"[+] Louvain å·²å®Œæˆï¼Œç»“æœå†™å…¥ `{write_property}`")

    
    # === 3. å–åŒç¤¾åŒºäº‹ä»¶å¯¹ ===
    def fetch_event_pairs_same_community(
            self,
            max_pairs: Optional[int] = None
        ) -> List[Dict[str, str]]:
        """
        è¿”å›åŒç¤¾åŒºçš„äº‹ä»¶å¯¹ ID åˆ—è¡¨ï¼ˆä¸å†è€ƒè™‘å›¾ä¸­æ˜¯å¦è·¯å¾„å¯è¾¾ï¼‰
        """
        q = """
        MATCH (e1:Event), (e2:Event)
        WHERE e1.community = e2.community AND id(e1) < id(e2)
        RETURN e1.id AS srcId, e2.id AS dstId
        """
        if max_pairs:
            q += f"\nLIMIT {max_pairs}"
        return self.execute_query(q)


    def write_event_causes(self, rows: List[Dict[str, Any]]) -> None:
        """
        å†™å…¥äº‹ä»¶é—´å…³ç³»ï¼ˆæŒ‰ predicate åˆ†ä¸‰ç±»ï¼‰ï¼š
        - CAUSES          -> :EVENT_CAUSES      ï¼ˆrelation_name=â€œå¯¼è‡´â€ï¼‰
        - INDIRECT_CAUSES -> :EVENT_INDIRECT_CAUSESï¼ˆrelation_name=â€œé—´æ¥å¯¼è‡´â€ï¼‰
        - PART_OF         -> :EVENT_PART_OF     ï¼ˆrelation_name=â€œå±äº/ç»„æˆâ€ï¼‰

        rows: [
        {"srcId": str, "dstId": str, "predicate": "CAUSES"|"INDIRECT_CAUSES"|"PART_OF",
        "reason": str, "confidence": float},
        ...
        ]
        """
        if not rows:
            return

        valid_rows = [r for r in rows if r.get("predicate") in ("CAUSES", "INDIRECT_CAUSES", "PART_OF")]
        if not valid_rows:
            print("[i] æ— å¯å†™å…¥çš„å…³ç³»ï¼ˆå…¨éƒ¨ä¸º NONE æˆ–æœªçŸ¥ predicateï¼‰")
            return

        cypher = """
        UNWIND $rows AS row
        MATCH (s:Event {id: row.srcId})
        MATCH (t:Event {id: row.dstId})
        WITH s, t, row

        // CAUSES
        FOREACH (_ IN CASE WHEN row.predicate = 'CAUSES' THEN [1] ELSE [] END |
        MERGE (s)-[r:EVENT_CAUSES]->(t)
        SET r.predicate     = row.predicate,
            r.reason        = row.reason,
            r.confidence    = coalesce(row.confidence, 0.0),
            r.relation_name = 'å¯¼è‡´'
        )

        // INDIRECT_CAUSES
        FOREACH (_ IN CASE WHEN row.predicate = 'INDIRECT_CAUSES' THEN [1] ELSE [] END |
        MERGE (s)-[r:EVENT_INDIRECT_CAUSES]->(t)
        SET r.predicate     = row.predicate,
            r.reason        = row.reason,
            r.confidence    = coalesce(row.confidence, 0.0),
            r.relation_name = 'é—´æ¥å¯¼è‡´'
        )

        // PART_OF
        FOREACH (_ IN CASE WHEN row.predicate = 'PART_OF' THEN [1] ELSE [] END |
        MERGE (s)-[r:EVENT_PART_OF]->(t)
        SET r.predicate     = row.predicate,
            r.reason        = row.reason,
            r.confidence    = coalesce(row.confidence, 0.0),
            r.relation_name = 'å±äº/ç»„æˆ'
        )
        """
        self.execute_query(cypher, {"rows": valid_rows})

        c_counts = {"CAUSES": 0, "INDIRECT_CAUSES": 0, "PART_OF": 0}
        for r in valid_rows:
            c_counts[r["predicate"]] += 1
        print(f"[+] å·²å†™å…¥/æ›´æ–°äº‹ä»¶å…³ç³» {len(valid_rows)} æ¡ "
            f"(CAUSES={c_counts['CAUSES']}, INDIRECT_CAUSES={c_counts['INDIRECT_CAUSES']}, PART_OF={c_counts['PART_OF']})")

    
    def get_all_events_with_causality(self, min_confidence: float = 0.0) -> List[Dict[str, Any]]:
        rel_types_str = '["EVENT_CAUSES","EVENT_INDIRECT_CAUSES","EVENT_PART_OF"]'
        cypher = f"""
        MATCH (e:Event)
        OPTIONAL MATCH (e)-[r]->(t:Event)
        WHERE type(r) IN {rel_types_str} AND coalesce(r.confidence,0.0) >= $min_conf
        OPTIONAL MATCH (s:Event)-[r2]->(e)
        WHERE type(r2) IN {rel_types_str} AND coalesce(r2.confidence,0.0) >= $min_conf
        RETURN e.id AS event_id,
            e.name AS event_name,
            e.description AS event_description,
            coalesce(e.properties, "{{}}") AS event_properties,
            collect(DISTINCT {{target: t.id, confidence: coalesce(r.confidence,0.0), rel_type: type(r)}}) AS outgoing,
            collect(DISTINCT {{source: s.id, confidence: coalesce(r2.confidence,0.0), rel_type: type(r2)}}) AS incoming
        """
        return self.execute_query(cypher, {"min_conf": float(min_confidence)})


    def get_causality_edges_by_confidence(self, min_confidence: float = 0.0) -> List[Dict[str, Any]]:
        rel_types_str = '["EVENT_CAUSES","EVENT_INDIRECT_CAUSES","EVENT_PART_OF"]'
        cypher = f"""
        MATCH (source:Event)-[r]->(target:Event)
        WHERE type(r) IN {rel_types_str} AND coalesce(r.confidence,0.0) >= $min_conf
        RETURN source.id AS source_id,
            target.id AS target_id,
            coalesce(r.confidence,0.0) AS confidence,
            type(r) AS rel_type
        """
        return self.execute_query(cypher, {"min_conf": float(min_confidence)})


    def identify_event_clusters_by_connectivity(self, min_confidence: float = 0.0) -> List[List[str]]:
        graph_name = f"event_causality_graph_{str(float(min_confidence)).replace('.', '_')}"
        try:
            self.execute_query(f"CALL gds.graph.drop('{graph_name}') YIELD graphName")
        except:
            pass

        rel_types_str = '["EVENT_CAUSES","EVENT_INDIRECT_CAUSES","EVENT_PART_OF"]'
        create_graph_cypher = f"""
        CALL gds.graph.project.cypher(
            '{graph_name}',
            'MATCH (n:Event) RETURN id(n) AS id',
            'MATCH (a:Event)-[r]->(b:Event)
            WHERE type(r) IN {rel_types_str} AND coalesce(r.confidence,0.0) >= {float(min_confidence)}
            RETURN id(a) AS source, id(b) AS target, coalesce(r.confidence,0.0) AS confidence'
        )
        """
        self.execute_query(create_graph_cypher)

        result = self.execute_query(f"""
        CALL gds.wcc.stream('{graph_name}')
        YIELD nodeId, componentId
        RETURN gds.util.asNode(nodeId).id as event_id, componentId
        ORDER BY componentId, event_id
        """)

        clusters = {}
        for r in result:
            clusters.setdefault(r["componentId"], []).append(r["event_id"])

        # ä»…ä¿ç•™ size>1 ä¸”èŠ‚ç‚¹ç¡®å®å‡ºç°åœ¨æ»¡è¶³é˜ˆå€¼çš„è¾¹ä¸­
        edges = self.get_causality_edges_by_confidence(min_confidence)
        connected = {e["source_id"] for e in edges} | {e["target_id"] for e in edges}
        return [c for c in clusters.values() if len(c) > 1 and any(x in connected for x in c)]

            

    def _fallback_clustering(self, threshold: float) -> List[List[str]]:
        """
        é™çº§èšç±»æ–¹æ³•ï¼šåŸºäºç›´æ¥å› æœå…³ç³»çš„ç®€å•èšç±»
        
        Args:
            threshold: æƒé‡é˜ˆå€¼
            
        Returns:
            List[List[str]]: äº‹ä»¶èšç±»åˆ—è¡¨
        """
        edges = self.get_causality_edges_by_confidence(threshold)
        
        # æ„å»ºé‚»æ¥è¡¨
        graph = {}
        all_events = set()
        
        for edge in edges:
            source = edge['source_id']
            target = edge['target_id']
            
            all_events.add(source)
            all_events.add(target)
            
            if source not in graph:
                graph[source] = []
            if target not in graph:
                graph[target] = []
                
            graph[source].append(target)
            graph[target].append(source)  # æ— å‘å›¾
        
        # DFSæŸ¥æ‰¾è¿é€šåˆ†é‡
        visited = set()
        clusters = []
        
        def dfs(node, current_cluster):
            if node in visited:
                return
            visited.add(node)
            current_cluster.append(node)
            
            for neighbor in graph.get(node, []):
                dfs(neighbor, current_cluster)
        
        for event in all_events:
            if event not in visited:
                cluster = []
                dfs(event, cluster)
                if len(cluster) > 1:  # åªä¿ç•™æœ‰å¤šä¸ªäº‹ä»¶çš„èšç±»
                    clusters.append(cluster)
        
        return clusters
    
    def enrich_event_nodes_with_context(self) -> None:
        """
        ä¸ºæ¯ä¸ª Event èŠ‚ç‚¹è¡¥å…¨ä¸Šä¸‹æ–‡å­—æ®µï¼Œå¹¶åˆå¹¶å†™å…¥åˆ° e.propertiesï¼ˆå­—ç¬¦ä¸²å‹ JSONï¼‰ä¸­ï¼š
        - time: List[str]
        - participants: List[str]
        - location: List[str]
        - chapter_name æˆ– scene_name: List[str]ï¼Œå–å†³äº doc_type
        """

        section_key = "scene_name" if self.doc_type == "screenplay" else "chapter_name"
        section_label = "Scene" if self.doc_type == "screenplay" else "Chapter"

        # Step 1: æŸ¥è¯¢æ‰€æœ‰äº‹ä»¶èŠ‚ç‚¹åŠå…¶ä¸Šä¸‹æ–‡
        cypher = f"""
        MATCH (e:Event)
        OPTIONAL MATCH (e)-[]-(t:TimePoint)
        OPTIONAL MATCH (e)-[]-(c:Character)
        OPTIONAL MATCH (e)-[]-(l:Location)
        OPTIONAL MATCH (e)-[]-(s:{section_label})
        RETURN e.id AS id,
            [x IN COLLECT(DISTINCT t.value) WHERE x IS NOT NULL] AS time,
            [x IN COLLECT(DISTINCT c.name) WHERE x IS NOT NULL] AS participants,
            [x IN COLLECT(DISTINCT l.name) WHERE x IS NOT NULL] AS location,
            [x IN COLLECT(DISTINCT s.name) WHERE x IS NOT NULL] AS {section_key},
            e.properties AS properties
        """
        records = self.execute_query(cypher)

        # Step 2: åˆå¹¶å­—æ®µå¹¶å†™å…¥ propertiesï¼ˆæ³¨æ„ properties æ˜¯å­—ç¬¦ä¸²å‹ JSONï¼‰
        for r in tqdm(records, desc="æ›´æ–° Event properties ä¸Šä¸‹æ–‡"):
            try:
                props: Dict[str, Any] = json.loads(r["properties"]) if r.get("properties") else {}
            except Exception:
                print(f"âš ï¸ JSON è§£æå¤±è´¥ï¼Œè·³è¿‡ id={r['id']}")
                continue

            props["time"] = r.get("time", [])
            props["participants"] = r.get("participants", [])
            props["location"] = r.get("location", [])
            props[section_key] = r.get(section_key, [])

            self.execute_query(
                "MATCH (e:Event {id: $id}) SET e.properties = $props_str",
                {"id": r["id"], "props_str": json.dumps(props, ensure_ascii=False)}
            )

        print(f"[âœ“] å·²å°†ä¸Šä¸‹æ–‡å±æ€§å°è£…å†™å…¥ e.properties å­—ç¬¦ä¸²å­—æ®µï¼ˆåŒ…å« time, participants, location, {section_key}ï¼‰")


    def get_event_details(self, event_ids: List[str]) -> List[Dict[str, Any]]:
        """
        è¿”å›äº‹ä»¶èŠ‚ç‚¹çš„æ ¸å¿ƒä¿¡æ¯ + properties + æ‰€å±ç« èŠ‚ä¿¡æ¯
        """
        cypher = f"""
        MATCH (e:Event)
        WHERE e.id IN $event_ids
        OPTIONAL MATCH (s:{self.meta['section_label']})-[:{self.meta['contains_pred']}]->(e)
        RETURN e.id          AS event_id,
            e.name        AS event_name,
            e.source_chunks AS source_chunks,
            e.description AS event_description,
            e.properties  AS event_properties,          // â† ç›´æ¥è¿”å›æ•´ä¸ªå±æ€§ Map
            collect(DISTINCT s.id)   AS section_ids,
            collect(DISTINCT s.name) AS section_names
        """
        return self.execute_query(cypher, {"event_ids": event_ids})


    def get_causality_paths(self, event_ids: List[str]) -> List[Dict[str, Any]]:
        rel_types_str = '["EVENT_CAUSES","EVENT_INDIRECT_CAUSES","EVENT_PART_OF"]'
        cypher = f"""
        MATCH (source:Event)-[r]->(target:Event)
        WHERE source.id IN $event_ids AND target.id IN $event_ids
        AND type(r) IN {rel_types_str}
        RETURN source.id AS source_id,
            source.name AS source_name,
            target.id AS target_id,
            target.name AS target_name,
            coalesce(r.confidence,0.0) AS confidence,
            r.reason AS causality_reason,
            type(r) AS rel_type
        ORDER BY confidence DESC
        """
        return self.execute_query(cypher, {"event_ids": event_ids})


    def create_plot_node(self, plot_data: Dict[str, Any]) -> bool:
        """
        åˆ›å»º Plot èŠ‚ç‚¹
        
        Args:
            plot_data: Plot æ•°æ®å­—å…¸
                å¿…é¡»åŒ…å«ï¼š
                - id: Plot ID
                - name: Plot åç§°ï¼ˆåŸ titleï¼‰
                - description: Plot æè¿°ï¼ˆåŸ summaryï¼‰
                - main_characters, locations, time, reason: å…¶ä»–å±æ€§
        
        Returns:
            bool: åˆ›å»ºæ˜¯å¦æˆåŠŸ
        """
        cypher = """
        MERGE (p:Plot {id: $plot_id})
        SET p.name = $name,
            p.description = $description,
            p.properties = $properties
        RETURN p.id AS plot_id
        """
        
        # ç»Ÿä¸€æ”¶é›†é™„åŠ å±æ€§åˆ° properties
        properties = {
            "main_characters": plot_data.get("main_characters"),
            "locations": plot_data.get("locations"),
            "time": plot_data.get("time"),
            "reason": plot_data.get("reason"),
            "related_events": plot_data.get("event_ids", []),
            "event_chain": "->".join(plot_data.get("event_ids", [])),
            "theme": plot_data.get("theme", ""),
            "goal": plot_data.get("goal", ""),
            "conflict": plot_data.get("conflict", ""),
            "resolution": plot_data.get("resolution", ""),
        }
        
        params = {
            "plot_id": plot_data["id"],
            "name": plot_data["title"],  # åŸ title
            "description": plot_data["summary"],  # åŸ summary
            "properties": json.dumps(properties, ensure_ascii=False)
        }
        
        try:
            result = self.execute_query(cypher, params)
            return len(list(result)) > 0
        except Exception as e:
            print(f"åˆ›å»º Plot èŠ‚ç‚¹å¤±è´¥: {e}")
            return False


    def create_plot_event_relationships(self, plot_id: str, event_ids: List[str]) -> bool:
        """
        åˆ›å»º HAS_EVENT å…³ç³»ï¼Œå¹¶å†™å…¥ä¸­æ–‡å«ä¹‰ relation_name=â€œåŒ…å«äº‹ä»¶â€
        """
        import hashlib

        rel_data = []
        for event_id in event_ids:
            rel_id = "rel_" + hashlib.sha1(f"{plot_id}-HAS_EVENT-{event_id}".encode("utf-8")).hexdigest()[:16]
            rel_data.append({
                "src_id": plot_id,
                "tgt_id": event_id,
                "rel_id": rel_id,
                "predicate": "HAS_EVENT",
                "relation_name": "åŒ…å«äº‹ä»¶",
            })

        cypher = """
        UNWIND $data AS row
        MATCH (p:Plot {id: row.src_id})
        MATCH (e:Event {id: row.tgt_id})
        MERGE (p)-[r:HAS_EVENT {id: row.rel_id}]->(e)
        SET r.predicate     = row.predicate,
            r.relation_name = row.relation_name
        RETURN count(r) AS relationships_created
        """
        try:
            result = self.execute_query(cypher, {"data": rel_data})
            count = list(result)[0]['relationships_created']
            return count == len(event_ids)
        except Exception as e:
            print(f"åˆ›å»º HAS_EVENT å…³ç³»å¤±è´¥: {e}")
            return False

    
    def create_plot_relations(self, edges: List[Dict[str, Any]]) -> bool:
        """
        æ‰¹é‡åˆ›å»ºæƒ…èŠ‚å…³ç³»ï¼ˆæœ€ç»ˆç‰ˆï¼Œå«ä¸­æ–‡ relation_nameï¼‰ï¼š
        - æœ‰å‘ï¼šPLOT_PREREQUISITE_FOR(â€œå‰ç½®/é“ºå«â€) / PLOT_ADVANCES(â€œæ¨è¿›â€) /
                PLOT_BLOCKS(â€œé˜»ç¢â€) / PLOT_RESOLVES(â€œè§£å†³â€)
        - æ— å‘ï¼šPLOT_CONFLICTS_WITH(â€œå†²çªâ€) / PLOT_PARALLELS(â€œå¹³è¡Œ/å‘¼åº”â€)

        edges: [{"src","tgt","relation_type","confidence","reason"}, ...]
        """
        if not edges:
            print("[!] æ²¡æœ‰ä¼ å…¥ä»»ä½•æƒ…èŠ‚å…³ç³»ï¼Œè·³è¿‡åˆ›å»ºã€‚")
            return False

        import hashlib

        DIRECTED = {
            "PLOT_PREREQUISITE_FOR",
            "PLOT_ADVANCES",
            "PLOT_BLOCKS",
            "PLOT_RESOLVES",
        }
        UNDIRECTED = {
            "PLOT_CONFLICTS_WITH",
            "PLOT_PARALLELS",
        }
        ALLOWED = DIRECTED | UNDIRECTED
        NAME_ZH = {
            "PLOT_PREREQUISITE_FOR": "å‰ç½®/é“ºå«",
            "PLOT_ADVANCES": "æ¨è¿›",
            "PLOT_BLOCKS": "é˜»ç¢",
            "PLOT_RESOLVES": "è§£å†³",
            "PLOT_CONFLICTS_WITH": "å†²çª",
            "PLOT_PARALLELS": "å¹³è¡Œ/å‘¼åº”",
        }

        norm: List[Dict[str, Any]] = []
        seen: set[tuple[str, str, str]] = set()

        for e in edges:
            rtype = e.get("relation_type")
            if rtype not in ALLOWED:
                continue
            src, tgt = e.get("src"), e.get("tgt")
            if not src or not tgt or src == tgt:
                continue

            # æ— å‘å…³ç³»è§„èŒƒåŒ–ï¼šåªå­˜ (min, max)
            if rtype in UNDIRECTED and tgt < src:
                src, tgt = tgt, src

            key = (src, rtype, tgt)
            if key in seen:
                continue
            seen.add(key)

            rel_id = "rel_" + hashlib.sha1(f"{src}|{rtype}|{tgt}".encode("utf-8")).hexdigest()[:16]
            norm.append({
                "src_id": src,
                "tgt_id": tgt,
                "rel_id": rel_id,
                "predicate": rtype,
                "relation_name": NAME_ZH[rtype],
                "confidence": float(e.get("confidence") or 0.0),
                "reason": e.get("reason", ""),
            })

        if not norm:
            print("[!] è¿‡æ»¤åæ— å¯å†™å…¥çš„æƒ…èŠ‚å…³ç³»ã€‚")
            return False

        all_created = True
        for rtype in sorted({e["predicate"] for e in norm}):
            subset = [e for e in norm if e["predicate"] == rtype]
            cypher = f"""
            UNWIND $data AS row
            MATCH (p1:Plot {{id: row.src_id}})
            MATCH (p2:Plot {{id: row.tgt_id}})
            MERGE (p1)-[r:{rtype} {{id: row.rel_id}}]->(p2)
            SET r.predicate     = row.predicate,
                r.relation_name = row.relation_name,
                r.confidence    = row.confidence,
                r.reason        = row.reason
            RETURN count(r) AS relationships_created
            """
            try:
                result = self.execute_query(cypher, {"data": subset})
                created = list(result)[0]["relationships_created"]
                if created != len(subset):
                    all_created = False
                    print(f"[!] {rtype} ä»…åˆ›å»º {created}/{len(subset)} æ¡ï¼Œå¯èƒ½å­˜åœ¨èŠ‚ç‚¹ç¼ºå¤±æˆ–å¹¶å‘ç«äº‰ã€‚")
                else:
                    print(f"[âœ“] {rtype} å·²åˆ›å»º {created} æ¡å…³ç³»")
            except Exception as e:
                print(f"[âŒ] åˆ›å»º {rtype} å…³ç³»å¤±è´¥: {e}")
                all_created = False

        return all_created

        
    def create_event_plot_graph(self):
        """
        ç”¨ç™½åå•å…³ç³»åˆ›å»º Event-Plot ä¸“ç”¨ GDS å›¾ï¼š
        - äº‹ä»¶ä¸‰ç±»ï¼šEVENT_CAUSES / EVENT_INDIRECT_CAUSES / EVENT_PART_OF
        - Plot å…­ç±»ï¼šPLOT_PREREQUISITE_FOR / PLOT_ADVANCES / PLOT_BLOCKS / PLOT_RESOLVES / PLOT_CONFLICTS_WITH / PLOT_PARALLELS
        - HAS_EVENT
        """
        # å…ˆåˆ æ—§å›¾
        try:
            self.execute_query("CALL gds.graph.drop('event_plot_graph', false)")
        except Exception:
            pass

        allowed = [
            "EVENT_CAUSES","EVENT_INDIRECT_CAUSES","EVENT_PART_OF",
            "HAS_EVENT",
            "PLOT_PREREQUISITE_FOR","PLOT_ADVANCES","PLOT_BLOCKS","PLOT_RESOLVES",
            "PLOT_CONFLICTS_WITH","PLOT_PARALLELS"
        ]
        types_str = ", ".join(f"\"{t}\"" for t in allowed)

        cypher = f"""
        CALL gds.graph.project.cypher(
        'event_plot_graph',
        'MATCH (n) RETURN id(n) AS id',
        'MATCH (a)-[r]->(b)
        WHERE type(r) IN [{types_str}]
        RETURN id(a) AS source, id(b) AS target'
        );
        """
        self.execute_query(cypher)
        print("âœ… åˆ›å»º Event Plot Graphï¼ˆäº‹ä»¶å› æœ + HAS_EVENT + 6 ç±» Plot è¾¹ï¼‰")




    def write_plot_to_neo4j(self, plot_data: Dict[str, Any]) -> bool:
        """
        å®Œæ•´çš„Plotå†™å…¥åŠŸèƒ½
        
        Args:
            plot_data: Plotæ•°æ®å­—å…¸ï¼ŒåŒ…å«idã€titleã€summaryã€event_idsã€structure
            
        Returns:
            bool: å†™å…¥æ˜¯å¦æˆåŠŸ
        """
        try:
            # 1. åˆ›å»ºPlotèŠ‚ç‚¹
            if not self.create_plot_node(plot_data):
                return False
            
            # 2. åˆ›å»ºHAS_EVENTå…³ç³»
            event_ids = plot_data.get("event_ids", [])
            if event_ids and not self.create_plot_event_relationships(plot_data["id"], event_ids):
                return False
            
            # print(f"æˆåŠŸå†™å…¥Plot: {plot_data['id']}")
            return True
            
        except Exception as e:
            print(f"å†™å…¥Plotåˆ°Neo4jå¤±è´¥: {e}")
            return False
    
    
    def load_connected_components_subgraph(self, node_ids: List[int]) -> tuple[Dict[int, Dict], List[Dict]]:
        """
        ä» Neo4j åŠ è½½ä¸€ä¸ª CC çš„æ‰€æœ‰èŠ‚ç‚¹å’Œè¾¹
        
        Args:
            node_ids: Neo4j å†…éƒ¨èŠ‚ç‚¹ ID åˆ—è¡¨

        Returns:
            - node_map: {nodeId -> å±æ€§å­—å…¸}
            - edges: List of {sid, tid, w, reason}
        """
        # 1. èŠ‚ç‚¹
        cypher_nodes = f"""
        UNWIND $ids AS nid
        MATCH (n) WHERE n.id = nid
        RETURN n.id AS dbid,
                n.id AS eid,
                n.embedding AS emb
        """
        nodes = self.execute_query(cypher_nodes, {"ids": node_ids})
        node_map = {n["dbid"]: n for n in nodes}

        # 2. è¾¹
        cypher_edges = """
        MATCH (u:Event)-[r]->(v:Event)
        WHERE u.id IN $ids AND v.id IN $ids AND type(r) IN ["EVENT_CAUSES","EVENT_INDIRECT_CAUSES","EVENT_PART_OF"]
        RETURN u.id AS sid,
            v.id AS tid,
            coalesce(r.confidence,0.0) AS confidence,
            r.reason AS reason
        """

        edges = self.execute_query(cypher_edges, {"ids": node_ids})
        return node_map, edges
    
    
    def fetch_scc_components(self, graph_name, min_size: int = 0) -> List[List[int]]:
        """
        è°ƒç”¨ GDS çš„ scc.stream è¿”å›å¼ºè¿é€šä½“
        é’ˆå¯¹ size>1 çš„ç»„ä»¶æ‰éœ€è¦æ–­ç¯
        """
        cypher = f"""
        CALL gds.scc.stream('{graph_name}')
        YIELD nodeId, componentId
        WITH gds.util.asNode(nodeId) AS n, componentId
        RETURN componentId,
            collect(n.id) AS nodeIds
        """
        sccs = self.execute_query(cypher)
        sccs = [c["nodeIds"] for c in sccs if len(c["nodeIds"]) >= min_size]
        # print(f"Detected { len(sccs)} SCCs with size>1")
        return sccs

    def fetch_wcc_components(self, graph_name, min_size: int = 0) -> List[List[int]]:
        """
        è°ƒç”¨ GDS çš„ scc.stream è¿”å›å¼ºè¿é€šä½“
        é’ˆå¯¹ size>1 çš„ç»„ä»¶æ‰éœ€è¦æ–­ç¯
        """
        cypher = f"""
        CALL gds.wcc.stream('{graph_name}')
        YIELD nodeId, componentId
        WITH gds.util.asNode(nodeId) AS n, componentId
        RETURN componentId,
            collect(n.id) AS nodeIds
        """
        sccs = self.execute_query(cypher)
        sccs = [c["nodeIds"] for c in sccs if len(c["nodeIds"]) >= min_size]
        # print(f"Detected { len(sccs)} WCCs with size>1")
        return sccs


    def get_plot_statistics(self) -> Dict[str, int]:
        """
        è·å–Plotå›¾è°±ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict[str, int]: ç»Ÿè®¡ä¿¡æ¯
        """
        cypher = f"""
        MATCH (p:Plot)
        OPTIONAL MATCH (p)-[:HAS_EVENT]->(e:Event)
        OPTIONAL MATCH (s:{self.meta['section_label']})-[:{self.meta['contains_pred']}]->(e)
        RETURN count(DISTINCT p) AS plot_count,
               count(DISTINCT e) AS event_count,
               count(DISTINCT s) AS section_count
        """
        
        result = self.execute_query(cypher)
        return dict(list(result)[0])
    
    def get_starting_events(self):
        cypher = """
        MATCH (e:Event)
        WHERE NOT ()-[:EVENT_CAUSES|:EVENT_INDIRECT_CAUSES|:EVENT_PART_OF]->(e)
        RETURN e.id AS event_id
        """

        result = self.execute_query(cypher)
        result = [e["event_id"] for e in result]
        return result
    
    def create_plot_event_relationships(self, plot_id: str, event_ids: List[str]) -> bool:
        """
        åˆ›å»º HAS_EVENT å…³ç³»ï¼Œå¹¶å†™å…¥ä¸­æ–‡å«ä¹‰ relation_name=â€œåŒ…å«äº‹ä»¶â€
        """
        import hashlib

        rel_data = []
        for event_id in event_ids:
            rel_id = "rel_" + hashlib.sha1(f"{plot_id}-HAS_EVENT-{event_id}".encode("utf-8")).hexdigest()[:16]
            rel_data.append({
                "src_id": plot_id,
                "tgt_id": event_id,
                "rel_id": rel_id,
                "predicate": "HAS_EVENT",
                "relation_name": "åŒ…å«äº‹ä»¶",
            })

        cypher = """
        UNWIND $data AS row
        MATCH (p:Plot {id: row.src_id})
        MATCH (e:Event {id: row.tgt_id})
        MERGE (p)-[r:HAS_EVENT {id: row.rel_id}]->(e)
        SET r.predicate     = row.predicate,
            r.relation_name = row.relation_name
        RETURN count(r) AS relationships_created
        """
        try:
            result = self.execute_query(cypher, {"data": rel_data})
            count = list(result)[0]['relationships_created']
            return count == len(event_ids)
        except Exception as e:
            print(f"åˆ›å»º HAS_EVENT å…³ç³»å¤±è´¥: {e}")
            return False



    
    def find_event_chain(self, entity_id: str, min_confidence: float = 0.0):
        """
        ä»æŒ‡å®šèµ·ç‚¹äº‹ä»¶å‡ºå‘ï¼Œè¿”å›æ‰€æœ‰åˆ°â€œç»ˆç‚¹äº‹ä»¶â€çš„è·¯å¾„ã€‚
        ç»ˆç‚¹äº‹ä»¶å®šä¹‰ï¼šåœ¨æ‰€è€ƒè™‘çš„å…³ç³»ç±»å‹ä¸­ä¸å†æœ‰å‡ºè¾¹ã€‚
        ä»…ä¿ç•™æ»¡è¶³ confidence é˜ˆå€¼çš„è¾¹ã€‚

        è€ƒè™‘çš„å…³ç³»ç±»å‹ï¼ˆå«å†å²å…¼å®¹åˆ«åï¼‰ï¼š
        - EVENT_CAUSES / EVENT_CAUSE
        - EVENT_INDIRECT_CAUSE / EVENT_INDIRECT_CAUSES
        - EVENT_PART_OF
        """
        # å…³ç³»ç±»å‹é›†åˆï¼ˆå«æ—§åï¼Œç¡®ä¿å…¼å®¹ï¼‰
        rel_types = [
            "EVENT_CAUSES", "EVENT_INDIRECT_CAUSES", "EVENT_PART_OF"
        ]
        rel_types_str = "|".join(rel_types)

        cypher = f"""
        MATCH path = (start:Event {{id: $entity_id}})-[
            r:{rel_types_str}*
        0..]->(end:Event)
        WHERE
        // è·¯å¾„ä¸Šæ‰€æœ‰å…³ç³»æ»¡è¶³ç½®ä¿¡åº¦é˜ˆå€¼
        ALL(rel IN relationships(path)
            WHERE coalesce(rel.confidence, 0.0) >= $min_confidence)
        // ç»ˆç‚¹ï¼šåœ¨æ‰€è€ƒè™‘çš„å…³ç³»é›†åˆä¸­ä¸å†æœ‰å‡ºè¾¹
        AND NOT (end)-[:{rel_types_str}]->()
        RETURN [n IN nodes(path) | n.id] AS event_chain
        """

        results = self.execute_query(
            cypher,
            {
                "entity_id": entity_id,
                "min_confidence": float(min_confidence)
            }
        )
        return [record["event_chain"] for record in results if "event_chain" in record]

    
    def reset_event_plot_graph(self):
        cypher = """
        MATCH ()-[r]->()
        WHERE type(r) IN [
        "HAS_EVENT",
        "PLOT_PREREQUISITE_FOR","PLOT_ADVANCES","PLOT_BLOCKS","PLOT_RESOLVES",
        "PLOT_CONFLICTS_WITH","PLOT_PARALLELS",
        "PLOT_CONTRIBUTES_TO","PLOT_SETS_UP" // å†å²å…¼å®¹å¯ç•™
        ]
        DELETE r
        """
        self.execute_query(cypher)
        
        cypher = """
        MATCH (p:Plot)
        DETACH DELETE p;
        """
        self.execute_query(cypher)
        print("âœ… Event Plot Graphå·²é‡ç½®")
    
    
    def get_plot_pairs(self, threshold=0):
        """
        å¬å›å€™é€‰æƒ…èŠ‚å¯¹ï¼ˆè¿”å›å­—å…¸è€Œéå…ƒç»„ï¼‰ï¼Œå¹¶å¸¦å›æœ€çŸ­è·¯å¾„é•¿åº¦ï¼š
        - ä»…æ²¿ä»¥ä¸‹è¾¹è”é€šï¼šäº‹ä»¶ä¸‰ç±» + HAS_EVENT + å…­ç±» Plot è¾¹
        - ä¼˜å…ˆé€‰æ‹©è·¯å¾„æ›´çŸ­çš„æƒ…èŠ‚å¯¹
        - æ€»é‡ä¸è¶…è¿‡ 3 Ã— Plot æ•°é‡
        - äºŒæ¬¡è¿‡æ»¤ï¼šæ–‡æœ¬å‘é‡ç›¸ä¼¼åº¦ & node2vec å›¾ç›¸ä¼¼åº¦

        è¿”å›: List[Dict]ï¼Œæ¯é¡¹å½¢å¦‚ {"src": str, "tgt": str, "path_len": int}
        """
        # 1) åªåœ¨ç™½åå•å…³ç³»ä¸Šæ‰¾ 1..5 è·³å†…æœ€çŸ­è·¯å¾„
        cypher = """
        MATCH (p1:Plot), (p2:Plot)
        WHERE id(p1) < id(p2)
        MATCH path = (p1)-[*1..5]-(p2)
        WITH p1, p2, min(length(path)) AS path_len
        RETURN p1.id AS src, p2.id AS tgt, path_len
        """
        results = self.execute_query(cypher)

        # 2) è®¡ç®— Plot æ•° & è®¾ä¸Šé™ï¼ˆå»ºè®®â‰ˆ 3xï¼‰
        plot_cypher = "MATCH (p:Plot) RETURN count(DISTINCT p) AS plot_count"
        res = self.execute_query(plot_cypher)
        num_plots = int(res[0]["plot_count"]) if res else 0
        max_num_relations = num_plots * 3

        # 3) æŒ‰è·¯å¾„é•¿åº¦åˆ†æ¡¶
        pair_maps: Dict[int, List[Dict[str, Any]]] = {}
        for row in results:
            d = int(row["path_len"])
            item = {"src": row["src"], "tgt": row["tgt"], "path_len": d}
            pair_maps.setdefault(d, []).append(item)

        # 4) ä¾æ¬¡ä»çŸ­åˆ°é•¿é€‰å–ï¼Œç›´åˆ°è¾¾åˆ°ä¸Šé™
        import random
        selected_pairs: List[Dict[str, Any]] = []
        count = 0
        for distance in sorted(pair_maps.keys()):
            bucket = pair_maps[distance]
            remain = max_num_relations - count
            if remain <= 0:
                break
            if len(bucket) <= remain:
                selected_pairs.extend(bucket)
                count += len(bucket)
            else:
                selected_pairs.extend(random.sample(bucket, remain))
                count += remain
                break

        # 5) ç›¸ä¼¼åº¦è¿‡æ»¤ï¼ˆæ–‡æœ¬ + å›¾ node2vecï¼‰
        if threshold > 0:
            filtered: List[Dict[str, Any]] = []
            for item in selected_pairs:
                src, tgt = item["src"], item["tgt"]
                # è¿™ä¸¤ä¸ªå‡½æ•°è¿”å› None æ—¶è·³è¿‡è¯¥å¯¹
                sim = self.compute_semantic_similarity(src, tgt)
                gsim = self.compute_graph_similarity(src, tgt, "node2vecEmbedding")
                if sim is None or gsim is None:
                    continue
                if sim >= threshold and gsim >= threshold:
                    filtered.append(item)
        else: 
            filtered = selected_pairs

        return filtered

    
    
    def create_event_plot_graph(self):
        cypher = """
        CALL gds.graph.drop('event_plot_graph', false);
        """
        self.execute_query(cypher) # åˆ é™¤å·²æœ‰çš„å›¾
        
        cypher = """
        CALL gds.graph.project(
        'event_plot_graph',
        {
            Plot: { properties: ['embedding'] },
            Event: { properties: ['embedding'] },
            Character: { properties: ['embedding'] },
            Location: { properties: ['embedding'] },
            Concept: { properties: ['embedding'] },
            Object: { properties: ['embedding'] }
        },
        '*'
        );
        """
        self.execute_query(cypher)
        print("âœ… åˆ›å»º Event Plot Graph")
        
    def run_node2vec(self):
        cypher = """
        CALL gds.node2vec.write(
        'event_plot_graph',
        {
            embeddingDimension: 128,        // å‘é‡ç»´åº¦
            walkLength: 80,                  // æ¯æ¡æ¸¸èµ°è·¯å¾„é•¿åº¦
            walksPerNode: 20,                  // æ¯ä¸ªèŠ‚ç‚¹èµ·ç‚¹çš„æ¸¸èµ°æ¬¡æ•°
            inOutFactor: 1.0,                 // p å‚æ•°ï¼ˆå›è®¿æ¦‚ç‡ï¼‰
            returnFactor: 1.0,                // q å‚æ•°ï¼ˆå‰è¿›æ¦‚ç‡ï¼‰
            concurrency: 4,                   // å¹¶è¡Œçº¿ç¨‹æ•°
            writeProperty: 'node2vecEmbedding' // å†™å›å±æ€§å
        }
        )
        YIELD nodeCount, nodePropertiesWritten;
        """
        self.execute_query(cypher)
        print("âœ… åˆ›å»º Node2Vecå‘é‡è‡³å±æ€§ node2vecEmbedding")
        