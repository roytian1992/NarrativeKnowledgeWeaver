# -*- coding: utf-8 -*-
from __future__ import annotations

"""
sqldb_tools.py
- æä¾›åŸºäº SQLite çš„ CMP_info è¡¨æŸ¥è¯¢å·¥å…·ï¼Œå¹¶æ³¨å†Œä¸º Qwen Agent å¯è°ƒç”¨å·¥å…·ã€‚
- å·¥å…·ï¼š
  1) search_by_character  æŒ‰â€œç›¸å…³è§’è‰²â€æ¨¡ç³Šæ£€ç´¢å®Œæ•´è®°å½•
  2) search_by_scene      æŒ‰â€œåœºæ¬¡å/å­åœºæ¬¡åâ€æ£€ç´¢å®Œæ•´è®°å½•
  3) chunk_to_scene       ç”± chunk_id æ˜ å°„åˆ° åœºæ¬¡å/å­åœºæ¬¡å
  4) scene_to_chunks      ç”±åœºæ¬¡ï¼ˆå¯é€‰å­åœºæ¬¡ï¼‰åˆ—å‡ºæ‰€æœ‰ chunk_id
"""

from typing import List, Dict, Any, Optional, Tuple, Union
import json
import sqlite3

from qwen_agent.tools.base import BaseTool, register_tool
from qwen_agent.utils.utils import logger
from langchain_community.utilities import SQLDatabase
from langchain_experimental.sql.base import SQLDatabaseSequentialChain

# å¦‚æœä½ å·²æœ‰ KAGConfig / OpenAILLMï¼Œå¯åœ¨ __init__ é‡ŒæŒ‰éœ€åˆ‡æ¢
from core.utils.config import KAGConfig
from core.model_providers.openai_llm import OpenAILLM

# â€”â€” åˆ—æ¸…å•ï¼ˆä¸è¡¨ç»“æ„ä¸€è‡´ï¼‰ â€”â€” #
COLUMNS = [
    "åç§°", "ç±»åˆ«", "å­ç±»åˆ«", "å¤–è§‚", "çŠ¶æ€", "ç›¸å…³è§’è‰²",
    "æ–‡ä¸­çº¿ç´¢", "è¡¥å……ä¿¡æ¯", "chunk_id", "åœºæ¬¡", "åœºæ¬¡å", "å­åœºæ¬¡å"
]


def build_cols_sql(conn, table: str, candidate_cols: list[str]) -> str:
    cur = conn.cursor()
    cur.execute(f"PRAGMA table_info('{table}')")
    cols_in_db = {row[1] for row in cur.fetchall()}
    valid_cols = [c for c in candidate_cols if c in cols_in_db]
    return ", ".join([f'"{c}"' for c in valid_cols])


def _parse_sql_from_steps(steps):
    if not steps:
        return None
    for st in steps:
        if isinstance(st, dict) and "sql_cmd" in st:
            return st["sql_cmd"].strip()
        if isinstance(st, str) and st.strip().lower().startswith("select"):
            return st.strip()
    return None


def _format_sql_rows_text(raw):
    if raw is None:
        return "æœªæŸ¥è¯¢åˆ°ç»“æœã€‚"
    if isinstance(raw, str):
        try:
            data = ast.literal_eval(raw)
            if isinstance(data, (list, tuple)) and data and isinstance(data[0], (list, tuple)):
                lines = []
                for row in data:
                    items = [str(x) for x in row]
                    lines.append("- " + "ï¼›".join(items))
                return "æŸ¥è¯¢ç»“æœå¦‚ä¸‹ï¼š\n" + "\n".join(lines)
            return raw
        except Exception:
            return raw
    if isinstance(raw, (list, tuple)):
        if not raw:
            return "æœªæŸ¥è¯¢åˆ°ç»“æœã€‚"
        lines = []
        for row in raw:
            if isinstance(row, (list, tuple)):
                items = [str(x) for x in row]
                lines.append("- " + "ï¼›".join(items))
            else:
                lines.append("- " + str(row))
        return "æŸ¥è¯¢ç»“æœå¦‚ä¸‹ï¼š\n" + "\n".join(lines)
    return str(raw)


# â€”â€” é€šç”¨æ ¼å¼åŒ–ï¼šæŠŠæŸ¥è¯¢ç»“æœè½¬ä¸ºè‡ªç„¶è¯­è¨€ â€”â€” #
def _fmt_kv_line(row: Dict[str, Any], columns: List[str]) -> str:
    items = []
    for c in columns:
        if c in row:
            v = row[c]
            v = "" if v is None else str(v).strip()
            if v != "":
                items.append(f"{c}ï¼š{v}")
    return "ï¼›".join(items)

def format_rows_dicts_to_nl(rows: List[Dict[str, Any]],
                            columns: Optional[List[str]] = None,
                            dedup: bool = True,
                            header: Optional[str] = "æŸ¥è¯¢ç»“æœå¦‚ä¸‹ï¼š") -> str:
    if not rows:
        return "æœªæŸ¥è¯¢åˆ°ç»“æœã€‚"
    if columns is None:
        # ä»¥ COLUMNS ä¸ºä¸»åºï¼Œå†è¡¥å…¶å®ƒé”®
        appeared = set()
        ordered = []
        for c in COLUMNS:
            if any(c in r for r in rows):
                ordered.append(c); appeared.add(c)
        for k in rows[0].keys():
            if k not in appeared:
                ordered.append(k); appeared.add(k)
        columns = ordered

    seen: set[Tuple] = set()
    lines: List[str] = []
    for r in rows:
        line = _fmt_kv_line(r, columns)
        if not line:
            continue
        key = tuple((k, r.get(k, None)) for k in columns)
        if dedup and key in seen:
            continue
        seen.add(key)
        lines.append(f"- {line}")

    if not lines:
        return "æœªæŸ¥è¯¢åˆ°ç»“æœã€‚"
    if header:
        return header + "\n" + "\n".join(lines)
    return "\n".join(lines)

def format_query_result(
    data: Union[List[Dict[str, Any]], None],
    columns: Optional[List[str]] = None,
    header: Optional[str] = "æŸ¥è¯¢ç»“æœå¦‚ä¸‹ï¼š",
) -> str:
    if data is None:
        return "æœªæŸ¥è¯¢åˆ°ç»“æœã€‚"
    if isinstance(data, list) and (not data or isinstance(data[0], dict)):
        return format_rows_dicts_to_nl(data, columns=columns, header=header)
    return "ï¼ˆæ— æ³•è¯†åˆ«çš„ç»“æœç±»å‹ï¼Œæœªèƒ½æ ¼å¼åŒ–ã€‚ï¼‰"

def format_mapping_chunk_to_scene(mapping: Optional[Dict[str, Any]]) -> str:
    """
    ä¸“ç”¨äº chunk_to_sceneï¼šæœŸæœ›å­—æ®µ chunk_id / åœºæ¬¡å / å­åœºæ¬¡å
    """
    if not mapping:
        return "æœªæ‰¾åˆ°è¯¥ chunk_id å¯¹åº”çš„åœºæ¬¡ä¿¡æ¯ã€‚"
    chunk = mapping.get("chunk_id", "")
    scene = mapping.get("åœºæ¬¡å", "")
    sub = mapping.get("å­åœºæ¬¡å", "")
    tail = f"ï¼›å­åœºæ¬¡åï¼š{sub}" if sub else ""
    return f"chunk_idï¼š{chunk} å¯¹åº” åœºæ¬¡åï¼š{scene}{tail}"

def format_scene_to_chunks(scene_name: str,
                           chunks: List[str],
                           subscene_name: Optional[str] = None) -> str:
    """
    ä¸“ç”¨äº scene_to_chunks çš„è¾“å‡º
    """
    if not chunks:
        if subscene_name:
            return f"æœªåœ¨åœºæ¬¡ã€Œ{scene_name}ã€-ã€Œ{subscene_name}ã€ä¸‹æ‰¾åˆ°ä»»ä½• chunk_idã€‚"
        return f"æœªåœ¨åœºæ¬¡ã€Œ{scene_name}ã€ä¸‹æ‰¾åˆ°ä»»ä½• chunk_idã€‚"
    head = f"åœºæ¬¡ã€Œ{scene_name}ã€" + (f" - ã€Œ{subscene_name}ã€" if subscene_name else "")
    lines = "\n".join(f"- {cid}" for cid in chunks)
    return f"{head} å…± {len(chunks)} ä¸ª chunk_idï¼š\n{lines}"


# â€”â€” SQLite åŸºç¡€ â€”â€” #
def get_conn(db_path: str) -> sqlite3.Connection:
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row
    return conn

def rows_to_dicts(rows: List[sqlite3.Row]) -> List[Dict[str, Any]]:
    return [dict(row) for row in rows]

def ensure_indices(conn: sqlite3.Connection, table: str) -> None:
    cur = conn.cursor()
    cur.execute(f'CREATE INDEX IF NOT EXISTS idx_{table}_related_role ON "{table}"("ç›¸å…³è§’è‰²");')
    cur.execute(f'CREATE INDEX IF NOT EXISTS idx_{table}_scene        ON "{table}"("åœºæ¬¡å");')
    cur.execute(f'CREATE INDEX IF NOT EXISTS idx_{table}_subscene     ON "{table}"("å­åœºæ¬¡å");')
    cur.execute(f'CREATE INDEX IF NOT EXISTS idx_{table}_chunk        ON "{table}"("chunk_id");')
    conn.commit()


# â€”â€” 1) æŒ‰è§’è‰²åæ¨¡ç³Šæ£€ç´¢ â€”â€” #
@register_tool("search_by_character")
class Search_By_Character(BaseTool):
    """
    åœ¨ SQLite è¡¨çš„â€œç›¸å…³è§’è‰²â€åˆ—è¿›è¡Œä¸åŒºåˆ†å¤§å°å†™çš„æ¨¡ç³ŠåŒ¹é…ï¼Œè¿”å›æ•´è¡Œä¿¡æ¯ã€‚
    """
    name = "search_by_character"
    description = "åœ¨ CMP_info è¡¨ä¸­æŒ‰â€œç›¸å…³è§’è‰²â€è¿›è¡Œæ¨¡ç³Šæ£€ç´¢ï¼Œè¿”å›åŒ¹é…åˆ°çš„å®Œæ•´è®°å½•ã€‚"
    parameters = [
        {
            "name": "query",
            "type": "string",
            "description": "è§’è‰²åå…³é”®è¯ï¼ˆæ¨¡ç³ŠåŒ¹é…ï¼Œå¤§å°å†™ä¸æ•æ„Ÿï¼‰",
            "required": True
        },
        {
            "name": "limit",
            "type": "integer",
            "description": "æœ€å¤šè¿”å›çš„è®°å½•æ¡æ•°ï¼ˆå¯é€‰ï¼‰",
            "required": False
        }
    ]

    def __init__(self, db_path: str,
                 default_table: str = "CMP_info",
                 build_indices: bool = False):
        self.db_path = db_path
        self.default_table = default_table
        if build_indices:
            conn = get_conn(self.db_path)
            try:
                ensure_indices(conn, self.default_table)
            finally:
                conn.close()
        self.COLS_SQL = build_cols_sql(get_conn(db_path), "CMP_info", COLUMNS)


    def _search_by_character(self, character_keyword: str,
                             limit: Optional[int] = None) -> List[Dict[str, Any]]:
        
        sql = f'''
            SELECT {self.COLS_SQL}
            FROM "{self.default_table}"
            WHERE "ç›¸å…³è§’è‰²" LIKE ? COLLATE NOCASE
            ORDER BY "åœºæ¬¡å","å­åœºæ¬¡å","chunk_id"
        '''
        params: List[Any] = [f"%{character_keyword}%"]
        if limit is not None:
            sql += " LIMIT ?"
            params.append(int(limit))

        conn = get_conn(self.db_path)
        try:
            cur = conn.cursor()
            cur.execute(sql, tuple(params))
            return rows_to_dicts(cur.fetchall())
        finally:
            conn.close()

    def call(self, params: str, **kwargs) -> str:
        logger.info("ğŸ” search_by_character: å¼€å§‹æ‰§è¡Œ SQL æ¨¡ç³Šæ£€ç´¢ï¼ˆç›¸å…³è§’è‰²ï¼‰")
        p: Dict[str, Any] = json.loads(params)
        query = str(p.get("query", "")).strip()
        limit = p.get("limit", None)
        if isinstance(limit, str) and limit.isdigit():
            limit = int(limit)
        elif not isinstance(limit, (int, type(None))):
            limit = None

        rows = self._search_by_character(query, limit=limit)
        return format_query_result(rows, header=f"ä¸ã€Œ{query}ã€ç›¸å…³çš„è®°å½•ï¼š")


# â€”â€” 2) æŒ‰åœºæ¬¡/å­åœºæ¬¡æ£€ç´¢ â€”â€” #
@register_tool("search_by_scene")
class Search_By_Scene(BaseTool):
    """
    æ ¹æ®åœºæ¬¡ï¼ˆå¯é€‰å­åœºæ¬¡ï¼‰è¿”å›æ‰€æœ‰ç›¸å…³ä¿¡æ¯ï¼›æ”¯æŒæ¨¡ç³Š/ç²¾ç¡®åŒ¹é…ã€‚
    """
    name = "search_by_scene"
    description = "åœ¨æŒ‡å®šè¡¨ä¸­æŒ‰â€œåœºæ¬¡åâ€ï¼ˆå¯é€‰â€œå­åœºæ¬¡åâ€ï¼‰æ£€ç´¢å¹¶è¿”å›å®Œæ•´è®°å½•ï¼Œæ”¯æŒæ¨¡ç³ŠåŒ¹é…ã€‚"
    parameters = [
        {
            "name": "scene_name",
            "type": "string",
            "description": "åœºæ¬¡åå…³é”®è¯ï¼ˆæ¨¡ç³Šæˆ–ç²¾ç¡®åŒ¹é…çš„å…³é”®å­—æ®µï¼‰",
            "required": True
        },
        {
            "name": "subscene_name",
            "type": "string",
            "description": "å­åœºæ¬¡åå…³é”®è¯ï¼ˆå¯é€‰ï¼›ä¸åœºæ¬¡åå…±åŒè¿‡æ»¤ï¼‰",
            "required": False
        },
        {
            "name": "fuzzy",
            "type": "boolean",
            "description": "æ˜¯å¦ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…ï¼ˆLIKEï¼‰ã€‚é»˜è®¤ trueã€‚",
            "required": False
        },
        {
            "name": "limit",
            "type": "integer",
            "description": "æœ€å¤šè¿”å›çš„è®°å½•æ¡æ•°ï¼ˆå¯é€‰ï¼‰",
            "required": False
        }
    ]

    def __init__(self, db_path: str,
                 default_table: str = "CMP_info",
                 build_indices: bool = False):
        self.db_path = db_path
        self.default_table = default_table
        if build_indices:
            conn = get_conn(self.db_path)
            try:
                ensure_indices(conn, self.default_table)
            finally:
                conn.close()
        self.COLS_SQL = build_cols_sql(get_conn(db_path), "CMP_info", COLUMNS)

    @staticmethod
    def _build_where(scene_name: str,
                     subscene_name: Optional[str],
                     fuzzy: bool) -> tuple[str, list[Any]]:
        where = []
        params: list[Any] = []
        if fuzzy:
            where.append('"åœºæ¬¡å" LIKE ? COLLATE NOCASE')
            params.append(f"%{scene_name}%")
        else:
            where.append('"åœºæ¬¡å" = ?')
            params.append(scene_name)

        if subscene_name:
            if fuzzy:
                where.append('"å­åœºæ¬¡å" LIKE ? COLLATE NOCASE')
                params.append(f"%{subscene_name}%")
            else:
                where.append('"å­åœºæ¬¡å" = ?')
                params.append(subscene_name)

        return " AND ".join(where) if where else "1=1", params

    def _search_by_scene(self, scene_name: str,
                         subscene_name: Optional[str] = None,
                         fuzzy: bool = True,
                         limit: Optional[int] = None) -> List[Dict[str, Any]]:
        where_sql, params = self._build_where(scene_name, subscene_name, fuzzy)
        sql = f'''
            SELECT {self.COLS_SQL}
            FROM "{self.default_table}"
            WHERE {where_sql}
            ORDER BY "åœºæ¬¡å","å­åœºæ¬¡å","chunk_id"
        '''
        if limit is not None:
            sql += " LIMIT ?"
            params.append(int(limit))

        conn = get_conn(self.db_path)
        try:
            cur = conn.cursor()
            cur.execute(sql, tuple(params))
            return rows_to_dicts(cur.fetchall())
        finally:
            conn.close()

    def call(self, params: str, **kwargs) -> str:
        logger.info("ğŸ¬ search_by_scene: æŒ‰åœºæ¬¡æ£€ç´¢å®Œæ•´è®°å½•")
        p: Dict[str, Any] = json.loads(params)
        scene_name = str(p.get("scene_name", "")).strip()
        subscene_name = (str(p["subscene_name"]).strip()
                         if p.get("subscene_name") not in (None, "") else None)
        fuzzy = True if p.get("fuzzy", True) else False
        limit = p.get("limit", None)
        if isinstance(limit, str) and limit.isdigit():
            limit = int(limit)
        elif not isinstance(limit, (int, type(None))):
            limit = None

        rows = self._search_by_scene(scene_name, subscene_name=subscene_name,
                                     fuzzy=fuzzy, limit=limit)
        head = f"åœºæ¬¡ã€Œ{scene_name}ã€" + (f" - ã€Œ{subscene_name}ã€" if subscene_name else "")
        return format_query_result(rows, header=f"{head} çš„ç›¸å…³è®°å½•ï¼š")


# â€”â€” 3) chunk_id â†’ åœºæ¬¡/å­åœºæ¬¡ â€”â€” #
@register_tool("chunk_to_scene")
class Chunk_To_Scene(BaseTool):
    """
    ä» chunk_id æ˜ å°„åˆ°åœºæ¬¡ï¼šè¿”å› chunk_idã€åœºæ¬¡åã€å­åœºæ¬¡åã€‚
    """
    name = "chunk_to_scene"
    description = "ç»™å®š chunk_idï¼ŒæŸ¥è¯¢å…¶å¯¹åº”çš„ åœºæ¬¡å / å­åœºæ¬¡å æ˜ å°„ã€‚"
    parameters = [
        {
            "name": "chunk_id",
            "type": "string",
            "description": "è¦æŸ¥è¯¢çš„ chunk_idï¼ˆç²¾ç¡®åŒ¹é…ï¼‰",
            "required": True
        }
    ]

    def __init__(self, db_path: str,
                 default_table: str = "CMP_info",
                 build_indices: bool = False):
        self.db_path = db_path
        self.default_table = default_table
        if build_indices:
            conn = get_conn(self.db_path)
            try:
                ensure_indices(conn, self.default_table)
            finally:
                conn.close()

    def _chunk_to_scene(self, chunk_id: str) -> Optional[Dict[str, Any]]:
        sql = f'''
            SELECT "chunk_id","åœºæ¬¡å","å­åœºæ¬¡å"
            FROM "{self.default_table}"
            WHERE "chunk_id" = ?
            LIMIT 1
        '''
        conn = get_conn(self.db_path)
        try:
            cur = conn.cursor()
            cur.execute(sql, (chunk_id,))
            row = cur.fetchone()
            return dict(row) if row else None
        finally:
            conn.close()

    def call(self, params: str, **kwargs) -> str:
        logger.info("ğŸ§­ chunk_to_scene: ç”± chunk_id æ˜ å°„åˆ°åœºæ¬¡")
        p: Dict[str, Any] = json.loads(params)
        chunk_id = str(p.get("chunk_id", "")).strip()
        mapping = self._chunk_to_scene(chunk_id)
        return format_mapping_chunk_to_scene(mapping)


# â€”â€” 4) åœºæ¬¡/å­åœºæ¬¡ â†’ chunk_id åˆ—è¡¨ â€”â€” #
@register_tool("scene_to_chunks")
class Scene_To_Chunks(BaseTool):
    """
    ä»åœºæ¬¡ï¼ˆå¯é€‰å­åœºæ¬¡ï¼‰æ˜ å°„åˆ°æ‰€æœ‰ chunk_idï¼ˆå»é‡ã€æ’åºï¼‰ã€‚
    """
    name = "scene_to_chunks"
    description = "ç»™å®šåœºæ¬¡åï¼ˆå¯é€‰å­åœºæ¬¡åï¼‰ï¼Œåˆ—å‡ºè¯¥èŒƒå›´å†…æ‰€æœ‰ chunk_idã€‚æ”¯æŒæ¨¡ç³ŠåŒ¹é…ã€‚"
    parameters = [
        {
            "name": "scene_name",
            "type": "string",
            "description": "åœºæ¬¡åå…³é”®è¯ï¼ˆæ¨¡ç³Šæˆ–ç²¾ç¡®åŒ¹é…çš„å…³é”®å­—æ®µï¼‰",
            "required": True
        },
        {
            "name": "subscene_name",
            "type": "string",
            "description": "å­åœºæ¬¡åå…³é”®è¯ï¼ˆå¯é€‰ï¼‰",
            "required": False
        },
        {
            "name": "fuzzy",
            "type": "boolean",
            "description": "æ˜¯å¦ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…ï¼ˆLIKEï¼‰ã€‚é»˜è®¤ trueã€‚",
            "required": False
        }
    ]

    def __init__(self, db_path: str,
                 default_table: str = "CMP_info",
                 build_indices: bool = False):
        self.db_path = db_path
        self.default_table = default_table
        if build_indices:
            conn = get_conn(self.db_path)
            try:
                ensure_indices(conn, self.default_table)
            finally:
                conn.close()

    @staticmethod
    def _build_where(scene_name: str,
                     subscene_name: Optional[str],
                     fuzzy: bool) -> tuple[str, list[Any]]:
        where = []
        params: list[Any] = []
        if fuzzy:
            where.append('"åœºæ¬¡å" LIKE ? COLLATE NOCASE')
            params.append(f"%{scene_name}%")
        else:
            where.append('"åœºæ¬¡å" = ?')
            params.append(scene_name)

        if subscene_name:
            if fuzzy:
                where.append('"å­åœºæ¬¡å" LIKE ? COLLATE NOCASE')
                params.append(f"%{subscene_name}%")
            else:
                where.append('"å­åœºæ¬¡å" = ?')
                params.append(subscene_name)

        return " AND ".join(where) if where else "1=1", params

    def _scene_to_chunks(self, scene_name: str,
                         subscene_name: Optional[str] = None,
                         fuzzy: bool = True) -> List[str]:
        where_sql, params = self._build_where(scene_name, subscene_name, fuzzy)
        sql = f'''
            SELECT DISTINCT "chunk_id"
            FROM "{self.default_table}"
            WHERE {where_sql}
            ORDER BY "chunk_id"
        '''
        conn = get_conn(self.db_path)
        try:
            cur = conn.cursor()
            cur.execute(sql, tuple(params))
            return [r["chunk_id"] for r in cur.fetchall()]
        finally:
            conn.close()

    def call(self, params: str, **kwargs) -> str:
        logger.info("ğŸ§© scene_to_chunks: ç”±åœºæ¬¡æ˜ å°„åˆ° chunk åˆ—è¡¨")
        p: Dict[str, Any] = json.loads(params)
        scene_name = str(p.get("scene_name", "")).strip()
        subscene_name = (str(p["subscene_name"]).strip()
                         if p.get("subscene_name") not in (None, "") else None)
        fuzzy = True if p.get("fuzzy", True) else False

        chunks = self._scene_to_chunks(scene_name, subscene_name=subscene_name, fuzzy=fuzzy)
        return format_scene_to_chunks(scene_name, chunks, subscene_name=subscene_name)


@register_tool("nlp2sql_query")
class NLP2SQL_Query(BaseTool):
    """
    ç”¨è‡ªç„¶è¯­è¨€æŸ¥è¯¢ SQLite æ•°æ®åº“ï¼ˆCMP.dbï¼‰ï¼Œè‡ªåŠ¨ç”Ÿæˆ SQL å¹¶æ‰§è¡Œã€‚
    """

    name = "nlp2sql_query"
    description = f"ç”¨è‡ªç„¶è¯­è¨€æé—®æœé¥°ã€åŒ–å¦†ã€é“å…·æ•°æ®åº“ï¼Œè‡ªåŠ¨ç”Ÿæˆå¹¶æ‰§è¡Œ SQLï¼Œè¿”å›è‡ªç„¶è¯­è¨€ç»“æœï¼ˆå¯é€‰é™„å¸¦ SQLï¼‰ã€‚è¯¥æ•°æ®åº“çš„åˆ—åcolumn namesæœ‰ï¼š{COLUMNS}"
    parameters = [
        {
            "name": "query",
            "type": "string",
            "description": "è‡ªç„¶è¯­è¨€æŸ¥è¯¢æ–‡æœ¬",
            "required": True
        },
        {
            "name": "return_sql",
            "type": "boolean",
            "description": "æ˜¯å¦åœ¨ç»“æœä¸­é™„å¸¦ç”Ÿæˆçš„ SQL è¯­å¥ï¼Œé»˜è®¤ false",
            "required": False
        }
    ]

    def __init__(self,
                 db_path, llm, instruction="åœ¨å¤„ç†æŸ¥è¯¢æ—¶ï¼Œä¸è¦åªåšç²¾ç¡®åŒ¹é…ï¼Œåº”åŒæ—¶è€ƒè™‘å­—ç¬¦ä¸²åŒ…å«ã€åŒä¹‰è¯æ‰©å±•æˆ–è¯­ä¹‰ç›¸ä¼¼åº¦ç­‰æ–¹å¼æ¥è¦†ç›–ç›¸å…³ç»“æœã€‚"):
        self.db_path = db_path
        self.db = SQLDatabase.from_uri(f"sqlite:///{self.db_path}")
        self.llm = llm
        self.instruction = instruction

        # åˆå§‹åŒ– SQL chainï¼ˆå›ºå®šå‚æ•°ï¼‰
        self.chain = SQLDatabaseSequentialChain.from_llm(
            llm=self.llm,
            db=self.db,
            verbose=False,
            return_direct=True,
            return_intermediate_steps=True,
            top_k=10000,
            use_query_checker=True
        )

    def call(self, params: str, **kwargs) -> str:
        logger.info("ğŸ§  nl2psql_query: è‡ªç„¶è¯­è¨€è½¬ SQL + æ‰§è¡Œ")
        p = json.loads(params)
        query = str(p.get("query", "")).strip()

        if not query:
            return "è¯·æä¾› queryã€‚"
        if self.instruction:
            query += "\n" + self.instruction

        return_sql = bool(p.get("return_sql", False))

        try:
            out = self.chain.invoke(query)
            result = out.get("result", "")
            steps = out.get("intermediate_steps", None)
            sql_cmd = _parse_sql_from_steps(steps)

            nl = _format_sql_rows_text(result)
            parts = [f"â—¼ï¸ è‡ªç„¶è¯­è¨€ç»“æœï¼š\n{nl}"]
            if return_sql and sql_cmd:
                parts.append(f"â—¼ï¸ ç”Ÿæˆçš„ SQLï¼š\n```sql\n{sql_cmd}\n```")
            return "\n\n".join(parts)
        except Exception as e:
            logger.exception("nl2sql_query æ‰§è¡Œå¤±è´¥")
            return f"æŸ¥è¯¢æ‰§è¡Œå¤±è´¥ï¼š{type(e).__name__}: {e}"
        

