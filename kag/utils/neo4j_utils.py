"""
Neo4jæ•°æ®åº“æ“ä½œå·¥å…·ç±»
æä¾›å¯æ‰©å±•çš„æŸ¥è¯¢æ¥å£ï¼Œä¾¿äºåç»­æ·»åŠ æ–°çš„æŸ¥è¯¢åŠŸèƒ½
"""

from typing import List, Optional, Union, Tuple, Dict, Any, Set
import json
import networkx as nx
from neo4j import Driver
from community import best_partition
from kag.models.entities import Entity, Relation
from sentence_transformers import SentenceTransformer
from tqdm import tqdm
# from kag.builder.kg_builder_2 import DOC_TYPE_META


DOC_TYPE_META: Dict[str, Dict[str, str]] = {
    "screenplay": {
        "section_label": "Scene",
        "title": "scene_name",
        "subtitle_key": "sub_scene_name",
        "contains_pred": "SCENE_CONTAINS",
    },
    "novel": {
        "section_label": "Chapter",
        "title": "chapter_name",
        "subtitle": "sub_chapter_name",
        "contains_pred": "CHAPTER_CONTAINS",
    },
}

class Neo4jUtils:
    """
    Neo4jæ•°æ®åº“æ“ä½œå·¥å…·ç±»
    è®¾è®¡åŸåˆ™ï¼š
    1. åŸºç¡€æŸ¥è¯¢æ–¹æ³•å¯å¤ç”¨
    2. æ”¯æŒåŠ¨æ€CypheræŸ¥è¯¢æ„å»º
    3. ä¾¿äºåç»­æ·»åŠ æ–°çš„æŸ¥è¯¢åŠŸèƒ½
    4. æŸ¥è¯¢ç»“æœæ ‡å‡†åŒ–å¤„ç†
    """
    
    def __init__(self, driver: Driver, doc_type: str = "screenplay"):
        """
        åˆå§‹åŒ–Neo4jå·¥å…·ç±»
        
        Args:
            driver: Neo4jè¿æ¥é©±åŠ¨
        """
        if doc_type not in DOC_TYPE_META:
            raise ValueError(f"Unsupported doc_type: {doc_type}")
        self.doc_type = doc_type
        self.meta = DOC_TYPE_META[doc_type]
        
        self.driver = driver
        self.model = None
        self.embedding_field = "embedding"
        self.dim = 768
        
    def load_emebdding_model(self, model_name):
        self.model = SentenceTransformer(model_name)
        self.dim = self.model.get_sentence_embedding_dimension()
        print("å‘é‡æ¨¡å‹å·²åŠ è½½")
    
    def execute_query(self, cypher: str, params: Dict[str, Any] = None) -> List[Dict]:
        """
        æ‰§è¡Œè‡ªå®šä¹‰CypheræŸ¥è¯¢çš„é€šç”¨æ–¹æ³•
        
        Args:
            cypher: CypheræŸ¥è¯¢è¯­å¥
            params: æŸ¥è¯¢å‚æ•°
            
        Returns:
            æŸ¥è¯¢ç»“æœåˆ—è¡¨
        """
        if params is None:
            params = {}
            
        with self.driver.session() as session:
            result = session.run(cypher, params)
            return [dict(record) for record in result]
        
    def search_entities_by_type(
        self,
        entity_type: Optional[str] = None,
        keyword: Optional[str] = None
    ) -> List[Entity]:
        """
        æœç´¢å›¾ä¸­æ‰€æœ‰æ»¡è¶³ç±»å‹å’Œå…³é”®è¯çš„å®ä½“ï¼ˆå¯é€‰è¿‡æ»¤ï¼‰
        
        Args:
            entity_type: å®ä½“ç±»å‹ï¼ˆå¦‚ "Character", "Concept", "Object"ï¼Œä¼  None è¡¨ç¤ºä¸é™åˆ¶ï¼‰
            keyword: å¯é€‰åç§°å…³é”®è¯ï¼ˆæ¨¡ç³ŠåŒ¹é… name æˆ– aliasesï¼‰
            limit: è¿”å›ç»“æœä¸Šé™
            
        Returns:
            List[Entity]
        """
        if self.driver is None:
            return []

        cypher_template = f"""
        MATCH (e:{entity_type if entity_type else ''})
        {{where_clause}}
        RETURN DISTINCT e
        """

        # åŠ¨æ€æ‹¼æ¥ WHERE å­å¥
        where_clauses = []
        params = {}

        if entity_type:
            where_clauses.append("e.type = $etype")
            params["etype"] = entity_type

        if keyword:
            where_clauses.append(
                "(e.name CONTAINS $kw OR any(alias IN e.aliases WHERE alias CONTAINS $kw))"
            )
            params["kw"] = keyword

        where_clause = ""
        if where_clauses:
            where_clause = "WHERE " + " AND ".join(where_clauses)

        cypher = cypher_template.format(where_clause=where_clause)

        # æ‰§è¡ŒæŸ¥è¯¢
        with self.driver.session() as session:
            result = session.run(cypher, params)
            entities = []
            for record in result:
                data = record["e"]
                entities.append(self._build_entity_from_data(data))
            return entities

    
    def search_related_entities(
        self,
        source_id: str,
        predicate: Optional[str] = None,
        relation_types: Optional[List[str]] = None,
        entity_types: Optional[List[str]] = None,
        limit: Optional[int] = None,
        return_relations: bool = False
    ) -> Union[List[Entity], List[Tuple[Entity, Relation]]]:
        """
        æœç´¢ä¸æŒ‡å®šå®ä½“ç›¸å…³çš„å®ä½“ï¼Œå¯æŒ‰å…³ç³»ç±»å‹ã€è°“è¯ã€ç›®æ ‡å®ä½“ç±»å‹è¿‡æ»¤

        Args:
            source_id: æºå®ä½“ ID
            predicate: å…³ç³»è°“è¯è¿‡æ»¤ï¼ˆrel.predicateï¼‰
            relation_types: å…³ç³»ç±»å‹æ ‡ç­¾åˆ—è¡¨ï¼ˆCypher ä¸­çš„ :TYPE æ ‡ç­¾ï¼‰
            entity_types: ç›®æ ‡å®ä½“ç±»å‹è¿‡æ»¤ï¼ˆtarget.typeï¼‰
            limit: è¿”å›æ•°é‡é™åˆ¶ï¼ˆå¯é€‰ï¼Œä¸ä¼ åˆ™ä¸é™åˆ¶ï¼‰
            return_relations: æ˜¯å¦è¿”å› (å®ä½“, å…³ç³») å¯¹

        Returns:
            å®ä½“åˆ—è¡¨æˆ–å®ä½“-å…³ç³»å…ƒç»„åˆ—è¡¨
        """
        if self.driver is None:
            return []

        params: Dict[str, any] = {"source_id": source_id}
        if predicate:
            params["predicate"] = predicate
        if relation_types:
            params["rel_types"] = relation_types
        if entity_types:
            params["etypes"] = entity_types
        if limit:
            params["limit"] = limit

        # æ„é€  Cypher è¿‡æ»¤å­å¥
        predicate_filter = "AND rel.predicate = $predicate" if predicate else ""
        type_filter = "AND target.type IN $etypes" if entity_types else ""
        rel_type_filter = "AND type(rel) IN $rel_types" if relation_types else ""
        limit_clause = "LIMIT $limit" if limit else ""

        results = []

        with self.driver.session() as session:
            # æ­£å‘è¾¹æŸ¥è¯¢
            forward_cypher = f"""
            MATCH (source)-[rel]->(target)
            WHERE source.id = $source_id
            AND rel.predicate IS NOT NULL
            {predicate_filter}
            {rel_type_filter}
            {type_filter}
            RETURN target, rel
            {limit_clause}
            """

            for record in session.run(forward_cypher, params):
                entity, relation = self._process_entity_relation_record(record, source_id, "forward")
                results.append((entity, relation) if return_relations else entity)

            # åå‘è¾¹æŸ¥è¯¢
            backward_cypher = f"""
            MATCH (target)-[rel]->(source)
            WHERE source.id = $source_id
            AND rel.predicate IS NOT NULL
            {predicate_filter}
            {rel_type_filter}
            {type_filter}
            RETURN target, rel
            {limit_clause}
            """

            for record in session.run(backward_cypher, params):
                entity, relation = self._process_entity_relation_record(record, source_id, "backward")
                results.append((entity, relation) if return_relations else entity)

        return results

    
    def get_entity_by_id(self, entity_id: str) -> Optional[Entity]:
        """
        æ ¹æ® ID ç²¾å‡†æŸ¥æ‰¾ä¸€ä¸ªå®ä½“èŠ‚ç‚¹ï¼ˆå…¼å®¹æ‰€æœ‰æ ‡ç­¾ï¼‰
        
        Args:
            entity_id: å®ä½“çš„å”¯ä¸€ IDï¼ˆä¾‹å¦‚ "entity_123456"ï¼‰
            
        Returns:
            åŒ¹é…çš„ Entity å¯¹è±¡ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å› None
        """
        cypher = """
        MATCH (e)
        WHERE e.id = $entity_id
        RETURN e
        LIMIT 1
        """
        params = {"entity_id": entity_id}

        with self.driver.session() as session:
            result = session.run(cypher, params)
            record = result.single()
            if not record:
                return None

            data = record["e"]
            return self._build_entity_from_data(data)
        
        
    def delete_relation_by_ids(
        self,
        source_id: str,
        target_id: str,
        relation_type: str
    ) -> bool:
        """
        æ ¹æ® source_idã€target_id å’Œ relation_type åˆ é™¤æŒ‡å®šå…³ç³»

        Args:
            source_id: æºå®ä½“çš„ ID
            target_id: ç›®æ ‡å®ä½“çš„ ID
            relation_type: è¦åˆ é™¤çš„å…³ç³»ç±»å‹ï¼ˆå¦‚ "EVENT_CAUSES"ï¼‰

        Returns:
            bool: æ˜¯å¦æˆåŠŸåˆ é™¤äº†å…³ç³»ï¼ˆTrue è¡¨ç¤ºè‡³å°‘åˆ é™¤äº†ä¸€æ¡ï¼‰
        """
        cypher = f"""
        MATCH (s)-[r:{relation_type}]->(t)
        WHERE s.id = $source_id AND t.id = $target_id
        DELETE r
        RETURN COUNT(r) AS deleted_count
        """
        params = {"source_id": source_id, "target_id": target_id}

        with self.driver.session() as session:
            result = session.run(cypher, params)
            record = result.single()
            return record and record["deleted_count"] > 0


    def list_relationship_types(self) -> List[str]:
        """
        è·å– Neo4j å›¾æ•°æ®åº“ä¸­å·²å­˜åœ¨çš„æ‰€æœ‰å…³ç³»ç±»å‹
        
        Returns:
            å…³ç³»ç±»å‹åç§°åˆ—è¡¨ï¼ˆå»é‡ã€æŒ‰å­—æ¯æ’åºï¼‰
        """
        cypher = """
        CALL db.relationshipTypes() YIELD relationshipType
        RETURN relationshipType
        ORDER BY relationshipType
        """

        with self.driver.session() as session:
            result = session.run(cypher)
            rel_types = [record["relationshipType"] for record in result]

        return rel_types
    
    def list_entity_types(self) -> List[str]:
        """
        è·å– Neo4j å›¾æ•°æ®åº“ä¸­å·²å­˜åœ¨çš„æ‰€æœ‰å®ä½“ç±»å‹ï¼ˆèŠ‚ç‚¹æ ‡ç­¾ï¼‰

        Returns:
            å®ä½“ç±»å‹åç§°åˆ—è¡¨ï¼ˆå»é‡ã€æŒ‰å­—æ¯æ’åºï¼‰
        """
        cypher = """
        CALL db.labels() YIELD label
        RETURN label
        ORDER BY label
        """
        with self.driver.session() as session:
            result = session.run(cypher)
            labels = [record["label"] for record in result]
        if "*" in labels:
            labels.remove("*")
        return labels


    def get_relation_summary(self, src_id: str, tgt_id: str, relation_type: str=None) -> Optional[str]:
        """
        ç›´æ¥åœ¨ Neo4j ä¸­æŸ¥æ‰¾ src_id åˆ° tgt_id ä¹‹é—´çš„ç‰¹å®šå…³ç³»ï¼Œå¹¶è¿”å›æ ¼å¼åŒ–æè¿°
        
        Args:
            src_id: æºå®ä½“ ID
            tgt_id: ç›®æ ‡å®ä½“ ID
            relation_type: å…³ç³»ç±»å‹ï¼ˆå¦‚ "EVENT_CAUSES"ï¼‰
        
        Returns:
            æ ¼å¼åŒ–æè¿°å­—ç¬¦ä¸²æˆ– None
        """
        cypher = f"""
        MATCH (s {{id: $src_id}})-[r:{relation_type}]->(t {{id: $tgt_id}})
        RETURN r, s.id AS source_id, t.id AS target_id
        LIMIT 1
        """
        results = self.execute_query(cypher, {"src_id": src_id, "tgt_id": tgt_id})

        if not results:
            return None

        record = results[0]
        relation = record["r"]
        description = ""
        subject_name = self.get_entity_by_id(src_id).name
        subject_description = self.get_entity_by_id(src_id).description
        object_name = self.get_entity_by_id(tgt_id).name
        object_description = self.get_entity_by_id(tgt_id).description
        if relation_type == "EVENT_CAUSES":
            if relation.get("reason", ""):
                description = " ç†ç”±: " + str(relation.get("reason"))
            return f"{src_id} --> {tgt_id}\n{subject_description}-->{object_description}{description}"
            
        relation_name = relation.get("relation_name", relation.get("predicate", relation_type))
        description = ":" + relation.get("description", "æ— ç›¸å…³æè¿°")
        return f"{subject_name}({subject_description})-{relation_name}->{object_name}({object_description}){description}"


    def delete_relation_type(self, relation_type):
        print(f"ğŸ§¹ æ­£åœ¨æ¸…é™¤å·²æœ‰çš„ {relation_type} å…³ç³»...")
        self.execute_query(f"""
            MATCH ()-[r:{relation_type}]->()
            DELETE r
        """)
        print(f"âœ… å·²åˆ é™¤æ‰€æœ‰ {relation_type} å…³ç³»")
        

    def has_path_between(
        self, 
        src_id: str, 
        dst_id: str, 
        max_depth: int = 5, 
        allowed_rels: Optional[List[str]] = None
    ) -> bool:
        """
        åˆ¤æ–­å›¾ä¸­æ˜¯å¦å­˜åœ¨ä» src åˆ° dst çš„è·¯å¾„ï¼Œä»…å…è®¸ä½¿ç”¨ç™½åå•ä¸­æŒ‡å®šçš„è¾¹ç±»å‹
        
        Args:
            src_id: æºå®ä½“ID
            dst_id: ç›®æ ‡å®ä½“ID
            max_depth: æœ€å¤§è·¯å¾„æ·±åº¦
            allowed_rels: å…è®¸çš„å…³ç³»ç±»å‹ï¼ˆå¦‚ ['follows', 'supports']ï¼‰
            
        Returns:
            æ˜¯å¦å­˜åœ¨è·¯å¾„
        """
        if not allowed_rels:
            print("âš ï¸ æ²¡æœ‰æŒ‡å®š allowed_rels ç™½åå•ï¼ŒæŸ¥è¯¢å¯èƒ½æ— æ„ä¹‰")
            return False

        # ç”¨å†’å·æ‹¼æ¥ï¼š:rel1|rel2|rel3
        rel_pattern = ":" + "|".join(allowed_rels)

        cypher = f"""
        MATCH p = (src {{id: $src}})-[{rel_pattern}*1..{max_depth}]-(dst {{id: $dst}})
        WHERE src.id <> dst.id
        RETURN count(p) > 0 AS connected
        """

        try:
            with self.driver.session() as session:
                result = session.run(
                    cypher,
                    {"src": src_id, "dst": dst_id}
                ).single()
                return result["connected"] if result else False
        except Exception as e:
            print(f"[Neo4j] has_path_between (whitelist mode) æ‰§è¡Œå¤±è´¥: {e}")
            return False


    def _build_entity_from_data(self, data) -> Entity:
        """
        ä»Neo4jæŸ¥è¯¢ç»“æœæ„å»ºEntityå¯¹è±¡
        
        Args:
            data: Neo4jèŠ‚ç‚¹æ•°æ®
            
        Returns:
            Entityå¯¹è±¡
        """
        return Entity(
            id=data["id"],
            name=data["name"],
            type=data.get("type", "Unknown"),
            aliases=data.get("aliases", []),
            description=data.get("description", ""),
            properties=json.loads(data.get("properties", "{}")),
            source_chunks=data.get("source_chunks", []),
        )

    def _process_entity_relation_record(
        self, 
        record, 
        source_id: str, 
        direction: str
    ) -> Tuple[Entity, Relation]:
        """
        å¤„ç†å®ä½“-å…³ç³»æŸ¥è¯¢è®°å½•
        
        Args:
            record: Neo4jæŸ¥è¯¢è®°å½•
            source_id: æºå®ä½“ID
            direction: å…³ç³»æ–¹å‘ ("forward" æˆ– "backward")
            
        Returns:
            (Entity, Relation)å…ƒç»„
        """
        data = record["target"]
        rel = record["rel"]
        # print("[CHECL] rel.type: ", rel.type )
        
        entity = self._build_entity_from_data(data)
        # print("[CHECK] rel: ", [k for k in rel])
        predicate = rel.get("predicate", rel.type)
        
        if direction == "forward":
            relation_id_str = f"{source_id}_{predicate}_{data["id"]}"
        else:
            relation_id_str = f"{data["id"]}_{predicate}_{source_id}"
            
        rel_id = f"rel_{hash(relation_id_str) % 1000000}"
        
        
        if direction == "forward":
            relation = Relation(
                id=rel.get("id", rel_id),
                subject_id=source_id,
                predicate=predicate,
                object_id=data["id"],
                source_chunks=rel.get("source_chunks", []),
                properties=json.loads(rel.get("properties", "{}")),
            )
        else:  # backward
            relation = Relation(
                id=rel.get("id", rel_id),
                subject_id=data["id"],
                predicate=predicate,
                object_id=source_id,
                source_chunks=rel.get("source_chunks", []),
                properties=json.loads(rel.get("properties", "{}")),
            )
        
        return entity, relation
    
    
    def encode_node_embedding(self, node: Dict) -> List[float]:
        name = node.get("name", "")
        desc = node.get("description", "")
        props = node.get("properties", "")
        try:
            props_dict = json.loads(props) if isinstance(props, str) else props
        except Exception:
            props_dict = {}

        # æ„é€ åµŒå…¥è¾“å…¥
        if props_dict:
            prop_text = "ï¼›".join([f"{k}ï¼š{v}" for k, v in props_dict.items()])
            text = f"{name}ï¼š{desc}ã€‚{prop_text}"
        else:
            text = f"{name}ï¼š{desc}"
        return self.model.encode(text, normalize_embeddings=True).tolist()

    def encode_relation_embedding(self, rel: Dict) -> Optional[List[float]]:
        try:
            props = rel.get("properties", "")
            props_dict = json.loads(props) if isinstance(props, str) else props
            desc = props_dict.get("description", "")
            if desc:
                return self.model.encode(desc, normalize_embeddings=True).tolist()
        except Exception:
            pass
        return None
    
    def fetch_all_nodes(self, node_types: List[str]) -> List[Dict]:
        results = []
        with self.driver.session() as session:
            for label in node_types:
                query = f"""
                MATCH (e:{label})
                RETURN labels(e) AS labels, e.id AS id, e.name AS name, e.description AS description, e.properties AS properties
                """
                res = session.run(query)
                results.extend([r.data() for r in res])
        return results

    def fetch_all_relations(self, relation_types: Optional[List[str]] = None) -> List[Dict]:
        """
        è·å–å›¾ä¸­æ‰€æœ‰å…³ç³»ï¼Œæ”¯æŒæŒ‰å…³ç³»ç±»å‹ï¼ˆpredicateï¼‰è¿‡æ»¤ã€‚

        Args:
            relation_types: è¦ä¿ç•™çš„å…³ç³»ç±»å‹åˆ—è¡¨ï¼ˆå¦‚ ["happens_at", "causes"]ï¼‰
                            è‹¥ä¸º Noneï¼Œåˆ™è¿”å›æ‰€æœ‰å…³ç³»

        Returns:
            æ¯æ¡è¾¹çš„æ•°æ®å­—å…¸ï¼Œå­—æ®µåŒ…æ‹¬ predicateã€idã€properties
        """
        with self.driver.session() as session:
            if relation_types:
                predicate_filter = ", ".join([f"'{r}'" for r in relation_types])
                query = f"""
                MATCH ()-[r]->()
                WHERE type(r) IN [{predicate_filter}]
                RETURN type(r) AS predicate, r.id AS id, r.properties AS properties
                """
            else:
                query = """
                MATCH ()-[r]->()
                RETURN type(r) AS predicate, r.id AS id, r.properties AS properties
                """

            result = session.run(query)
            return [record.data() for record in result]

        
    def update_node_embedding(self, node_id: str, embedding: List[float]) -> None:
        with self.driver.session() as session:
            session.run(f"""
            MATCH (e) WHERE e.id = $id
            SET e.{self.embedding_field} = $embedding
            """, id=node_id, embedding=embedding)
            
    def update_relation_embedding(self, rel_id: str, embedding: List[float]) -> None:
        with self.driver.session() as session:
            session.run(f"""
            MATCH ()-[r]->() WHERE r.id = $id
            SET r.{self.embedding_field} = $embedding
            """, id=rel_id, embedding=embedding)
    
    def process_all_embeddings(self, exclude_entity_types: List[str] = [], exclude_relation_types: List[str] = []):
        """
        è‡ªåŠ¨å¤„ç†æ‰€æœ‰èŠ‚ç‚¹æ ‡ç­¾å’Œæ‰€æœ‰è¾¹ï¼Œä¸ºå…¶ç”Ÿæˆ embedding å¹¶å†™å›å›¾æ•°æ®åº“ã€‚
        èŠ‚ç‚¹ embedding è¾“å…¥ï¼šname + description (+ properties)
        è¾¹ embedding è¾“å…¥ï¼šproperties.description
        """
        # === è·å–æ‰€æœ‰å®ä½“ç±»å‹ï¼ˆæ ‡ç­¾ï¼‰ ===
        entity_types = self.list_entity_types()

        # === å¤„ç†èŠ‚ç‚¹åµŒå…¥ ===
        print("ğŸš€ å¼€å§‹å¤„ç†èŠ‚ç‚¹åµŒå…¥...")
        for node in exclude_entity_types:
            if node in entity_types:
                entity_types.remove(node)
                
        print(f"ğŸ“Œ å®ä½“ç±»å‹æ ‡ç­¾: {entity_types}")
        nodes = self.fetch_all_nodes(entity_types)
        for n in  tqdm(nodes, desc="Encoding Nodes", ncols=80):
            try:
                emb = self.encode_node_embedding(n)
                self.update_node_embedding(n["id"], emb)
            except Exception as e:
                print(f"âš ï¸ Node {n.get('id')} embedding failed:", str(e))

        print(f"âœ… èŠ‚ç‚¹åµŒå…¥å®Œæˆï¼Œå…±å¤„ç† {len(nodes)} ä¸ªèŠ‚ç‚¹")
                
    def ensure_entity_superlabel(self):
        """
        ä¸ºæ‰€æœ‰å…·æœ‰ embedding çš„èŠ‚ç‚¹æ·»åŠ è¶…æ ‡ç­¾ :Entityï¼ˆè·³è¿‡å·²å­˜åœ¨æ ‡ç­¾ï¼‰
        """
        query = """
        MATCH (n)
        WHERE n.embedding IS NOT NULL AND NOT 'Entity' IN labels(n)
        SET n:Entity
        """
        with self.driver.session() as session:
            session.run(query)
            print("[âœ“] å·²ä¸ºæ‰€æœ‰å« embedding çš„èŠ‚ç‚¹æ·»åŠ è¶…æ ‡ç­¾ :Entity")

    def create_vector_index(self, index_name="entityEmbeddingIndex", similarity="cosine"):
        """
        åˆ é™¤å·²æœ‰åŒåç´¢å¼•å¹¶é‡å»ºç»Ÿä¸€å‘é‡ç´¢å¼•
        """

        with self.driver.session() as session:
            # DROP index if existsï¼ˆ5.x è¯­æ³•ï¼‰
            session.run(f"DROP INDEX {index_name} IF EXISTS")
            print(f"[âœ“] å·²åˆ é™¤æ—§ç´¢å¼• {index_name}ï¼ˆå¦‚å­˜åœ¨ï¼‰")

            # åˆ›å»ºæ–°ç´¢å¼•ï¼ˆæ ‡å‡† Cypher è¯­æ³•ï¼Œç¤¾åŒºç‰ˆå…¼å®¹ï¼‰
            session.run(f"""
            CREATE VECTOR INDEX {index_name}
            FOR (n:Entity)
            ON (n.embedding)
            OPTIONS {{
              indexConfig: {{
                `vector.dimensions`: {self.dim},
                `vector.similarity_function`: '{similarity}'
              }}
            }}
            """)
            print(f"[âœ“] å·²åˆ›å»ºæ–°å‘é‡ç´¢å¼• {index_name} on :Entity(embedding)")

    def _query_entity_knn(self, embedding: list, top_k: int = 5):
        """
        æŸ¥è¯¢ä¸è¾“å…¥ embedding å‘é‡æœ€ç›¸ä¼¼çš„ top-K èŠ‚ç‚¹
        """
        query = """
        CALL db.index.vector.queryNodes('entityEmbeddingIndex', $top_k, $embedding)
        YIELD node, score
        RETURN node.name AS name, labels(node) AS labels, node.id AS id, score
        ORDER BY score DESC
        """

        with self.driver.session() as session:
            result = session.run(query, {"embedding": embedding, "top_k": top_k})
            return result.data()

    def query_similar_entities(self, text: str, top_k: int = 5, normalize: bool = True):
        """
        ç»™å®šè‡ªç„¶è¯­è¨€ `text`ï¼Œè‡ªåŠ¨ç¼–ç ä¸º embeddingï¼ŒæŸ¥è¯¢æœ€ç›¸ä¼¼çš„å®ä½“èŠ‚ç‚¹ï¼ˆä½¿ç”¨ entityEmbeddingIndexï¼‰

        Args:
            text (str): æŸ¥è¯¢æ–‡æœ¬ï¼ˆå¦‚å®ä½“åã€äº‹ä»¶ç‰‡æ®µç­‰ï¼‰
            model: ä½ çš„ embedding æ¨¡å‹ï¼ˆéœ€æœ‰ encode æ–¹æ³•ï¼‰
            top_k (int): è¿”å›å‰ top-k ä¸ªç»“æœ
            normalize (bool): æ˜¯å¦æ ‡å‡†åŒ–å‘é‡ï¼ˆç¡®ä¿åŒ¹é… cosine ç´¢å¼•ï¼‰

        Returns:
            List[Dict]: åŒ…å« nameã€labelsã€idã€score çš„ç»“æœåˆ—è¡¨
        """
        embed = self.model.encode(text, normalize_embeddings=normalize).tolist()
        return self._query_entity_knn(embed, top_k=top_k)
    
    
    def compute_semantic_similarity(self, node_id_1, node_id_2):
        query = f"""
        MATCH (a {{id: '{node_id_1}'}}), (b {{id: '{node_id_2}'}})                                          
        RETURN gds.similarity.cosine(a.embedding, b.embedding) AS similarity
        """
        result = self.execute_query(query)
        return result[0].get("similarity")
    
    def check_nodes_reachable(
        self,
        src_id: str,
        dst_id: str,
        max_depth: int = 3,
        excluded_rels: Optional[List[str]] = None
    ) -> bool:
        """
        åˆ¤æ–­ä¸¤ä¸ªä»»æ„èŠ‚ç‚¹ä¹‹é—´æ˜¯å¦å­˜åœ¨è·¯å¾„ï¼Œé•¿åº¦ä¸è¶…è¿‡ max_depthï¼Œä¸”ä¸åŒ…å«æŸäº›å…³ç³»ç±»å‹
        
        Args:
            src_id: èµ·ç‚¹èŠ‚ç‚¹ ID
            dst_id: ç»ˆç‚¹èŠ‚ç‚¹ ID
            max_depth: æœ€å¤§å…è®¸çš„è·¯å¾„æ·±åº¦
            excluded_rels: è¦æ’é™¤çš„å…³ç³»ç±»å‹åˆ—è¡¨ï¼ˆå¦‚ ["SCENE_CONTAINS"]ï¼‰
            
        Returns:
            æ˜¯å¦å¯è¾¾ï¼ˆTrue/Falseï¼‰
        """
        rel_filter = ""
        if excluded_rels:
            # æ„é€ è¿‡æ»¤è°“è¯ï¼štype(r) <> 'X' AND type(r) <> 'Y' ...
            rel_filter = " AND ".join([f"type(r) <> '{rel}'" for rel in excluded_rels])
            rel_filter = f"WHERE ALL(r IN relationships(p) WHERE {rel_filter})"

        query = f"""
        MATCH (n1 {{id: $src_id}}), (n2 {{id: $dst_id}})
        RETURN EXISTS {{
            MATCH p = (n1)-[*1..{max_depth}]-(n2)
            {rel_filter}
        }} AS reachable
        """
        result = self.execute_query(query, {"src_id": src_id, "dst_id": dst_id})
        if result and isinstance(result, list):
            return result[0].get("reachable", False)
        return False


    def create_event_causality_graph(self, graph_name: str = "event_causality_graph", force_refresh: bool = True):
        """
        åˆ›å»ºä¸€ä¸ªåªåŒ…å« Event èŠ‚ç‚¹ + EVENT_CAUSES è¾¹çš„ GDS å›¾ï¼Œç”¨äºå› æœåˆ†æ
        """
        with self.driver.session() as s:
            if force_refresh:
                s.run("CALL gds.graph.drop($name, false) YIELD graphName", name=graph_name)
                print(f"[âœ“] å·²åˆ é™¤æ—§å›¾ {graph_name}")

            s.run("""
            CALL gds.graph.project(
                $name,
                'Event',
                {
                    EVENT_CAUSES: {
                        orientation: 'NATURAL',
                        properties: ['weight']
                    }
                }
            )
            """, name=graph_name)

            print(f"[+] å·²åˆ›å»ºå› æœå­å›¾ {graph_name}ï¼ˆä»…åŒ…å« Event èŠ‚ç‚¹ä¸ EVENT_CAUSES è¾¹ï¼‰")
            
            result = s.run("""
                MATCH (:Event)-[r:EVENT_CAUSES]->(:Event)
                RETURN count(r) AS edge_count
            """)
            edge_count = result.single()["edge_count"]
            print(f"[âœ“] å½“å‰ EVENT_CAUSES è¾¹æ•°é‡ï¼š{edge_count}")

    
    def create_subgraph(
        self,
        graph_name: str = "subgraph_1",
        exclude_entity_types: Optional[List[str]] = None,
        exclude_relation_types: Optional[List[str]] = None,
        force_refresh: bool = False,
    ) -> None:
        """
        åˆ›å»º/åˆ·æ–°ä¸€ä¸ª GDS å‘½åå­å›¾ï¼š
        - èŠ‚ç‚¹ï¼šå…¨å›¾èŠ‚ç‚¹ï¼Œä½†ä¼šæ’é™¤æŒ‡å®šæ ‡ç­¾ï¼ˆé»˜è®¤ :Sceneï¼‰
        - è¾¹  ï¼šæ’é™¤æŒ‡å®šå…³ç³»ç±»å‹ï¼ˆé»˜è®¤ SCENE_CONTAINSï¼‰
        
        Args:
            graph_name:            å­å›¾åç§°
            exclude_node_labels:   è¦æ’é™¤çš„èŠ‚ç‚¹æ ‡ç­¾åˆ—è¡¨ï¼Œé»˜è®¤ ["Scene"]
            exclude_rel_types:     è¦æ’é™¤çš„å…³ç³»ç±»å‹åˆ—è¡¨ï¼Œé»˜è®¤ ["SCENE_CONTAINS"]
            force_refresh:         å¦‚å­å›¾å·²å­˜åœ¨ï¼Œæ˜¯å¦å¼ºåˆ¶åˆ é™¤åé‡å»º
        """

        exclude_entity_types = exclude_entity_types or [self.meta["section_label"]]
        exclude_relation_types = exclude_relation_types or [self.meta["contains_pred"]]

        with self.driver.session() as s:
            # --- 1. è‹¥å·²å­˜åœ¨ä¸”è¦æ±‚åˆ·æ–°ï¼Œåˆ™åˆ é™¤ ---
            exists = s.run("RETURN gds.graph.exists($name) AS ok",
                        name=graph_name).single()["ok"]
            if exists and force_refresh:
                s.run("CALL gds.graph.drop($name, false)", name=graph_name)
                exists = False
                print(f"[âœ“] æ—§å­å›¾ {graph_name} å·²åˆ é™¤å¹¶åˆ·æ–°")

            if exists:
                print(f"[âœ“] GDS å­å›¾ {graph_name} å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º")
                return

            # --- 2. ç”ŸæˆèŠ‚ç‚¹ / å…³ç³» Cypher ---
            #   èŠ‚ç‚¹ï¼šæ’é™¤æŒ‡å®šæ ‡ç­¾
            label_filter = " AND ".join([f"NOT '{lbl}' IN labels(n)" for lbl in exclude_entity_types]) or "true"
            node_query = f"""
            MATCH (n) WHERE {label_filter}
            RETURN id(n) AS id
            """

            #   å…³ç³»ï¼šæ’é™¤æŒ‡å®šç±»å‹ & æ’é™¤ä¸è¢«æ’é™¤èŠ‚ç‚¹ç›¸è¿çš„è¾¹
            rel_filter = " AND ".join([f"type(r) <> '{rt}'" for rt in exclude_relation_types]) or "true"
            # é¢å¤–ä¿è¯ä¸¤ç«¯èŠ‚ç‚¹éƒ½ä¸æ˜¯è¢«æ’é™¤æ ‡ç­¾
            node_label_neg = " AND ".join([f"NOT '{lbl}' IN labels(a)" for lbl in exclude_entity_types] +
                                        [f"NOT '{lbl}' IN labels(b)" for lbl in exclude_entity_types]) or "true"

            rel_query = f"""
            MATCH (a)-[r]->(b)
            WHERE {rel_filter} AND {node_label_neg}
            RETURN id(a) AS source, id(b) AS target
            """

            # --- 3. è°ƒç”¨ project.cypher ---
            s.run("""
            CALL gds.graph.project.cypher(
            $name,
            $nodeQuery,
            $relQuery
            )
            """, name=graph_name, nodeQuery=node_query, relQuery=rel_query)

            print(f"[+] å·²åˆ›å»º GDS å­å›¾ {graph_name}ï¼ˆæ’é™¤æ ‡ç­¾ {exclude_entity_types}ï¼Œæ’é™¤è¾¹ {exclude_relation_types}ï¼‰")

    def run_louvain(
        self,
        graph_name: str = "event_graph",
        write_property: str = "community",
        max_iterations: int = 20,
        force_run: bool = False
    ) -> None:
        """
        åœ¨æŒ‡å®šå­å›¾ä¸Šè·‘ Louvainï¼›è‹¥å·²å†™è¿‡å±æ€§ä¸” !force_run åˆ™è·³è¿‡
        """
        with self.driver.session() as s:
            if not force_run:
                # å¿«é€Ÿæ£€æµ‹æ˜¯å¦å·²æœ‰ç¤¾åŒºå­—æ®µ
                has_prop = s.run("""
                    MATCH (n) WHERE exists(n[$prop]) RETURN n LIMIT 1
                """, prop=write_property).single()
                if has_prop:
                    print(f"[âœ“] èŠ‚ç‚¹å·²å­˜åœ¨ {write_property}ï¼Œè·³è¿‡ Louvain")
                    return

            s.run(f"""
            CALL gds.louvain.write($graph, {{
              writeProperty: $prop,
              maxIterations: $iters
            }});
            """, graph=graph_name, prop=write_property, iters=max_iterations)
            print(f"[+] Louvain å·²å®Œæˆï¼Œç»“æœå†™å…¥ `{write_property}`")

    
    # === 3. å–åŒç¤¾åŒºäº‹ä»¶å¯¹ ===
    def fetch_event_pairs_same_community(
            self,
            max_pairs: Optional[int] = None
        ) -> List[Dict[str, str]]:
        """
        è¿”å›åŒç¤¾åŒºçš„äº‹ä»¶å¯¹ ID åˆ—è¡¨ï¼ˆä¸å†è€ƒè™‘å›¾ä¸­æ˜¯å¦è·¯å¾„å¯è¾¾ï¼‰
        """
        q = """
        MATCH (e1:Event), (e2:Event)
        WHERE e1.community = e2.community AND id(e1) < id(e2)
        RETURN e1.id AS srcId, e2.id AS dstId
        """
        if max_pairs:
            q += f"\nLIMIT {max_pairs}"
        return self.execute_query(q)

    def write_event_causes(self, rows: List[Dict[str, Any]]) -> None:
        """
        rows: [{srcId, dstId, weight, reason}]
        """
        if not rows:
            return
        self.execute_query("""
        UNWIND $rows AS row
        MATCH (s:Event {id: row.srcId})
        MATCH (t:Event {id: row.dstId})
        MERGE (s)-[ca:EVENT_CAUSES]->(t)
        SET ca.weight = row.weight,
            ca.reason = row.reason,
            ca.confidence = row.confidence,
            ca.predicate = row.predicate
        """, {"rows": rows})
        print(f"[+] å·²å†™å…¥/æ›´æ–° EVENT_CAUSES å…³ç³» {len(rows)} æ¡")
    
    def get_all_events_with_causality(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰äº‹ä»¶åŠå…¶å› æœå…³ç³»ä¿¡æ¯
        
        Returns:
            List[Dict]: åŒ…å«äº‹ä»¶IDã€å±æ€§å’Œå› æœå…³ç³»çš„åˆ—è¡¨
        """
        cypher = """
        MATCH (e:Event)
        OPTIONAL MATCH (e)-[r:EVENT_CAUSES]->(target:Event)
        OPTIONAL MATCH (source:Event)-[r2:EVENT_CAUSES]->(e)
        RETURN e.id as event_id, 
            e.name as event_name,
            e.description as event_description,
            e.participants as participants,
            collect(DISTINCT {target: target.id, weight: r.weight}) as outgoing_causes,
            collect(DISTINCT {source: source.id, weight: r2.weight}) as incoming_causes
        """
        
        result = self.execute_query(cypher)
        return [dict(record) for record in result]

    def get_causality_edges_by_weight(self, threshold: str = "Medium") -> List[Dict[str, Any]]:
        """
        æ ¹æ®æƒé‡é˜ˆå€¼è·å–å› æœå…³ç³»è¾¹
        
        Args:
            threshold: æƒé‡é˜ˆå€¼ ("High", "Medium", "Low")
            
        Returns:
            List[Dict]: å› æœå…³ç³»è¾¹åˆ—è¡¨
        """
        # å®šä¹‰æƒé‡æ˜ å°„
        weight_hierarchy = {
            "High": 1.0,
            "Medium": 0.6, 
            "Low": 0.3
        }
        
        weight_threshold = weight_hierarchy.get(threshold, 0.6)
        
        cypher = """
        MATCH (source:Event)-[r:EVENT_CAUSES]->(target:Event)
        WHERE r.weight >= $weight_threshold
        RETURN source.id AS source_id, 
            target.id AS target_id, 
            r.weight AS weight
        """
        
        params = {"weight_threshold": weight_threshold}
        result = self.execute_query(cypher, params)
        return [dict(record) for record in result]

    def identify_event_clusters_by_connectivity(self, threshold: str = "Medium") -> List[List[str]]:
        """
        ä½¿ç”¨GDSè¿é€šåˆ†é‡ç®—æ³•è¯†åˆ«äº‹ä»¶èšç±»
        
        Args:
            threshold: å› æœå…³ç³»æƒé‡é˜ˆå€¼
            
        Returns:
            List[List[str]]: äº‹ä»¶èšç±»åˆ—è¡¨ï¼Œæ¯ä¸ªèšç±»åŒ…å«äº‹ä»¶IDåˆ—è¡¨
        """
        # 1. åˆ›å»ºåŸºäºæƒé‡é˜ˆå€¼çš„æŠ•å½±å›¾
        graph_name = f"event_causality_graph_{threshold.lower()}"
        
        # åˆ é™¤å¯èƒ½å­˜åœ¨çš„æ—§å›¾
        drop_cypher = f"CALL gds.graph.drop('{graph_name}') YIELD graphName"
        try:
            self.execute_query(drop_cypher)
        except:
            pass  # å›¾ä¸å­˜åœ¨æ—¶å¿½ç•¥é”™è¯¯
        
        # è·å–æƒé‡è¿‡æ»¤æ¡ä»¶
        weight_hierarchy = {
            "High": 1.0,
            "Medium": 0.6, 
            "Low": 0.3
        }
        weight_threshold = weight_hierarchy.get(threshold, 0.6)
        
        # åˆ›å»ºæŠ•å½±å›¾ - åªåŒ…å«æ»¡è¶³æƒé‡æ¡ä»¶çš„å…³ç³»
        create_graph_cypher = f"""
        CALL gds.graph.project.cypher(
            '{graph_name}',
            'MATCH (n:Event) RETURN id(n) AS id',
            'MATCH (a:Event)-[r:EVENT_CAUSES]->(b:Event) 
            WHERE r.weight >= {weight_threshold}
            RETURN id(a) AS source, id(b) AS target, r.weight AS weight'
        )
        """
        # print("[CHECK] create_graph_cypher", create_graph_cypher)
        
        self.execute_query(create_graph_cypher)
        
        # 2. è¿è¡Œè¿é€šåˆ†é‡ç®—æ³•
        wcc_cypher = f"""
        CALL gds.wcc.stream('{graph_name}')
        YIELD nodeId, componentId
        RETURN gds.util.asNode(nodeId).id as event_id, componentId
        ORDER BY componentId, event_id
        """
        
        result = self.execute_query(wcc_cypher)
        # print("[CHECK] result: ", result)
        
        # 3. ç»„ç»‡ç»“æœä¸ºèšç±»
        clusters = {}
        for record in result:
            component_id = record['componentId']
            event_id = record['event_id']
            
            if component_id not in clusters:
                clusters[component_id] = []
            clusters[component_id].append(event_id)
        
        # print("[CHECK] clusters: ", clusters)
        # 4. æ¸…ç†å›¾
        # self.execute_query(drop_cypher)
        
        # 5. è¿‡æ»¤èšç±» - åªä¿ç•™é€šè¿‡æƒé‡é˜ˆå€¼è¿æ¥çš„äº‹ä»¶
        filtered_clusters = []
        edges = self.get_causality_edges_by_weight(threshold)
        # print("[CHECK] edges: ", edges)
        
        # æ„å»ºæ»¡è¶³æƒé‡æ¡ä»¶çš„è¿æ¥å›¾
        connected_events = set()
        for edge in edges:
            connected_events.add(edge['source_id'])
            connected_events.add(edge['target_id'])
        
        for cluster in clusters.values():
            # åªä¿ç•™æœ‰æ»¡è¶³æƒé‡æ¡ä»¶è¿æ¥çš„èšç±»ï¼Œä¸”èšç±»å¤§å°å¤§äº1
            if len(cluster) > 1:
                cluster_has_valid_connections = any(event_id in connected_events for event_id in cluster)
                if cluster_has_valid_connections:
                    filtered_clusters.append(cluster)
        
        return filtered_clusters
            

    def _fallback_clustering(self, threshold: str) -> List[List[str]]:
        """
        é™çº§èšç±»æ–¹æ³•ï¼šåŸºäºç›´æ¥å› æœå…³ç³»çš„ç®€å•èšç±»
        
        Args:
            threshold: æƒé‡é˜ˆå€¼
            
        Returns:
            List[List[str]]: äº‹ä»¶èšç±»åˆ—è¡¨
        """
        edges = self.get_causality_edges_by_weight(threshold)
        
        # æ„å»ºé‚»æ¥è¡¨
        graph = {}
        all_events = set()
        
        for edge in edges:
            source = edge['source_id']
            target = edge['target_id']
            
            all_events.add(source)
            all_events.add(target)
            
            if source not in graph:
                graph[source] = []
            if target not in graph:
                graph[target] = []
                
            graph[source].append(target)
            graph[target].append(source)  # æ— å‘å›¾
        
        # DFSæŸ¥æ‰¾è¿é€šåˆ†é‡
        visited = set()
        clusters = []
        
        def dfs(node, current_cluster):
            if node in visited:
                return
            visited.add(node)
            current_cluster.append(node)
            
            for neighbor in graph.get(node, []):
                dfs(neighbor, current_cluster)
        
        for event in all_events:
            if event not in visited:
                cluster = []
                dfs(event, cluster)
                if len(cluster) > 1:  # åªä¿ç•™æœ‰å¤šä¸ªäº‹ä»¶çš„èšç±»
                    clusters.append(cluster)
        
        return clusters
    
    def enrich_event_nodes_with_context(self) -> None:
        """
        ä¸ºæ¯ä¸ª Event èŠ‚ç‚¹è¡¥å…¨ä¸Šä¸‹æ–‡å­—æ®µï¼Œå¹¶åˆå¹¶å†™å…¥åˆ° e.propertiesï¼ˆå­—ç¬¦ä¸²å‹ JSONï¼‰ä¸­ï¼š
        - time: List[str]
        - participants: List[str]
        - location: List[str]
        - chapter_name æˆ– scene_name: List[str]ï¼Œå–å†³äº doc_type
        """

        section_key = "scene_name" if self.doc_type == "screenplay" else "chapter_name"
        section_label = "Scene" if self.doc_type == "screenplay" else "Chapter"

        # Step 1: æŸ¥è¯¢æ‰€æœ‰äº‹ä»¶èŠ‚ç‚¹åŠå…¶ä¸Šä¸‹æ–‡
        cypher = f"""
        MATCH (e:Event)
        OPTIONAL MATCH (e)-[]-(t:TimePoint)
        OPTIONAL MATCH (e)-[]-(c:Character)
        OPTIONAL MATCH (e)-[]-(l:Location)
        OPTIONAL MATCH (e)-[]-(s:{section_label})
        RETURN e.id AS id,
            [x IN COLLECT(DISTINCT t.value) WHERE x IS NOT NULL] AS time,
            [x IN COLLECT(DISTINCT c.name) WHERE x IS NOT NULL] AS participants,
            [x IN COLLECT(DISTINCT l.name) WHERE x IS NOT NULL] AS location,
            [x IN COLLECT(DISTINCT s.name) WHERE x IS NOT NULL] AS {section_key},
            e.properties AS properties
        """
        records = self.execute_query(cypher)

        # Step 2: åˆå¹¶å­—æ®µå¹¶å†™å…¥ propertiesï¼ˆæ³¨æ„ properties æ˜¯å­—ç¬¦ä¸²å‹ JSONï¼‰
        for r in tqdm(records, desc="æ›´æ–° Event properties ä¸Šä¸‹æ–‡"):
            try:
                props: Dict[str, Any] = json.loads(r["properties"]) if r.get("properties") else {}
            except Exception:
                print(f"âš ï¸ JSON è§£æå¤±è´¥ï¼Œè·³è¿‡ id={r['id']}")
                continue

            props["time"] = r.get("time", [])
            props["participants"] = r.get("participants", [])
            props["location"] = r.get("location", [])
            props[section_key] = r.get(section_key, [])

            self.execute_query(
                "MATCH (e:Event {id: $id}) SET e.properties = $props_str",
                {"id": r["id"], "props_str": json.dumps(props, ensure_ascii=False)}
            )

        print(f"[âœ“] å·²å°†ä¸Šä¸‹æ–‡å±æ€§å°è£…å†™å…¥ e.properties å­—ç¬¦ä¸²å­—æ®µï¼ˆåŒ…å« time, participants, location, {section_key}ï¼‰")


    def get_event_details(self, event_ids: List[str]) -> List[Dict[str, Any]]:
        """
        è¿”å›äº‹ä»¶èŠ‚ç‚¹çš„æ ¸å¿ƒä¿¡æ¯ + properties + æ‰€å±ç« èŠ‚ä¿¡æ¯
        """
        cypher = f"""
        MATCH (e:Event)
        WHERE e.id IN $event_ids
        OPTIONAL MATCH (s:{self.meta['section_label']})-[:{self.meta['contains_pred']}]->(e)
        RETURN e.id          AS event_id,
            e.name        AS event_name,
            e.source_chunks AS source_chunks,
            e.description AS event_description,
            e.properties  AS event_properties,          // â† ç›´æ¥è¿”å›æ•´ä¸ªå±æ€§ Map
            collect(DISTINCT s.id)   AS section_ids,
            collect(DISTINCT s.name) AS section_names
        """
        return self.execute_query(cypher, {"event_ids": event_ids})


    def get_causality_paths(self, event_ids: List[str]) -> List[Dict[str, Any]]:
        """
        è·å–äº‹ä»¶é—´çš„å› æœè·¯å¾„
        
        Args:
            event_ids: äº‹ä»¶IDåˆ—è¡¨
            
        Returns:
            List[Dict]: å› æœè·¯å¾„ä¿¡æ¯
        """
        cypher = """
        MATCH (source:Event)-[r:EVENT_CAUSES]->(target:Event)
        WHERE source.id IN $event_ids AND target.id IN $event_ids
        RETURN source.id as source_id,
            source.name as source_name,
            target.id as target_id,
            target.name as target_name,
            r.weight as weight,
            r.description as causality_description
        ORDER BY 
            CASE r.weight 
                WHEN 'High' THEN 1 
                WHEN 'Medium' THEN 2 
                WHEN 'Low' THEN 3 
                ELSE 4 
            END
        """
        
        params = {"event_ids": event_ids}
        result = self.execute_query(cypher, params)
        return [dict(record) for record in result]

    def create_plot_node(self, plot_data: Dict[str, Any]) -> bool:
        """
        åˆ›å»ºPlotèŠ‚ç‚¹
        
        Args:
            plot_data: Plotæ•°æ®å­—å…¸
            
        Returns:
            bool: åˆ›å»ºæ˜¯å¦æˆåŠŸ
        """
        cypher = """
        CREATE (p:Plot {
            id: $plot_id,
            title: $title,
            summary: $summary,
            structure_type: $structure_type,
            narrative_roles: $narrative_roles,
            created_at: datetime()
        })
        RETURN p.id as plot_id
        """
        
        params = {
            "plot_id": plot_data["id"],
            "title": plot_data["title"],
            "summary": plot_data["summary"],
            "structure_type": plot_data.get("structure", {}).get("type", "èµ·æ‰¿è½¬åˆ"),
            "narrative_roles": str(plot_data.get("structure", {}).get("narrative_roles", {}))
        }
        
        try:
            result = self.execute_query(cypher, params)
            return len(list(result)) > 0
        except Exception as e:
            print(f"åˆ›å»ºPlotèŠ‚ç‚¹å¤±è´¥: {e}")
            return False

    def create_has_event_relationships(self, plot_id: str, event_ids: List[str]) -> bool:
        """
        åˆ›å»ºHAS_EVENTå…³ç³»
        
        Args:
            plot_id: Plot ID
            event_ids: äº‹ä»¶IDåˆ—è¡¨
            
        Returns:
            bool: åˆ›å»ºæ˜¯å¦æˆåŠŸ
        """
        cypher = """
        MATCH (p:Plot {id: $plot_id})
        MATCH (e:Event)
        WHERE e.id IN $event_ids
        CREATE (p)-[:HAS_EVENT]->(e)
        RETURN count(*) as relationships_created
        """
        
        params = {
            "plot_id": plot_id,
            "event_ids": event_ids
        }
        
        try:
            result = self.execute_query(cypher, params)
            count = list(result)[0]['relationships_created']
            return count == len(event_ids)
        except Exception as e:
            print(f"åˆ›å»ºHAS_EVENTå…³ç³»å¤±è´¥: {e}")
            return False

    def write_plot_to_neo4j(self, plot_data: Dict[str, Any]) -> bool:
        """
        å®Œæ•´çš„Plotå†™å…¥åŠŸèƒ½
        
        Args:
            plot_data: Plotæ•°æ®å­—å…¸ï¼ŒåŒ…å«idã€titleã€summaryã€event_idsã€structure
            
        Returns:
            bool: å†™å…¥æ˜¯å¦æˆåŠŸ
        """
        try:
            # 1. åˆ›å»ºPlotèŠ‚ç‚¹
            if not self.create_plot_node(plot_data):
                return False
            
            # 2. åˆ›å»ºHAS_EVENTå…³ç³»
            event_ids = plot_data.get("event_ids", [])
            if event_ids and not self.create_has_event_relationships(plot_data["id"], event_ids):
                return False
            
            print(f"æˆåŠŸå†™å…¥Plot: {plot_data['id']}")
            return True
            
        except Exception as e:
            print(f"å†™å…¥Plotåˆ°Neo4jå¤±è´¥: {e}")
            return False
    
    
    def load_connected_components_subgraph(self, node_ids: List[int]) -> tuple[Dict[int, Dict], List[Dict]]:
        """
        ä» Neo4j åŠ è½½ä¸€ä¸ª CC çš„æ‰€æœ‰èŠ‚ç‚¹å’Œè¾¹
        
        Args:
            node_ids: Neo4j å†…éƒ¨èŠ‚ç‚¹ ID åˆ—è¡¨

        Returns:
            - node_map: {nodeId -> å±æ€§å­—å…¸}
            - edges: List of {sid, tid, w, reason}
        """
        # 1. èŠ‚ç‚¹
        cypher_nodes = f"""
        UNWIND $ids AS nid
        MATCH (n) WHERE n.id = nid
        RETURN n.id AS dbid,
                n.id AS eid,
                n.embedding AS emb
        """
        nodes = self.execute_query(cypher_nodes, {"ids": node_ids})
        node_map = {n["dbid"]: n for n in nodes}

        # 2. è¾¹
        cypher_edges = """
        MATCH (u)-[r:EVENT_CAUSES]->(v)
        WHERE u.id IN $ids AND v.id IN $ids
        RETURN u.id AS sid,
                v.id AS tid,
                r.weight AS weight,
                r.reason AS reason,
                r.confidence AS confidence
        """
        edges = self.execute_query(cypher_edges, {"ids": node_ids})
        return node_map, edges
    
    
    def fetch_scc_components(self, graph_name, min_size: int = 0) -> List[List[int]]:
        """
        è°ƒç”¨ GDS çš„ scc.stream è¿”å›å¼ºè¿é€šä½“
        é’ˆå¯¹ size>1 çš„ç»„ä»¶æ‰éœ€è¦æ–­ç¯
        """
        cypher = f"""
        CALL gds.scc.stream('{graph_name}')
        YIELD nodeId, componentId
        WITH gds.util.asNode(nodeId) AS n, componentId
        RETURN componentId,
            collect(n.id) AS nodeIds
        """
        sccs = self.execute_query(cypher)
        sccs = [c["nodeIds"] for c in sccs if len(c["nodeIds"]) >= min_size]
        # print(f"Detected { len(sccs)} SCCs with size>1")
        return sccs

    def fetch_wcc_components(self, graph_name, min_size: int = 0) -> List[List[int]]:
        """
        è°ƒç”¨ GDS çš„ scc.stream è¿”å›å¼ºè¿é€šä½“
        é’ˆå¯¹ size>1 çš„ç»„ä»¶æ‰éœ€è¦æ–­ç¯
        """
        cypher = f"""
        CALL gds.wcc.stream('{graph_name}')
        YIELD nodeId, componentId
        WITH gds.util.asNode(nodeId) AS n, componentId
        RETURN componentId,
            collect(n.id) AS nodeIds
        """
        sccs = self.execute_query(cypher)
        sccs = [c["nodeIds"] for c in sccs if len(c["nodeIds"]) >= min_size]
        # print(f"Detected { len(sccs)} WCCs with size>1")
        return sccs


    def get_plot_statistics(self) -> Dict[str, int]:
        """
        è·å–Plotå›¾è°±ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict[str, int]: ç»Ÿè®¡ä¿¡æ¯
        """
        cypher = f"""
        MATCH (p:Plot)
        OPTIONAL MATCH (p)-[:HAS_EVENT]->(e:Event)
        OPTIONAL MATCH (s:{self.meta['section_label']})-[:{self.meta['contains_pred']}]->(e)
        RETURN count(DISTINCT p) AS plot_count,
               count(DISTINCT e) AS event_count,
               count(DISTINCT s) AS section_count
        """
        
        result = self.execute_query(cypher)
        return dict(list(result)[0])
    
    def get_starting_events(self):
        cypher = """
        MATCH (e:Event)
        WHERE NOT ()-[:EVENT_CAUSES]->(e)
        RETURN e.id AS event_id
        """
        result = self.execute_query(cypher)
        result = [e["event_id"] for e in result]
        return result
    
    def find_event_chain(self, entity_id: str, graph_name: str) -> List[List[str]]:
        """
        ä½¿ç”¨ GDS çš„ DFSï¼Œä»æŒ‡å®š entity_id å‡ºå‘ï¼Œåœ¨ç»™å®šå›¾ä¸­æœç´¢æ‰€æœ‰å› æœè·¯å¾„ï¼ˆäº‹ä»¶é“¾ï¼‰
        
        Args:
            entity_id: äº‹ä»¶èŠ‚ç‚¹ IDï¼ˆå¦‚ 'entity_123456'ï¼‰
            graph_name: å·²åˆ›å»ºçš„ GDS å›¾åï¼ˆå¦‚ 'eventCausalGraph'ï¼‰

        Returns:
            æ‰€æœ‰ DFS è·¯å¾„æ„æˆçš„äº‹ä»¶é“¾åˆ—è¡¨ï¼Œæ¯æ¡é“¾æ˜¯ event_id çš„æœ‰åºåˆ—è¡¨
        """
        cypher = """
        MATCH (e:Event {id: $entity_id})
        WITH e AS start_node
        CALL gds.dfs.stream($graph_name, { sourceNode: start_node })
        YIELD nodeIds
        RETURN [nodeId IN nodeIds | gds.util.asNode(nodeId).id] AS event_chain
        """
        
        results = self.execute_query(cypher, {"entity_id": entity_id, "graph_name": graph_name})
        return [record["event_chain"] for record in results if "event_chain" in record]

    