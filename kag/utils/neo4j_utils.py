"""
Neo4jæ•°æ®åº“æ“ä½œå·¥å…·ç±»
æä¾›å¯æ‰©å±•çš„æŸ¥è¯¢æ¥å£ï¼Œä¾¿äºåç»­æ·»åŠ æ–°çš„æŸ¥è¯¢åŠŸèƒ½
"""

from typing import List, Optional, Union, Tuple, Dict, Any, Set
import json
import networkx as nx
from neo4j import Driver
from community import best_partition
from kag.models.entities import Entity, Relation
from sentence_transformers import SentenceTransformer
from tqdm import tqdm


class Neo4jUtils:
    """
    Neo4jæ•°æ®åº“æ“ä½œå·¥å…·ç±»
    è®¾è®¡åŸåˆ™ï¼š
    1. åŸºç¡€æŸ¥è¯¢æ–¹æ³•å¯å¤ç”¨
    2. æ”¯æŒåŠ¨æ€CypheræŸ¥è¯¢æ„å»º
    3. ä¾¿äºåç»­æ·»åŠ æ–°çš„æŸ¥è¯¢åŠŸèƒ½
    4. æŸ¥è¯¢ç»“æœæ ‡å‡†åŒ–å¤„ç†
    """
    
    def __init__(self, driver: Driver):
        """
        åˆå§‹åŒ–Neo4jå·¥å…·ç±»
        
        Args:
            driver: Neo4jè¿æ¥é©±åŠ¨
        """
        self.driver = driver
        self.model = None
        self.embedding_field = "embedding"
        self.dim = 768
        
    def load_emebdding_model(self, model_name):
        self.model = SentenceTransformer(model_name)
        self.dim = self.model.get_sentence_embedding_dimension()
        print("å‘é‡æ¨¡å‹å·²åŠ è½½")
    
    def execute_query(self, cypher: str, params: Dict[str, Any] = None) -> List[Dict]:
        """
        æ‰§è¡Œè‡ªå®šä¹‰CypheræŸ¥è¯¢çš„é€šç”¨æ–¹æ³•
        
        Args:
            cypher: CypheræŸ¥è¯¢è¯­å¥
            params: æŸ¥è¯¢å‚æ•°
            
        Returns:
            æŸ¥è¯¢ç»“æœåˆ—è¡¨
        """
        if params is None:
            params = {}
            
        with self.driver.session() as session:
            result = session.run(cypher, params)
            return [dict(record) for record in result]
        
    def search_entities_by_type(
        self,
        entity_type: Optional[str] = None,
        keyword: Optional[str] = None,
        limit: int = 20,
    ) -> List[Entity]:
        """
        æœç´¢å›¾ä¸­æ‰€æœ‰æ»¡è¶³ç±»å‹å’Œå…³é”®è¯çš„å®ä½“ï¼ˆå¯é€‰è¿‡æ»¤ï¼‰
        
        Args:
            entity_type: å®ä½“ç±»å‹ï¼ˆå¦‚ "Character", "Concept", "Object"ï¼Œä¼  None è¡¨ç¤ºä¸é™åˆ¶ï¼‰
            keyword: å¯é€‰åç§°å…³é”®è¯ï¼ˆæ¨¡ç³ŠåŒ¹é… name æˆ– aliasesï¼‰
            limit: è¿”å›ç»“æœä¸Šé™
            
        Returns:
            List[Entity]
        """
        if self.driver is None:
            return []

        cypher_template = f"""
        MATCH (e:{entity_type if entity_type else ''})
        {{where_clause}}
        RETURN DISTINCT e
        LIMIT $limit
        """

        # åŠ¨æ€æ‹¼æ¥ WHERE å­å¥
        where_clauses = []
        params = {"limit": limit}

        if entity_type:
            where_clauses.append("e.type = $etype")
            params["etype"] = entity_type

        if keyword:
            where_clauses.append(
                "(e.name CONTAINS $kw OR any(alias IN e.aliases WHERE alias CONTAINS $kw))"
            )
            params["kw"] = keyword

        where_clause = ""
        if where_clauses:
            where_clause = "WHERE " + " AND ".join(where_clauses)

        cypher = cypher_template.format(where_clause=where_clause)

        # æ‰§è¡ŒæŸ¥è¯¢
        with self.driver.session() as session:
            result = session.run(cypher, params)
            entities = []
            for record in result:
                data = record["e"]
                entities.append(self._build_entity_from_data(data))
            return entities

    def search_related_entities(
        self,
        source_id: str,
        predicate: Optional[str] = None,
        relation_type: Optional[str] = None,
        entity_types: Optional[List[str]] = None,
        limit: int = 10,
        return_relations: bool = False
    ) -> Union[List[Entity], List[Tuple[Entity, Relation]]]:
        """
        æœç´¢ä¸æŒ‡å®šå®ä½“ç›¸å…³çš„å®ä½“
        
        Args:
            source_id: æºå®ä½“ID
            predicate: å…³ç³»è°“è¯è¿‡æ»¤
            entity_types: ç›®æ ‡å®ä½“ç±»å‹è¿‡æ»¤
            limit: ç»“æœæ•°é‡é™åˆ¶
            return_relations: æ˜¯å¦è¿”å›å…³ç³»ä¿¡æ¯
            
        Returns:
            å®ä½“åˆ—è¡¨æˆ–å®ä½“-å…³ç³»å…ƒç»„åˆ—è¡¨
        """
        if self.driver is None:
            return []
            
        params = {"source_id": source_id, "limit": limit}
        if relation_type:
            params["rel_type"] = relation_type
        if predicate:
            params["predicate"] = predicate
        if entity_types:
            params["etypes"] = entity_types

        # entity type è¿‡æ»¤è¯­å¥
        type_filter = "AND target.type IN $etypes" if entity_types else ""
        pred_filter = "AND rel.predicate = $predicate" if predicate else ""
        rel_type_clause = f":{relation_type}" if relation_type else ""

        results = []

        with self.driver.session() as session:
            # æ­£å‘å…³ç³»
            forward_cypher = f"""
            MATCH (source)-[rel{rel_type_clause }]->(target)
            WHERE source.id = $source_id
              AND rel.predicate IS NOT NULL
              {pred_filter}
              {type_filter}
            RETURN target, rel
            LIMIT $limit
            """
            # print("[CHECK] forward_cypher: ", session.run(forward_cypher, params))

            for record in session.run(forward_cypher, params):
                entity, relation = self._process_entity_relation_record(record, source_id, "forward")
                if return_relations:
                    results.append((entity, relation))
                else:
                    results.append(entity)

            # åå‘å…³ç³»
            backward_cypher = f"""
            MATCH (target)-[rel{rel_type_clause}]->(source)
            WHERE source.id = $source_id
              AND rel.predicate IS NOT NULL
              {pred_filter}
              {type_filter}
            RETURN target, rel
            LIMIT $limit
            """

            for record in session.run(backward_cypher, params):
                entity, relation = self._process_entity_relation_record(record, source_id, "backward")
                if return_relations:
                    results.append((entity, relation))
                else:
                    results.append(entity)

        return results

    def get_entity_by_id(self, entity_id: str) -> Optional[Entity]:
        """
        æ ¹æ® ID ç²¾å‡†æŸ¥æ‰¾ä¸€ä¸ªå®ä½“èŠ‚ç‚¹ï¼ˆå…¼å®¹æ‰€æœ‰æ ‡ç­¾ï¼‰
        
        Args:
            entity_id: å®ä½“çš„å”¯ä¸€ IDï¼ˆä¾‹å¦‚ "entity_123456"ï¼‰
            
        Returns:
            åŒ¹é…çš„ Entity å¯¹è±¡ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å› None
        """
        cypher = """
        MATCH (e)
        WHERE e.id = $entity_id
        RETURN e
        LIMIT 1
        """
        params = {"entity_id": entity_id}

        with self.driver.session() as session:
            result = session.run(cypher, params)
            record = result.single()
            if not record:
                return None

            data = record["e"]
            return self._build_entity_from_data(data)

    def list_relationship_types(self) -> List[str]:
        """
        è·å– Neo4j å›¾æ•°æ®åº“ä¸­å·²å­˜åœ¨çš„æ‰€æœ‰å…³ç³»ç±»å‹
        
        Returns:
            å…³ç³»ç±»å‹åç§°åˆ—è¡¨ï¼ˆå»é‡ã€æŒ‰å­—æ¯æ’åºï¼‰
        """
        cypher = """
        CALL db.relationshipTypes() YIELD relationshipType
        RETURN relationshipType
        ORDER BY relationshipType
        """

        with self.driver.session() as session:
            result = session.run(cypher)
            rel_types = [record["relationshipType"] for record in result]

        return rel_types
    
    def list_entity_types(self) -> List[str]:
        """
        è·å– Neo4j å›¾æ•°æ®åº“ä¸­å·²å­˜åœ¨çš„æ‰€æœ‰å®ä½“ç±»å‹ï¼ˆèŠ‚ç‚¹æ ‡ç­¾ï¼‰

        Returns:
            å®ä½“ç±»å‹åç§°åˆ—è¡¨ï¼ˆå»é‡ã€æŒ‰å­—æ¯æ’åºï¼‰
        """
        cypher = """
        CALL db.labels() YIELD label
        RETURN label
        ORDER BY label
        """
        with self.driver.session() as session:
            result = session.run(cypher)
            labels = [record["label"] for record in result]
        if "*" in labels:
            labels.remove("*")
        return labels


    def has_path_between(
        self, 
        src_id: str, 
        dst_id: str, 
        max_depth: int = 5, 
        allowed_rels: Optional[List[str]] = None
    ) -> bool:
        """
        åˆ¤æ–­å›¾ä¸­æ˜¯å¦å­˜åœ¨ä» src åˆ° dst çš„è·¯å¾„ï¼Œä»…å…è®¸ä½¿ç”¨ç™½åå•ä¸­æŒ‡å®šçš„è¾¹ç±»å‹
        
        Args:
            src_id: æºå®ä½“ID
            dst_id: ç›®æ ‡å®ä½“ID
            max_depth: æœ€å¤§è·¯å¾„æ·±åº¦
            allowed_rels: å…è®¸çš„å…³ç³»ç±»å‹ï¼ˆå¦‚ ['follows', 'supports']ï¼‰
            
        Returns:
            æ˜¯å¦å­˜åœ¨è·¯å¾„
        """
        if not allowed_rels:
            print("âš ï¸ æ²¡æœ‰æŒ‡å®š allowed_rels ç™½åå•ï¼ŒæŸ¥è¯¢å¯èƒ½æ— æ„ä¹‰")
            return False

        # ç”¨å†’å·æ‹¼æ¥ï¼š:rel1|rel2|rel3
        rel_pattern = ":" + "|".join(allowed_rels)

        cypher = f"""
        MATCH p = (src {{id: $src}})-[{rel_pattern}*1..{max_depth}]-(dst {{id: $dst}})
        WHERE src.id <> dst.id
        RETURN count(p) > 0 AS connected
        """

        try:
            with self.driver.session() as session:
                result = session.run(
                    cypher,
                    {"src": src_id, "dst": dst_id}
                ).single()
                return result["connected"] if result else False
        except Exception as e:
            print(f"[Neo4j] has_path_between (whitelist mode) æ‰§è¡Œå¤±è´¥: {e}")
            return False

    def build_filtered_graph(self, allowed_rels: Set[str]) -> nx.Graph:
        """
        ä» Neo4j æ„å»ºä¸€ä¸ªä»…åŒ…å«æŒ‡å®šå…³ç³»ç±»å‹çš„æ— å‘å›¾
        
        Args:
            allowed_rels: å…è®¸çš„å…³ç³»ç±»å‹é›†åˆ
            
        Returns:
            NetworkXæ— å‘å›¾
        """
        G = nx.Graph()
        with self.driver.session() as session:
            cypher = f"""
            MATCH (s)-[r]->(o)
            WHERE type(r) IN $allowed_rels
            RETURN s.id AS src, o.id AS dst
            """
            result = session.run(cypher, {"allowed_rels": list(allowed_rels)})
            for record in result:
                src, dst = record["src"], record["dst"]
                if src and dst:
                    G.add_edge(src, dst)
        return G

    def assign_components_and_communities(self, G: nx.Graph) -> Dict[str, Tuple[int, int]]:
        """
        ä¸ºå›¾ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹åˆ†é… (component_id, community_id)
        
        Args:
            G: NetworkXå›¾
            
        Returns:
            èŠ‚ç‚¹IDåˆ°(è¿é€šä½“ID, ç¤¾åŒºID)çš„æ˜ å°„
        """
        node_map = {}
        component_id = 0

        for component_nodes in nx.connected_components(G):
            subgraph = G.subgraph(component_nodes)
            community_dict = best_partition(subgraph)
            for node_id in community_dict:
                community_id = community_dict[node_id]
                node_map[node_id] = (component_id, community_id)
            component_id += 1

        return node_map

    def has_path_between_nx(
        self, 
        G: nx.Graph, 
        src_id: str, 
        dst_id: str, 
        max_depth: int = 3
    ) -> bool:
        """
        åˆ¤æ–­ NetworkX å›¾ä¸­ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´æ˜¯å¦å­˜åœ¨è·¯å¾„ï¼Œä¸”è·¯å¾„é•¿åº¦ä¸è¶…è¿‡ max_depth
        
        Args:
            G: NetworkXå›¾ï¼ˆå·²è¿‡æ»¤åçš„ç™½åå•å›¾ï¼‰
            src_id: èµ·ç‚¹èŠ‚ç‚¹ ID
            dst_id: ç»ˆç‚¹èŠ‚ç‚¹ ID
            max_depth: è·¯å¾„æœ€å¤§æ·±åº¦
            
        Returns:
            æ˜¯å¦å­˜åœ¨æ»¡è¶³æ¡ä»¶çš„è·¯å¾„
        """
        if src_id not in G or dst_id not in G:
            return False
        try:
            length = nx.shortest_path_length(G, source=src_id, target=dst_id)
            return length <= max_depth
        except nx.NetworkXNoPath:
            return False
        except nx.NodeNotFound:
            return False

    def _build_entity_from_data(self, data) -> Entity:
        """
        ä»Neo4jæŸ¥è¯¢ç»“æœæ„å»ºEntityå¯¹è±¡
        
        Args:
            data: Neo4jèŠ‚ç‚¹æ•°æ®
            
        Returns:
            Entityå¯¹è±¡
        """
        return Entity(
            id=data["id"],
            name=data["name"],
            type=data.get("type", "Unknown"),
            aliases=data.get("aliases", []),
            description=data.get("description", ""),
            properties=json.loads(data.get("properties", "{}")),
            source_chunks=data.get("source_chunks", []),
        )

    def _process_entity_relation_record(
        self, 
        record, 
        source_id: str, 
        direction: str
    ) -> Tuple[Entity, Relation]:
        """
        å¤„ç†å®ä½“-å…³ç³»æŸ¥è¯¢è®°å½•
        
        Args:
            record: Neo4jæŸ¥è¯¢è®°å½•
            source_id: æºå®ä½“ID
            direction: å…³ç³»æ–¹å‘ ("forward" æˆ– "backward")
            
        Returns:
            (Entity, Relation)å…ƒç»„
        """
        data = record["target"]
        rel = record["rel"]
        # print("[CHECL] rel.type: ", rel.type )
        
        entity = self._build_entity_from_data(data)
        # print("[CHECK] rel: ", [k for k in rel])
        predicate = rel.get("predicate", rel.type)
        
        if direction == "forward":
            relation_id_str = f"{source_id}_{predicate}_{data["id"]}"
        else:
            relation_id_str = f"{data["id"]}_{predicate}_{source_id}"
            
        rel_id = f"rel_{hash(relation_id_str) % 1000000}"
        
        
        if direction == "forward":
            relation = Relation(
                id=rel.get("id", rel_id),
                subject_id=source_id,
                predicate=predicate,
                object_id=data["id"],
                source_chunks=rel.get("source_chunks", []),
                properties=json.loads(rel.get("properties", "{}")),
            )
        else:  # backward
            relation = Relation(
                id=rel.get("id", rel_id),
                subject_id=data["id"],
                predicate=predicate,
                object_id=source_id,
                source_chunks=rel.get("source_chunks", []),
                properties=json.loads(rel.get("properties", "{}")),
            )
        
        return entity, relation
    
    
    def encode_node_embedding(self, node: Dict) -> List[float]:
        name = node.get("name", "")
        desc = node.get("description", "")
        props = node.get("properties", "")
        try:
            props_dict = json.loads(props) if isinstance(props, str) else props
        except Exception:
            props_dict = {}

        # æ„é€ åµŒå…¥è¾“å…¥
        if props_dict:
            prop_text = "ï¼›".join([f"{k}ï¼š{v}" for k, v in props_dict.items()])
            text = f"{name}ï¼š{desc}ã€‚{prop_text}"
        else:
            text = f"{name}ï¼š{desc}"
        return self.model.encode(text, normalize_embeddings=True).tolist()

    def encode_relation_embedding(self, rel: Dict) -> Optional[List[float]]:
        try:
            props = rel.get("properties", "")
            props_dict = json.loads(props) if isinstance(props, str) else props
            desc = props_dict.get("description", "")
            if desc:
                return self.model.encode(desc, normalize_embeddings=True).tolist()
        except Exception:
            pass
        return None
    
    def fetch_all_nodes(self, node_types: List[str]) -> List[Dict]:
        results = []
        with self.driver.session() as session:
            for label in node_types:
                query = f"""
                MATCH (e:{label})
                RETURN labels(e) AS labels, e.id AS id, e.name AS name, e.description AS description, e.properties AS properties
                """
                res = session.run(query)
                results.extend([r.data() for r in res])
        return results

    def fetch_all_relations(self, relation_types: Optional[List[str]] = None) -> List[Dict]:
        """
        è·å–å›¾ä¸­æ‰€æœ‰å…³ç³»ï¼Œæ”¯æŒæŒ‰å…³ç³»ç±»å‹ï¼ˆpredicateï¼‰è¿‡æ»¤ã€‚

        Args:
            relation_types: è¦ä¿ç•™çš„å…³ç³»ç±»å‹åˆ—è¡¨ï¼ˆå¦‚ ["happens_at", "causes"]ï¼‰
                            è‹¥ä¸º Noneï¼Œåˆ™è¿”å›æ‰€æœ‰å…³ç³»

        Returns:
            æ¯æ¡è¾¹çš„æ•°æ®å­—å…¸ï¼Œå­—æ®µåŒ…æ‹¬ predicateã€idã€properties
        """
        with self.driver.session() as session:
            if relation_types:
                predicate_filter = ", ".join([f"'{r}'" for r in relation_types])
                query = f"""
                MATCH ()-[r]->()
                WHERE type(r) IN [{predicate_filter}]
                RETURN type(r) AS predicate, r.id AS id, r.properties AS properties
                """
            else:
                query = """
                MATCH ()-[r]->()
                RETURN type(r) AS predicate, r.id AS id, r.properties AS properties
                """

            result = session.run(query)
            return [record.data() for record in result]

        
    def update_node_embedding(self, node_id: str, embedding: List[float]) -> None:
        with self.driver.session() as session:
            session.run(f"""
            MATCH (e) WHERE e.id = $id
            SET e.{self.embedding_field} = $embedding
            """, id=node_id, embedding=embedding)
            
    def update_relation_embedding(self, rel_id: str, embedding: List[float]) -> None:
        with self.driver.session() as session:
            session.run(f"""
            MATCH ()-[r]->() WHERE r.id = $id
            SET r.{self.embedding_field} = $embedding
            """, id=rel_id, embedding=embedding)
    
    def process_all_embeddings(self, exclude_node_types: List[str] = [], exclude_rel_types: List[str] = []):
        """
        è‡ªåŠ¨å¤„ç†æ‰€æœ‰èŠ‚ç‚¹æ ‡ç­¾å’Œæ‰€æœ‰è¾¹ï¼Œä¸ºå…¶ç”Ÿæˆ embedding å¹¶å†™å›å›¾æ•°æ®åº“ã€‚
        èŠ‚ç‚¹ embedding è¾“å…¥ï¼šname + description (+ properties)
        è¾¹ embedding è¾“å…¥ï¼šproperties.description
        """
        # === è·å–æ‰€æœ‰å®ä½“ç±»å‹ï¼ˆæ ‡ç­¾ï¼‰ ===
        node_types = self.list_entity_types()

        # === å¤„ç†èŠ‚ç‚¹åµŒå…¥ ===
        print("ğŸš€ å¼€å§‹å¤„ç†èŠ‚ç‚¹åµŒå…¥...")
        for node in exclude_node_types:
            if node in node_types:
                node_types.remove(node)
                
        print(f"ğŸ“Œ å®ä½“ç±»å‹æ ‡ç­¾: {node_types}")
        nodes = self.fetch_all_nodes(node_types)
        for n in  tqdm(nodes, desc="Encoding Nodes", ncols=80):
            try:
                emb = self.encode_node_embedding(n)
                self.update_node_embedding(n["id"], emb)
            except Exception as e:
                print(f"âš ï¸ Node {n.get('id')} embedding failed:", str(e))

        print(f"âœ… èŠ‚ç‚¹åµŒå…¥å®Œæˆï¼Œå…±å¤„ç† {len(nodes)} ä¸ªèŠ‚ç‚¹")

        # === å¤„ç†å…³ç³»åµŒå…¥ ===
        print("ğŸš€ å¼€å§‹å¤„ç†è¾¹åµŒå…¥...")
        rel_types = self.list_relationship_types()
        for rel in exclude_rel_types: # ç§»é™¤ä¸éœ€è¦è€ƒè™‘çš„è¾¹å…³ç³»
            if rel in rel_types:
                rel_types.remove(rel)
        
        rels = self.fetch_all_relations(rel_types)
        
        for r in tqdm(rels, desc="Encoding Edges", ncols=80):
            try:
                emb = self.encode_relation_embedding(r)
                if emb:
                    self.update_relation_embedding(r["id"], emb)
            except Exception as e:
                print(f"âš ï¸ Relation {r.get('id')} embedding failed:", str(e))

        print(f"âœ… è¾¹åµŒå…¥å®Œæˆï¼Œå…±å¤„ç† {len(rels)} æ¡è¾¹")
        
        
    def ensure_entity_superlabel(self):
        """
        ä¸ºæ‰€æœ‰å…·æœ‰ embedding çš„èŠ‚ç‚¹æ·»åŠ è¶…æ ‡ç­¾ :Entityï¼ˆè·³è¿‡å·²å­˜åœ¨æ ‡ç­¾ï¼‰
        """
        query = """
        MATCH (n)
        WHERE n.embedding IS NOT NULL AND NOT 'Entity' IN labels(n)
        SET n:Entity
        """
        with self.driver.session() as session:
            session.run(query)
            print("[âœ“] å·²ä¸ºæ‰€æœ‰å« embedding çš„èŠ‚ç‚¹æ·»åŠ è¶…æ ‡ç­¾ :Entity")

    def create_vector_index(self, index_name="entityEmbeddingIndex", similarity="cosine"):
        """
        åˆ é™¤å·²æœ‰åŒåç´¢å¼•å¹¶é‡å»ºç»Ÿä¸€å‘é‡ç´¢å¼•
        """

        with self.driver.session() as session:
            # DROP index if existsï¼ˆ5.x è¯­æ³•ï¼‰
            session.run(f"DROP INDEX {index_name} IF EXISTS")
            print(f"[âœ“] å·²åˆ é™¤æ—§ç´¢å¼• {index_name}ï¼ˆå¦‚å­˜åœ¨ï¼‰")

            # åˆ›å»ºæ–°ç´¢å¼•ï¼ˆæ ‡å‡† Cypher è¯­æ³•ï¼Œç¤¾åŒºç‰ˆå…¼å®¹ï¼‰
            session.run(f"""
            CREATE VECTOR INDEX {index_name}
            FOR (n:Entity)
            ON (n.embedding)
            OPTIONS {{
              indexConfig: {{
                `vector.dimensions`: {self.dim},
                `vector.similarity_function`: '{similarity}'
              }}
            }}
            """)
            print(f"[âœ“] å·²åˆ›å»ºæ–°å‘é‡ç´¢å¼• {index_name} on :Entity(embedding)")

    def _query_entity_knn(self, embedding: list, top_k: int = 5):
        """
        æŸ¥è¯¢ä¸è¾“å…¥ embedding å‘é‡æœ€ç›¸ä¼¼çš„ top-K èŠ‚ç‚¹
        """
        query = """
        CALL db.index.vector.queryNodes('entityEmbeddingIndex', $top_k, $embedding)
        YIELD node, score
        RETURN node.name AS name, labels(node) AS labels, node.id AS id, score
        ORDER BY score DESC
        """

        with self.driver.session() as session:
            result = session.run(query, {"embedding": embedding, "top_k": top_k})
            return result.data()

    def query_similar_entities(self, text: str, top_k: int = 5, normalize: bool = True):
        """
        ç»™å®šè‡ªç„¶è¯­è¨€ `text`ï¼Œè‡ªåŠ¨ç¼–ç ä¸º embeddingï¼ŒæŸ¥è¯¢æœ€ç›¸ä¼¼çš„å®ä½“èŠ‚ç‚¹ï¼ˆä½¿ç”¨ entityEmbeddingIndexï¼‰

        Args:
            text (str): æŸ¥è¯¢æ–‡æœ¬ï¼ˆå¦‚å®ä½“åã€äº‹ä»¶ç‰‡æ®µç­‰ï¼‰
            model: ä½ çš„ embedding æ¨¡å‹ï¼ˆéœ€æœ‰ encode æ–¹æ³•ï¼‰
            top_k (int): è¿”å›å‰ top-k ä¸ªç»“æœ
            normalize (bool): æ˜¯å¦æ ‡å‡†åŒ–å‘é‡ï¼ˆç¡®ä¿åŒ¹é… cosine ç´¢å¼•ï¼‰

        Returns:
            List[Dict]: åŒ…å« nameã€labelsã€idã€score çš„ç»“æœåˆ—è¡¨
        """
        embed = self.model.encode(text, normalize_embeddings=normalize).tolist()
        return self._query_entity_knn(embed, top_k=top_k)
    
    
    def create_subgraph(
        self,
        graph_name: str = "subgraph_1",
        exclude_node_labels: Optional[List[str]] = None,
        exclude_rel_types: Optional[List[str]] = None,
        force_refresh: bool = False,
    ) -> None:
        """
        åˆ›å»º/åˆ·æ–°ä¸€ä¸ª GDS å‘½åå­å›¾ï¼š
        - èŠ‚ç‚¹ï¼šå…¨å›¾èŠ‚ç‚¹ï¼Œä½†ä¼šæ’é™¤æŒ‡å®šæ ‡ç­¾ï¼ˆé»˜è®¤ :Sceneï¼‰
        - è¾¹  ï¼šæ’é™¤æŒ‡å®šå…³ç³»ç±»å‹ï¼ˆé»˜è®¤ SCENE_CONTAINSï¼‰
        
        Args:
            graph_name:            å­å›¾åç§°
            exclude_node_labels:   è¦æ’é™¤çš„èŠ‚ç‚¹æ ‡ç­¾åˆ—è¡¨ï¼Œé»˜è®¤ ["Scene"]
            exclude_rel_types:     è¦æ’é™¤çš„å…³ç³»ç±»å‹åˆ—è¡¨ï¼Œé»˜è®¤ ["SCENE_CONTAINS"]
            force_refresh:         å¦‚å­å›¾å·²å­˜åœ¨ï¼Œæ˜¯å¦å¼ºåˆ¶åˆ é™¤åé‡å»º
        """

        exclude_node_labels = exclude_node_labels or ["Scene"]
        exclude_rel_types   = exclude_rel_types   or ["SCENE_CONTAINS"]

        with self.driver.session() as s:
            # --- 1. è‹¥å·²å­˜åœ¨ä¸”è¦æ±‚åˆ·æ–°ï¼Œåˆ™åˆ é™¤ ---
            exists = s.run("RETURN gds.graph.exists($name) AS ok",
                        name=graph_name).single()["ok"]
            if exists and force_refresh:
                s.run("CALL gds.graph.drop($name, false)", name=graph_name)
                exists = False
                print(f"[âœ“] æ—§å­å›¾ {graph_name} å·²åˆ é™¤å¹¶åˆ·æ–°")

            if exists:
                print(f"[âœ“] GDS å­å›¾ {graph_name} å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º")
                return

            # --- 2. ç”ŸæˆèŠ‚ç‚¹ / å…³ç³» Cypher ---
            #   èŠ‚ç‚¹ï¼šæ’é™¤æŒ‡å®šæ ‡ç­¾
            label_filter = " AND ".join([f"NOT '{lbl}' IN labels(n)" for lbl in exclude_node_labels]) or "true"
            node_query = f"""
            MATCH (n) WHERE {label_filter}
            RETURN id(n) AS id
            """

            #   å…³ç³»ï¼šæ’é™¤æŒ‡å®šç±»å‹ & æ’é™¤ä¸è¢«æ’é™¤èŠ‚ç‚¹ç›¸è¿çš„è¾¹
            rel_filter = " AND ".join([f"type(r) <> '{rt}'" for rt in exclude_rel_types]) or "true"
            # é¢å¤–ä¿è¯ä¸¤ç«¯èŠ‚ç‚¹éƒ½ä¸æ˜¯è¢«æ’é™¤æ ‡ç­¾
            node_label_neg = " AND ".join([f"NOT '{lbl}' IN labels(a)" for lbl in exclude_node_labels] +
                                        [f"NOT '{lbl}' IN labels(b)" for lbl in exclude_node_labels]) or "true"

            rel_query = f"""
            MATCH (a)-[r]->(b)
            WHERE {rel_filter} AND {node_label_neg}
            RETURN id(a) AS source, id(b) AS target
            """

            # --- 3. è°ƒç”¨ project.cypher ---
            s.run("""
            CALL gds.graph.project.cypher(
            $name,
            $nodeQuery,
            $relQuery
            )
            """, name=graph_name, nodeQuery=node_query, relQuery=rel_query)

            print(f"[+] å·²åˆ›å»º GDS å­å›¾ {graph_name}ï¼ˆæ’é™¤æ ‡ç­¾ {exclude_node_labels}ï¼Œæ’é™¤è¾¹ {exclude_rel_types}ï¼‰")

    def run_louvain(
        self,
        graph_name: str = "event_graph",
        write_property: str = "community",
        max_iterations: int = 20,
        force_run: bool = False
    ) -> None:
        """
        åœ¨æŒ‡å®šå­å›¾ä¸Šè·‘ Louvainï¼›è‹¥å·²å†™è¿‡å±æ€§ä¸” !force_run åˆ™è·³è¿‡
        """
        with self.driver.session() as s:
            if not force_run:
                # å¿«é€Ÿæ£€æµ‹æ˜¯å¦å·²æœ‰ç¤¾åŒºå­—æ®µ
                has_prop = s.run("""
                    MATCH (n) WHERE exists(n[$prop]) RETURN n LIMIT 1
                """, prop=write_property).single()
                if has_prop:
                    print(f"[âœ“] èŠ‚ç‚¹å·²å­˜åœ¨ {write_property}ï¼Œè·³è¿‡ Louvain")
                    return

            s.run(f"""
            CALL gds.louvain.write($graph, {{
              writeProperty: $prop,
              maxIterations: $iters
            }});
            """, graph=graph_name, prop=write_property, iters=max_iterations)
            print(f"[+] Louvain å·²å®Œæˆï¼Œç»“æœå†™å…¥ `{write_property}`")

    # === 3. å–åŒç¤¾åŒºäº‹ä»¶å¯¹ ===
    def fetch_event_pairs_same_community(
        self,
        max_depth: int = 3,
        max_pairs: Optional[int] = None
    ) -> List[Dict[str, str]]:
        """
        è¿”å›åŒç¤¾åŒº & è·¯å¾„åœ¨ max_depth å†…å¯è¾¾çš„äº‹ä»¶å¯¹ ID åˆ—è¡¨
        """
        q = f"""
        MATCH (e1:Event)
        MATCH (e2:Event)
        WHERE e1.community = e2.community AND id(e1) < id(e2)
          AND EXISTS {{
              MATCH p = (e1)-[*1..{max_depth}]-(e2)
              WHERE ALL(r IN relationships(p) WHERE type(r) <> 'SCENE_CONTAINS')
          }}
        RETURN e1.id AS srcId, e2.id AS dstId
        """ + (f"LIMIT {max_pairs}" if max_pairs else "")
        return self.execute_query(q)

    def write_event_causes(self, rows: List[Dict[str, Any]]) -> None:
        """
        rows: [{srcId, dstId, weight, reason}]
        """
        if not rows:
            return
        self.execute_query("""
        UNWIND $rows AS row
        MATCH (s:Event {id: row.srcId})
        MATCH (t:Event {id: row.dstId})
        MERGE (s)-[ca:EVENT_CAUSES]->(t)
        SET ca.weight = row.weight,
            ca.reason = row.reason,
            ca.predicate = row.predicate
        """, {"rows": rows})
        print(f"[+] å·²å†™å…¥/æ›´æ–° EVENT_CAUSES å…³ç³» {len(rows)} æ¡")
    
    def get_all_events_with_causality(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰äº‹ä»¶åŠå…¶å› æœå…³ç³»ä¿¡æ¯
        
        Returns:
            List[Dict]: åŒ…å«äº‹ä»¶IDã€å±æ€§å’Œå› æœå…³ç³»çš„åˆ—è¡¨
        """
        cypher = """
        MATCH (e:Event)
        OPTIONAL MATCH (e)-[r:EVENT_CAUSES]->(target:Event)
        OPTIONAL MATCH (source:Event)-[r2:EVENT_CAUSES]->(e)
        RETURN e.id as event_id, 
            e.name as event_name,
            e.description as event_description,
            e.participants as participants,
            collect(DISTINCT {target: target.id, weight: r.weight}) as outgoing_causes,
            collect(DISTINCT {source: source.id, weight: r2.weight}) as incoming_causes
        """
        
        result = self.execute_query(cypher)
        return [dict(record) for record in result]

    def get_causality_edges_by_weight(self, threshold: str = "Medium") -> List[Dict[str, Any]]:
        """
        æ ¹æ®æƒé‡é˜ˆå€¼è·å–å› æœå…³ç³»è¾¹
        
        Args:
            threshold: æƒé‡é˜ˆå€¼ ("High", "Medium", "Low")
            
        Returns:
            List[Dict]: å› æœå…³ç³»è¾¹åˆ—è¡¨
        """
        # å®šä¹‰æƒé‡æ˜ å°„
        weight_hierarchy = {
            "High": 1.0,
            "Medium": 0.6, 
            "Low": 0.3
        }
        
        weight_threshold = weight_hierarchy.get(threshold, 0.6)
        
        cypher = """
        MATCH (source:Event)-[r:EVENT_CAUSES]->(target:Event)
        WHERE r.weight >= $weight_threshold
        RETURN source.id AS source_id, 
            target.id AS target_id, 
            r.weight AS weight
        """
        
        params = {"weight_threshold": weight_threshold}
        result = self.execute_query(cypher, params)
        return [dict(record) for record in result]

    def identify_event_clusters_by_connectivity(self, threshold: str = "Medium") -> List[List[str]]:
        """
        ä½¿ç”¨GDSè¿é€šåˆ†é‡ç®—æ³•è¯†åˆ«äº‹ä»¶èšç±»
        
        Args:
            threshold: å› æœå…³ç³»æƒé‡é˜ˆå€¼
            
        Returns:
            List[List[str]]: äº‹ä»¶èšç±»åˆ—è¡¨ï¼Œæ¯ä¸ªèšç±»åŒ…å«äº‹ä»¶IDåˆ—è¡¨
        """
        # 1. åˆ›å»ºåŸºäºæƒé‡é˜ˆå€¼çš„æŠ•å½±å›¾
        graph_name = f"event_causality_graph_{threshold.lower()}"
        
        # åˆ é™¤å¯èƒ½å­˜åœ¨çš„æ—§å›¾
        drop_cypher = f"CALL gds.graph.drop('{graph_name}') YIELD graphName"
        try:
            self.execute_query(drop_cypher)
        except:
            pass  # å›¾ä¸å­˜åœ¨æ—¶å¿½ç•¥é”™è¯¯
        
        # è·å–æƒé‡è¿‡æ»¤æ¡ä»¶
        weight_hierarchy = {
            "High": 1.0,
            "Medium": 0.6, 
            "Low": 0.3
        }
        weight_threshold = weight_hierarchy.get(threshold, 0.6)
        
        # åˆ›å»ºæŠ•å½±å›¾ - åªåŒ…å«æ»¡è¶³æƒé‡æ¡ä»¶çš„å…³ç³»
        create_graph_cypher = f"""
        CALL gds.graph.project.cypher(
            '{graph_name}',
            'MATCH (n:Event) RETURN id(n) AS id',
            'MATCH (a:Event)-[r:EVENT_CAUSES]->(b:Event) 
            WHERE r.weight >= {weight_threshold}
            RETURN id(a) AS source, id(b) AS target, r.weight AS weight'
        )
        """
        # print("[CHECK] create_graph_cypher", create_graph_cypher)
        
        self.execute_query(create_graph_cypher)
        
        # 2. è¿è¡Œè¿é€šåˆ†é‡ç®—æ³•
        wcc_cypher = f"""
        CALL gds.wcc.stream('{graph_name}')
        YIELD nodeId, componentId
        RETURN gds.util.asNode(nodeId).id as event_id, componentId
        ORDER BY componentId, event_id
        """
        
        result = self.execute_query(wcc_cypher)
        # print("[CHECK] result: ", result)
        
        # 3. ç»„ç»‡ç»“æœä¸ºèšç±»
        clusters = {}
        for record in result:
            component_id = record['componentId']
            event_id = record['event_id']
            
            if component_id not in clusters:
                clusters[component_id] = []
            clusters[component_id].append(event_id)
        
        # print("[CHECK] clusters: ", clusters)
        # 4. æ¸…ç†å›¾
        # self.execute_query(drop_cypher)
        
        # 5. è¿‡æ»¤èšç±» - åªä¿ç•™é€šè¿‡æƒé‡é˜ˆå€¼è¿æ¥çš„äº‹ä»¶
        filtered_clusters = []
        edges = self.get_causality_edges_by_weight(threshold)
        # print("[CHECK] edges: ", edges)
        
        # æ„å»ºæ»¡è¶³æƒé‡æ¡ä»¶çš„è¿æ¥å›¾
        connected_events = set()
        for edge in edges:
            connected_events.add(edge['source_id'])
            connected_events.add(edge['target_id'])
        
        for cluster in clusters.values():
            # åªä¿ç•™æœ‰æ»¡è¶³æƒé‡æ¡ä»¶è¿æ¥çš„èšç±»ï¼Œä¸”èšç±»å¤§å°å¤§äº1
            if len(cluster) > 1:
                cluster_has_valid_connections = any(event_id in connected_events for event_id in cluster)
                if cluster_has_valid_connections:
                    filtered_clusters.append(cluster)
        
        return filtered_clusters
            

    def _fallback_clustering(self, threshold: str) -> List[List[str]]:
        """
        é™çº§èšç±»æ–¹æ³•ï¼šåŸºäºç›´æ¥å› æœå…³ç³»çš„ç®€å•èšç±»
        
        Args:
            threshold: æƒé‡é˜ˆå€¼
            
        Returns:
            List[List[str]]: äº‹ä»¶èšç±»åˆ—è¡¨
        """
        edges = self.get_causality_edges_by_weight(threshold)
        
        # æ„å»ºé‚»æ¥è¡¨
        graph = {}
        all_events = set()
        
        for edge in edges:
            source = edge['source_id']
            target = edge['target_id']
            
            all_events.add(source)
            all_events.add(target)
            
            if source not in graph:
                graph[source] = []
            if target not in graph:
                graph[target] = []
                
            graph[source].append(target)
            graph[target].append(source)  # æ— å‘å›¾
        
        # DFSæŸ¥æ‰¾è¿é€šåˆ†é‡
        visited = set()
        clusters = []
        
        def dfs(node, current_cluster):
            if node in visited:
                return
            visited.add(node)
            current_cluster.append(node)
            
            for neighbor in graph.get(node, []):
                dfs(neighbor, current_cluster)
        
        for event in all_events:
            if event not in visited:
                cluster = []
                dfs(event, cluster)
                if len(cluster) > 1:  # åªä¿ç•™æœ‰å¤šä¸ªäº‹ä»¶çš„èšç±»
                    clusters.append(cluster)
        
        return clusters

    def get_event_details(self, event_ids: List[str]) -> List[Dict[str, Any]]:
        """
        è·å–äº‹ä»¶è¯¦ç»†ä¿¡æ¯
        
        Args:
            event_ids: äº‹ä»¶IDåˆ—è¡¨
            
        Returns:
            List[Dict]: äº‹ä»¶è¯¦ç»†ä¿¡æ¯åˆ—è¡¨
        """
        cypher = """
        MATCH (e:Event)
        WHERE e.id IN $event_ids
        OPTIONAL MATCH (s:Scene)-[:SCENE_CONTAINS]->(e)
        RETURN e.id as event_id,
            e.name as event_name,
            e.description as event_description,
            e.participants as participants,
            e.location as location,
            e.time as time,
            collect(DISTINCT s.id) as scene_ids,
            collect(DISTINCT s.name) as scene_names
        """
        
        params = {"event_ids": event_ids}
        result = self.execute_query(cypher, params)
        return [dict(record) for record in result]

    def get_causality_paths(self, event_ids: List[str]) -> List[Dict[str, Any]]:
        """
        è·å–äº‹ä»¶é—´çš„å› æœè·¯å¾„
        
        Args:
            event_ids: äº‹ä»¶IDåˆ—è¡¨
            
        Returns:
            List[Dict]: å› æœè·¯å¾„ä¿¡æ¯
        """
        cypher = """
        MATCH (source:Event)-[r:EVENT_CAUSES]->(target:Event)
        WHERE source.id IN $event_ids AND target.id IN $event_ids
        RETURN source.id as source_id,
            source.name as source_name,
            target.id as target_id,
            target.name as target_name,
            r.weight as weight,
            r.description as causality_description
        ORDER BY 
            CASE r.weight 
                WHEN 'High' THEN 1 
                WHEN 'Medium' THEN 2 
                WHEN 'Low' THEN 3 
                ELSE 4 
            END
        """
        
        params = {"event_ids": event_ids}
        result = self.execute_query(cypher, params)
        return [dict(record) for record in result]

    def create_plot_node(self, plot_data: Dict[str, Any]) -> bool:
        """
        åˆ›å»ºPlotèŠ‚ç‚¹
        
        Args:
            plot_data: Plotæ•°æ®å­—å…¸
            
        Returns:
            bool: åˆ›å»ºæ˜¯å¦æˆåŠŸ
        """
        cypher = """
        CREATE (p:Plot {
            id: $plot_id,
            title: $title,
            summary: $summary,
            structure_type: $structure_type,
            narrative_roles: $narrative_roles,
            created_at: datetime()
        })
        RETURN p.id as plot_id
        """
        
        params = {
            "plot_id": plot_data["id"],
            "title": plot_data["title"],
            "summary": plot_data["summary"],
            "structure_type": plot_data.get("structure", {}).get("type", "èµ·æ‰¿è½¬åˆ"),
            "narrative_roles": str(plot_data.get("structure", {}).get("narrative_roles", {}))
        }
        
        try:
            result = self.execute_query(cypher, params)
            return len(list(result)) > 0
        except Exception as e:
            print(f"åˆ›å»ºPlotèŠ‚ç‚¹å¤±è´¥: {e}")
            return False

    def create_has_event_relationships(self, plot_id: str, event_ids: List[str]) -> bool:
        """
        åˆ›å»ºHAS_EVENTå…³ç³»
        
        Args:
            plot_id: Plot ID
            event_ids: äº‹ä»¶IDåˆ—è¡¨
            
        Returns:
            bool: åˆ›å»ºæ˜¯å¦æˆåŠŸ
        """
        cypher = """
        MATCH (p:Plot {id: $plot_id})
        MATCH (e:Event)
        WHERE e.id IN $event_ids
        CREATE (p)-[:HAS_EVENT]->(e)
        RETURN count(*) as relationships_created
        """
        
        params = {
            "plot_id": plot_id,
            "event_ids": event_ids
        }
        
        try:
            result = self.execute_query(cypher, params)
            count = list(result)[0]['relationships_created']
            return count == len(event_ids)
        except Exception as e:
            print(f"åˆ›å»ºHAS_EVENTå…³ç³»å¤±è´¥: {e}")
            return False

    def write_plot_to_neo4j(self, plot_data: Dict[str, Any]) -> bool:
        """
        å®Œæ•´çš„Plotå†™å…¥åŠŸèƒ½
        
        Args:
            plot_data: Plotæ•°æ®å­—å…¸ï¼ŒåŒ…å«idã€titleã€summaryã€event_idsã€structure
            
        Returns:
            bool: å†™å…¥æ˜¯å¦æˆåŠŸ
        """
        try:
            # 1. åˆ›å»ºPlotèŠ‚ç‚¹
            if not self.create_plot_node(plot_data):
                return False
            
            # 2. åˆ›å»ºHAS_EVENTå…³ç³»
            event_ids = plot_data.get("event_ids", [])
            if event_ids and not self.create_has_event_relationships(plot_data["id"], event_ids):
                return False
            
            print(f"æˆåŠŸå†™å…¥Plot: {plot_data['id']}")
            return True
            
        except Exception as e:
            print(f"å†™å…¥Plotåˆ°Neo4jå¤±è´¥: {e}")
            return False

    def get_plot_statistics(self) -> Dict[str, int]:
        """
        è·å–Plotå›¾è°±ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict[str, int]: ç»Ÿè®¡ä¿¡æ¯
        """
        cypher = """
        MATCH (p:Plot)
        OPTIONAL MATCH (p)-[:HAS_EVENT]->(e:Event)
        OPTIONAL MATCH (s:Scene)-[:SCENE_CONTAINS]->(e)
        RETURN count(DISTINCT p) as plot_count,
            count(DISTINCT e) as event_count,
            count(DISTINCT s) as scene_count
        """
        
        result = self.execute_query(cypher)
        return dict(list(result)[0])
    
    