"""
äº‹ä»¶å› æœå›¾æ„å»ºå™¨
è´Ÿè´£æ„å»ºäº‹ä»¶å› æœå…³ç³»çš„æœ‰å‘å¸¦æƒå›¾
"""

import json
import pickle
import networkx as nx
from typing import List, Dict, Tuple, Optional, Any
from tqdm import tqdm
from pathlib import Path
from kag.llm.llm_manager import LLMManager
from kag.utils.neo4j_utils import Neo4jUtils
from kag.models.entities import Entity
from kag.builder.extractor import InformationExtractor
from ..storage.graph_store import GraphStore

class EventCausalityBuilder:
    """
    äº‹ä»¶å› æœå›¾æ„å»ºå™¨
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. ä»Neo4jåŠ è½½å’Œæ’åºäº‹ä»¶
    2. é€šè¿‡è¿é€šä½“å’Œç¤¾åŒºè¿‡æ»¤äº‹ä»¶å¯¹
    3. ä½¿ç”¨extractoræ£€æŸ¥å› æœå…³ç³»
    4. æ„å»ºæœ‰å‘å¸¦æƒNetworkXå›¾
    5. ä¿å­˜å’ŒåŠ è½½å›¾æ•°æ®
    """
    
    def __init__(self, config):
        """
        åˆå§‹åŒ–äº‹ä»¶å› æœå›¾æ„å»ºå™¨
        
        Args:
            config: KAGé…ç½®å¯¹è±¡
        """
        self.config = config
        self.llm_manager = LLMManager(config)
        self.llm = self.llm_manager.get_llm()
        self.graph_store = GraphStore(config)
        self.neo4j_utils = Neo4jUtils(self.graph_store.driver)
        self.extractor = InformationExtractor(config, self.llm)
        self.event_fallback = [] # å¯ä»¥åŠ å…¥Goalå’ŒAction

        # ç¼“å­˜æ•°æ®
        self.load_abbreviations("kag/schema/settings_schema.json")
        
        self.sorted_scenes = []
        self.event_list = []
        self.event2scene_map = {}
        self.allowed_rels = []
        self.max_depth = 3
        
        # å› æœå…³ç³»å¼ºåº¦åˆ°æƒé‡çš„æ˜ å°„
        self.causality_weight_map = {
            "High": 1.0,
            "Medium": 0.6,
            "Low": 0.3
        }
    
    def load_abbreviations(self, path: str):
        """
        ä»JSONæ–‡ä»¶åŠ è½½ç¼©å†™åˆ—è¡¨ï¼Œè¿”å›æ ¼å¼åŒ–åçš„æ–‡æœ¬ï¼ˆé€‚åˆæ’å…¥æç¤ºè¯ï¼‰
        
        Args:
            path: ç¼©å†™æ–‡ä»¶è·¯å¾„
        """
        with open(path, 'r', encoding='utf-8') as f:
            abbr = json.load(f)
        abbr_list = abbr.get("abbreviations", [])

        formatted = []
        for item in abbr_list:
            line = f"- **{item['abbr']}**: {item['full']}ï¼ˆ{item['zh']}ï¼‰ - {item['description']}"
            formatted.append(line)
        self.abbreviation_info = "\n".join(formatted)
        
        print(f"âœ… å·²åŠ è½½ {len(abbr_list)} ä¸ªç¼©å†™å®šä¹‰")
    
    def build_event_list(self) -> List[Entity]:
        """
        æ„å»ºæ’åºåçš„äº‹ä»¶åˆ—è¡¨
        
        Returns:
            æ’åºåçš„äº‹ä»¶åˆ—è¡¨
        """
        print("ğŸ” å¼€å§‹æ„å»ºäº‹ä»¶åˆ—è¡¨...")
        
        # 1. è·å–æ‰€æœ‰åœºæ™¯å¹¶æ’åº
        scene_entities = self.neo4j_utils.search_entities_by_type(
            entity_type="Scene", 
            limit=500
        )
        
        self.sorted_scenes = sorted(
            scene_entities,
            key=lambda e: (
                int(e.properties.get("scene_number", 0)),
                int(e.properties.get("sub_scene_number", 0))
            )
        )
        
        print(f"âœ… æ‰¾åˆ° {len(self.sorted_scenes)} ä¸ªåœºæ™¯")
        
        # 2. ä»åœºæ™¯ä¸­æå–äº‹ä»¶
        event_list = []
        event2scene_map = {}
        
        for scene in tqdm(self.sorted_scenes, desc="æå–åœºæ™¯ä¸­çš„äº‹ä»¶"):
            # ä¼˜å…ˆæŸ¥æ‰¾äº‹ä»¶
            results = self.neo4j_utils.search_related_entities(
                source_id=scene.id, 
                predicate="SCENE_CONTAINS", 
                entity_types=["Event"], 
                return_relations=False
            )
            
            # å¦‚æœåœºæ™¯ä¸­æ²¡æœ‰äº‹ä»¶ï¼Œåˆ™ç”¨åŠ¨ä½œæˆ–è€…ç›®æ ‡æ¥å¡«å……
            if not results and self.event_fallback:
                results = self.neo4j_utils.search_related_entities(
                    source_id=scene.id, 
                    predicate="SCENE_CONTAINS", 
                    entity_types=self.event_fallback, 
                    return_relations=False
                )
            
            for result in results:
                if result.id not in event2scene_map:
                    event2scene_map[result.id] = scene.id
                    event_list.append(result)
        
        self.event_list = event_list
        self.event2scene_map = event2scene_map
        
        print(f"âœ… æ„å»ºå®Œæˆï¼Œå…±æ‰¾åˆ° {len(event_list)} ä¸ªäº‹ä»¶")
        return event_list
    
    def get_event_info(self, event_id: str, event_tag: int = 1) -> str:
        """
        è·å–äº‹ä»¶çš„è¯¦ç»†ä¿¡æ¯ï¼Œç”¨äºå› æœå…³ç³»æ£€æŸ¥
        
        Args:
            event_id: äº‹ä»¶ID
            event_tag: äº‹ä»¶æ ‡ç­¾ï¼ˆç”¨äºåŒºåˆ†äº‹ä»¶1å’Œäº‹ä»¶2ï¼‰
            
        Returns:
            æ ¼å¼åŒ–çš„äº‹ä»¶ä¿¡æ¯å­—ç¬¦ä¸²
        """
        event_node = self.neo4j_utils.get_entity_by_id(event_id)
        if not event_node:
            return f"äº‹ä»¶{event_tag}ï¼šæœªæ‰¾åˆ°äº‹ä»¶ä¿¡æ¯"
        
        results = self.neo4j_utils.search_related_entities(
            source_id=event_id, 
            return_relations=True
        )
        
        relevant_info = []
        for result in results:
            info = self._get_relation_info(result[1])
            if info:
                relevant_info.append(info)
        
        context = (
            f"äº‹ä»¶{event_tag}ï¼ˆ{event_node.name}ï¼‰ï¼š{event_node.properties.get('description', 'æ— å…·ä½“æè¿°')}\n"
            f"ç›¸å…³ä¿¡æ¯æœ‰ï¼š\n" + "\n".join(relevant_info)
        )
        return context
    
    def _get_relation_info(self, relation) -> Optional[str]:
        """
        è·å–å…³ç³»ä¿¡æ¯çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        
        Args:
            relation: å…³ç³»å¯¹è±¡
            
        Returns:
            æ ¼å¼åŒ–çš„å…³ç³»ä¿¡æ¯ï¼Œå¦‚æœæ˜¯SCENE_CONTAINSåˆ™è¿”å›None
        """
        if relation.predicate == "SCENE_CONTAINS":
            return None
            
        subject_id = relation.subject_id
        subject_name = self.neo4j_utils.get_entity_by_id(subject_id).name
        object_id = relation.object_id
        object_name = self.neo4j_utils.get_entity_by_id(object_id).name
        relation_name = relation.properties.get("relation_name", relation.predicate)
        description = relation.properties.get("description", "")
        
        return f"{subject_name}-{relation_name}->{object_name}: {description}"
    
    def filter_event_pairs_by_community(
        self, 
        events: List[Entity],
    ) -> List[Tuple[Entity, Entity]]:
        """
        é€šè¿‡è¿é€šä½“å’Œç¤¾åŒºè¿‡æ»¤äº‹ä»¶å¯¹
        
        Args:
            events: äº‹ä»¶åˆ—è¡¨
            
        Returns:
            è¿‡æ»¤åçš„äº‹ä»¶å¯¹åˆ—è¡¨
        """
        print("ğŸ” å¼€å§‹ç¤¾åŒºè¿‡æ»¤...")
        
        # 1. è·å–å…è®¸çš„å…³ç³»ç±»å‹ï¼ˆæ’é™¤SCENE_CONTAINSï¼‰
        self.allowed_rels = self.neo4j_utils.list_relationship_types()
        if "SCENE_CONTAINS" in self.allowed_rels:
            self.allowed_rels.remove("SCENE_CONTAINS")
        
        print(f"âœ… ä½¿ç”¨å…³ç³»ç±»å‹: {len(self.allowed_rels)} ç§")
        
        # 2. æ„å»ºè¿‡æ»¤åçš„å›¾
        G = self.neo4j_utils.build_filtered_graph(set(self.allowed_rels))
        print(f"âœ… å›¾æ„å»ºå®Œæˆï¼ŒèŠ‚ç‚¹æ•°: {G.number_of_nodes()}ï¼Œè¾¹æ•°: {G.number_of_edges()}")
        
        # 3. æ‰§è¡Œè¿é€šä½“ + Louvain ç¤¾åŒºåˆ’åˆ†
        print("ğŸ” æ‰§è¡Œè¿é€šä½“ + Louvain ç¤¾åŒºåˆ’åˆ†ä¸­...")
        node_cluster_map = self.neo4j_utils.assign_components_and_communities(G)
        
        print(f"âœ… åˆ’åˆ†å®Œæˆï¼Œå…±æœ‰ {len(set(c for c, _ in node_cluster_map.values()))} ä¸ªè¿é€šä½“ï¼Œ"
              f"{len(set((c, comm) for c, comm in node_cluster_map.values()))} ä¸ªç¤¾åŒº")
        
        # 4. ç­›é€‰åŒä¸€ç¤¾åŒºå†…çš„äº‹ä»¶å¯¹
        exist_count = 0
        nonexist_count = 0
        total_pairs = 0
        accepted_pairs = []
        
        print("ğŸ” å¼€å§‹ç­›é€‰ç¤¾åŒºå†…éƒ¨äº‹ä»¶å¯¹...")
        
        for i in tqdm(range(len(events))):
            for j in range(i + 1, len(events)):
                e1 = events[i]
                e2 = events[j]

                key1 = node_cluster_map.get(e1.id)
                key2 = node_cluster_map.get(e2.id)

                if not key1 or not key2:
                    continue

                if key1 == key2:
                    exist_count += 1
                    accepted_pairs.append((e1, e2))
                else:
                    nonexist_count += 1

                total_pairs += 1
        
        print(f"âœ… æ€»å…±å¯¹æ¯”: {total_pairs} å¯¹")
        print(f"âœ… åŒä¸€ç¤¾åŒºå†…: {exist_count} å¯¹")
        print(f"âŒ ä¸åŒç¤¾åŒºè·³è¿‡: {nonexist_count} å¯¹")
        
        # 5. è¿›ä¸€æ­¥é€šè¿‡è·¯å¾„è¿é€šæ€§è¿‡æ»¤
        filtered_pairs = []
        
        for src_node, tgt_node in tqdm(accepted_pairs, desc="ğŸ” ç­›é€‰è·¯å¾„è¿é€šçš„äº‹ä»¶å¯¹"):
            src_id, tgt_id = src_node.id, tgt_node.id

            # è¿é€šä½“å¾ˆå°ï¼Œç›´æ¥é€šè¿‡
            component_id, _ = node_cluster_map[src_id]
            component_size = sum(1 for c, _ in node_cluster_map.values() if c == component_id)
            if component_size < self.max_depth:
                filtered_pairs.append((src_node, tgt_node))
                continue

            # è¿›ä¸€æ­¥åœ¨ max_depth å†…æœç´¢è·¯å¾„
            if self.neo4j_utils.has_path_between_nx(G, src_id, tgt_id, max_depth=self.max_depth):
                filtered_pairs.append((src_node, tgt_node))
        
        print(f"âœ… è·¯å¾„è¿‡æ»¤å®Œæˆï¼Œæœ€ç»ˆä¿ç•™ {len(filtered_pairs)} å¯¹äº‹ä»¶")
        return filtered_pairs
    
    def check_causality_batch(
        self, 
        pairs: List[Tuple[Entity, Entity]]
    ) -> Dict[Tuple[str, str], Dict[str, Any]]:
        """
        æ‰¹é‡æ£€æŸ¥äº‹ä»¶å¯¹çš„å› æœå…³ç³»
        
        Args:
            pairs: äº‹ä»¶å¯¹åˆ—è¡¨
            
        Returns:
            äº‹ä»¶å¯¹IDåˆ°å› æœå…³ç³»ç»“æœçš„æ˜ å°„
        """
        print(f"ğŸ” å¼€å§‹æ‰¹é‡æ£€æŸ¥ {len(pairs)} å¯¹äº‹ä»¶çš„å› æœå…³ç³»...")
        
        causality_results = {}
        
        for src_event, tgt_event in tqdm(pairs, desc="æ£€æŸ¥å› æœå…³ç³»"):
            # è·å–äº‹ä»¶ä¿¡æ¯
            event_1_info = self.get_event_info(src_event.id, 1)
            event_2_info = self.get_event_info(tgt_event.id, 2)
            
            # è°ƒç”¨extractoræ£€æŸ¥å› æœå…³ç³»
            try:
                result_json_str = self.extractor.check_event_causality(
                    event_1_info, 
                    event_2_info, 
                    self.abbreviation_info
                )
                
                # è§£æJSONç»“æœ
                result_dict = json.loads(result_json_str)
                
                # å­˜å‚¨ç»“æœï¼ŒåŒ…æ‹¬æ–°çš„reverseå­—æ®µ
                pair_key = (src_event.id, tgt_event.id)
                causality_results[pair_key] = {
                    'src_event': src_event,
                    'tgt_event': tgt_event,
                    'causal': result_dict.get('causal', 'Low'),
                    'reason': result_dict.get('reason', ''),
                    'reverse': result_dict.get('reverse', False),  # æ–°å¢ï¼šæ˜¯å¦åè½¬å› æœæ–¹å‘
                    'raw_result': result_json_str
                }
                
            except Exception as e:
                print(f"âš ï¸ æ£€æŸ¥äº‹ä»¶å¯¹ {src_event.id} -> {tgt_event.id} æ—¶å‡ºé”™: {e}")
                pair_key = (src_event.id, tgt_event.id)
                causality_results[pair_key] = {
                    'src_event': src_event,
                    'tgt_event': tgt_event,
                    'causal': 'Low',
                    'reason': f'æ£€æŸ¥è¿‡ç¨‹å‡ºé”™: {e}',
                    'reverse': False,  # å‡ºé”™æ—¶é»˜è®¤ä¸åè½¬
                    'raw_result': ''
                }
        
        print(f"âœ… å› æœå…³ç³»æ£€æŸ¥å®Œæˆ")
        return causality_results
    
    def build_causality_graph(
        self, 
        causality_results: Dict[Tuple[str, str], Dict[str, Any]]
    ) -> nx.DiGraph:
        """
        æ„å»ºäº‹ä»¶å› æœå…³ç³»çš„æœ‰å‘å¸¦æƒå›¾
        
        Args:
            causality_results: å› æœå…³ç³»æ£€æŸ¥ç»“æœ
            
        Returns:
            NetworkXæœ‰å‘å›¾
        """
        print("ğŸ” å¼€å§‹æ„å»ºå› æœå…³ç³»å›¾...")
        
        G = nx.DiGraph()
        
        # æ·»åŠ èŠ‚ç‚¹å’Œè¾¹
        for pair_key, result in causality_results.items():
            src_id, tgt_id = pair_key
            src_event = result['src_event']
            tgt_event = result['tgt_event']
            causal_level = result['causal']
            reason = result['reason']
            reverse = result.get('reverse', False)  # è·å–reverseå­—æ®µ
            
            # æ ¹æ®scene_idæ’åºå†³å®šåˆå§‹è¾¹çš„æ–¹å‘
            src_scene_id = self.event2scene_map.get(src_id)
            tgt_scene_id = self.event2scene_map.get(tgt_id)
            
            if src_scene_id and tgt_scene_id:
                src_scene = self.neo4j_utils.get_entity_by_id(src_scene_id)
                tgt_scene = self.neo4j_utils.get_entity_by_id(tgt_scene_id)
                
                if src_scene and tgt_scene:
                    # æ¯”è¾ƒscene_idå’Œsub_scene_id
                    src_scene_num = int(src_scene.properties.get("scene_number", 0))
                    src_sub_scene_num = int(src_scene.properties.get("sub_scene_number", 0))
                    tgt_scene_num = int(tgt_scene.properties.get("scene_number", 0))
                    tgt_sub_scene_num = int(tgt_scene.properties.get("sub_scene_number", 0))
                    
                    # ç¡®å®šåˆå§‹è¾¹çš„æ–¹å‘ï¼šè¾ƒæ—©çš„äº‹ä»¶æŒ‡å‘è¾ƒæ™šçš„äº‹ä»¶
                    if (src_scene_num, src_sub_scene_num) <= (tgt_scene_num, tgt_sub_scene_num):
                        from_id, to_id = src_id, tgt_id
                        from_event, to_event = src_event, tgt_event
                        from_scene, to_scene = src_scene, tgt_scene   
                    else:
                        from_id, to_id = tgt_id, src_id
                        from_event, to_event = tgt_event, src_event
                        from_scene, to_scene = tgt_scene, src_scene 
                    
                    # æ ¹æ®reverseå­—æ®µå†³å®šæ˜¯å¦åè½¬æ–¹å‘
                    if reverse:
                        # å¦‚æœreverseä¸ºTrueï¼Œåè½¬å› æœæ–¹å‘
                        from_id, to_id = to_id, from_id
                        from_event, to_event = to_event, from_event
                        from_scene, to_scene = to_scene, from_scene
                        print(f"ğŸ”„ åè½¬å› æœæ–¹å‘: {from_event.name} -> {to_event.name}")
                    
                    # æ·»åŠ èŠ‚ç‚¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                    if not G.has_node(from_id):
                        G.add_node(from_id, 
                                  name=from_event.name,
                                  description=from_event.properties.get("description", ""),
                                  # scene_id=self.event2scene_map.get(from_id),
                                  scene_name = from_scene.name if from_scene else None,
                                  entity_type=from_event.type)
                    
                    if not G.has_node(to_id):
                        G.add_node(to_id, 
                                  name=to_event.name,
                                  description=to_event.properties.get("description", ""),
                                  # scene_id=self.event2scene_map.get(to_id),
                                  scene_name = to_scene.name if to_scene else None,
                                  entity_type=to_event.type)
                    
                    # æ·»åŠ è¾¹ï¼ˆå¸¦æƒé‡ï¼‰
                    weight = self.causality_weight_map.get(causal_level, 0.3)
                    G.add_edge(from_id, to_id,
                              weight=weight,
                              causal_level=causal_level,
                              reason=reason,
                              reverse=reverse,  # ä¿å­˜reverseä¿¡æ¯
                              raw_result=result.get('raw_result', ''))
        
        print(f"âœ… å› æœå…³ç³»å›¾æ„å»ºå®Œæˆ")
        print(f"   èŠ‚ç‚¹æ•°: {G.number_of_nodes()}")
        print(f"   è¾¹æ•°: {G.number_of_edges()}")
        
        # ç»Ÿè®¡å› æœå…³ç³»å¼ºåº¦åˆ†å¸ƒ
        causal_levels = [data['causal_level'] for _, _, data in G.edges(data=True)]
        level_counts = {level: causal_levels.count(level) for level in set(causal_levels)}
        print(f"   å› æœå…³ç³»å¼ºåº¦åˆ†å¸ƒ: {level_counts}")
        
        # ç»Ÿè®¡åè½¬è¾¹çš„æ•°é‡
        reversed_edges = [data for _, _, data in G.edges(data=True) if data.get('reverse', False)]
        print(f"   åè½¬è¾¹æ•°é‡: {len(reversed_edges)}")
        
        return G
    
    def save_graph(self, graph: nx.DiGraph, filepath: str):
        """
        ä¿å­˜å›¾åˆ°æ–‡ä»¶
        
        Args:
            graph: NetworkXæœ‰å‘å›¾
            filepath: ä¿å­˜è·¯å¾„
        """
        filepath = Path(filepath)
        filepath.parent.mkdir(parents=True, exist_ok=True)
    
        with open(filepath, 'wb') as f:
            pickle.dump(graph, f)
        
        print(f"âœ… å›¾å·²ä¿å­˜åˆ°: {filepath}")
    
    def load_graph(self, filepath: str, format: str = 'graphml') -> nx.DiGraph:
        """
        ä»æ–‡ä»¶åŠ è½½å›¾
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            
        Returns:
            NetworkXæœ‰å‘å›¾
        """
        with open(filepath, 'rb') as f:
            graph = pickle.load(f)
            
        print(f"âœ… å›¾å·²ä» {filepath} åŠ è½½")
        return graph
    
    def build_complete_causality_graph(
        self,
        limit_events: Optional[int] = None,
    ) -> nx.DiGraph:
        """
        å®Œæ•´çš„äº‹ä»¶å› æœå›¾æ„å»ºæµç¨‹
        
        Args:
            limit_events: é™åˆ¶å¤„ç†çš„äº‹ä»¶æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
            
        Returns:
            æ„å»ºå®Œæˆçš„NetworkXæœ‰å‘å›¾
        """
        print("ğŸš€ å¼€å§‹å®Œæ•´çš„äº‹ä»¶å› æœå›¾æ„å»ºæµç¨‹...")
        
        # 2. æ„å»ºäº‹ä»¶åˆ—è¡¨
        print("\nğŸ” æ„å»ºäº‹ä»¶åˆ—è¡¨...")
        event_list = self.build_event_list()
        
        # 3. é™åˆ¶äº‹ä»¶æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        if limit_events and limit_events < len(event_list):
            event_list = event_list[:limit_events]
            print(f"âš ï¸ é™åˆ¶å¤„ç†äº‹ä»¶æ•°é‡ä¸º: {limit_events}")
        
        # 4. è¿‡æ»¤äº‹ä»¶å¯¹
        print("\nğŸ” è¿‡æ»¤äº‹ä»¶å¯¹...")
        filtered_pairs = self.filter_event_pairs_by_community(
            event_list
        )
        
        if not filtered_pairs:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„äº‹ä»¶å¯¹ï¼Œè¿”å›ç©ºå›¾")
            return nx.DiGraph()
        
        # 5. æ£€æŸ¥å› æœå…³ç³»
        print("\nğŸ” æ£€æŸ¥å› æœå…³ç³»...")
        causality_results = self.check_causality_batch(filtered_pairs)
        
        # 6. æ„å»ºå› æœå›¾
        print("\nğŸ” æ„å»ºå› æœå›¾...")
        causality_graph = self.build_causality_graph(causality_results)
        
        # 7. ä¿å­˜å›¾ï¼ˆå¦‚æœæŒ‡å®šäº†è¾“å‡ºè·¯å¾„ï¼‰
        output_path = "data/event_causality_graph/event_causality_graph.pickle"
        print(f"\nğŸ’¾ ä¿å­˜å›¾åˆ° {output_path}...")
        self.save_graph(causality_graph, output_path)
        
        # 8. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š å›¾ç»Ÿè®¡ä¿¡æ¯:")
        stats = self.get_graph_statistics(causality_graph)
        for key, value in stats.items():
            print(f"   {key}: {value}")
        
        print("\nâœ… äº‹ä»¶å› æœå›¾æ„å»ºå®Œæˆï¼")
        return causality_graph

    def get_graph_statistics(self, graph: nx.DiGraph) -> Dict[str, Any]:
        """
        è·å–å›¾çš„ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            graph: NetworkXæœ‰å‘å›¾
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        stats = {
            'nodes': graph.number_of_nodes(),
            'edges': graph.number_of_edges(),
            'density': nx.density(graph),
            'is_connected': nx.is_weakly_connected(graph),
            'strongly_connected_components': nx.number_strongly_connected_components(graph),
            'weakly_connected_components': nx.number_weakly_connected_components(graph)
        }
        
        # å› æœå…³ç³»å¼ºåº¦åˆ†å¸ƒ
        if graph.number_of_edges() > 0:
            causal_levels = [data['causal_level'] for _, _, data in graph.edges(data=True)]
            stats['causal_level_distribution'] = {
                level: causal_levels.count(level) for level in set(causal_levels)
            }
            
            # åè½¬è¾¹ç»Ÿè®¡
            reversed_edges = [data for _, _, data in graph.edges(data=True) if data.get('reverse', False)]
            stats['reversed_edges_count'] = len(reversed_edges)
            stats['reversed_edges_percentage'] = len(reversed_edges) / graph.number_of_edges() * 100
        
        return stats

